{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf3f30e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# In root/notebooks/fulltrain_analysis.ipynb\n",
    "\n",
    "from pathlib import Path\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "BASE = Path(\"../experiments/cls_collapse\")\n",
    "RUN_25 = \"full_full_cls_w0.25\"   # 25-epoch run you just trained\n",
    "RUN_5  = \"full_full_cls_w0.25\"   # (optional) change to your older 5-epoch run name if different\n",
    "\n",
    "def read_json(p: Path):\n",
    "    return json.loads(p.read_text()) if p.exists() else {}\n",
    "\n",
    "def read_csv(p: Path):\n",
    "    return pd.read_csv(p) if p.exists() else pd.DataFrame()\n",
    "\n",
    "def read_jsonl(p: Path):\n",
    "    if not p.exists():\n",
    "        return pd.DataFrame()\n",
    "    rows = []\n",
    "    for line in p.read_text().splitlines():\n",
    "        line = line.strip()\n",
    "        if line:\n",
    "            rows.append(json.loads(line))\n",
    "    return pd.DataFrame(rows)\n",
    "\n",
    "def load_run(run_name: str):\n",
    "    d = BASE / run_name\n",
    "    return {\n",
    "        \"name\": run_name,\n",
    "        \"dir\": d,\n",
    "        \"meta\": read_json(d / \"meta.json\"),\n",
    "        \"opt\": read_json(d / \"optimizer.json\"),\n",
    "        \"steps\": read_csv(d / \"step_losses.csv\"),\n",
    "        \"epochs\": read_csv(d / \"epoch_summary.csv\"),\n",
    "        \"dbg\": read_jsonl(d / \"debug.jsonl\"),\n",
    "    }\n",
    "\n",
    "run = load_run(RUN_25)\n",
    "run[\"dir\"], run[\"steps\"].shape, run[\"epochs\"].shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec943555",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1) Final-epoch summary + quick collapse flags\n",
    "epochs = run[\"epochs\"].copy()\n",
    "epochs = epochs.sort_values(\"epoch\") if \"epoch\" in epochs.columns else epochs\n",
    "last = epochs.iloc[-1].to_dict() if len(epochs) else {}\n",
    "\n",
    "summary = {\n",
    "    \"run\": run[\"name\"],\n",
    "    \"epochs_logged\": int(epochs[\"epoch\"].max()) + 1 if len(epochs) and \"epoch\" in epochs.columns else None,\n",
    "    \"cls_max_mean_last\": last.get(\"cls_max_mean\"),\n",
    "    \"cls_max_p95_last\": last.get(\"cls_max_p95\"),\n",
    "    \"mask_max_mean_last\": last.get(\"mask_max_mean\"),\n",
    "    \"mask_max_p95_last\": last.get(\"mask_max_p95\"),\n",
    "    \"img_forged_mean_last\": last.get(\"img_forged_mean\"),\n",
    "    \"img_forged_p95_last\": last.get(\"img_forged_p95\"),\n",
    "}\n",
    "\n",
    "summary, {\n",
    "    \"cls_collapsed@~0.125\": (summary[\"cls_max_mean_last\"] is not None) and abs(summary[\"cls_max_mean_last\"] - 0.125) < 1e-3,\n",
    "    \"mask_saturated@>0.99\": (summary[\"mask_max_mean_last\"] is not None) and summary[\"mask_max_mean_last\"] > 0.99,\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2af89d55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2) Learning curves (step-level)\n",
    "steps = run[\"steps\"].copy()\n",
    "steps = steps.sort_values(\"global_step\") if \"global_step\" in steps.columns else steps\n",
    "\n",
    "def plot_step(metric):\n",
    "    if metric not in steps.columns or \"global_step\" not in steps.columns:\n",
    "        print(f\"missing {metric} or global_step in step_losses.csv\")\n",
    "        return\n",
    "    plt.figure()\n",
    "    plt.plot(steps[\"global_step\"], steps[metric])\n",
    "    plt.xlabel(\"global_step\")\n",
    "    plt.ylabel(metric)\n",
    "    plt.title(f\"{run['name']} — {metric}\")\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "for m in [\"loss_total\", \"loss_mask_cls\", \"loss_auth_penalty\"]:\n",
    "    plot_step(m)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2666366b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3) Epoch curves (collapse indicators over time)\n",
    "def plot_epoch(metric):\n",
    "    if metric not in epochs.columns or \"epoch\" not in epochs.columns:\n",
    "        print(f\"missing {metric} or epoch in epoch_summary.csv\")\n",
    "        return\n",
    "    plt.figure()\n",
    "    plt.plot(epochs[\"epoch\"], epochs[metric], marker=\"o\")\n",
    "    plt.xlabel(\"epoch\")\n",
    "    plt.ylabel(metric)\n",
    "    plt.title(f\"{run['name']} — {metric} (epoch)\")\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "for m in [\"cls_max_mean\", \"cls_max_p95\", \"mask_max_mean\", \"img_forged_mean\"]:\n",
    "    plot_epoch(m)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdbd98f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4) Debug JSONL: cls target density + auth penalty stats (if present)\n",
    "dbg = run[\"dbg\"].copy()\n",
    "dbg.head(), dbg[\"tag\"].value_counts() if \"tag\" in dbg.columns else \"no tag column\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34065b44",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_dbg(tag, y):\n",
    "    if dbg.empty or \"tag\" not in dbg.columns:\n",
    "        print(\"no debug.jsonl\")\n",
    "        return\n",
    "    sub = dbg[dbg[\"tag\"] == tag].copy()\n",
    "    if sub.empty or y not in sub.columns:\n",
    "        print(f\"no rows for tag={tag} with field={y}\")\n",
    "        return\n",
    "    x = \"global_step\" if \"global_step\" in sub.columns else None\n",
    "    if x is None:\n",
    "        print(\"no global_step in debug.jsonl records\")\n",
    "        return\n",
    "    sub = sub.sort_values(x)\n",
    "    plt.figure()\n",
    "    plt.plot(sub[x], sub[y])\n",
    "    plt.xlabel(x)\n",
    "    plt.ylabel(y)\n",
    "    plt.title(f\"{run['name']} — {tag}:{y}\")\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "plot_dbg(\"loss_cls_targets\", \"pos_frac\")\n",
    "plot_dbg(\"loss_auth_penalty_stats\", \"per_image_penalty_mean\")\n",
    "plot_dbg(\"loss_auth_penalty_stats\", \"loss_auth_penalty\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebffb147",
   "metadata": {},
   "outputs": [],
   "source": [
    "# (Optional) compare your new 25-epoch run to an older run (set RUN_5 to the old run folder name)\n",
    "if RUN_5 != RUN_25:\n",
    "    run_old = load_run(RUN_5)\n",
    "    e_new = run[\"epochs\"].sort_values(\"epoch\")\n",
    "    e_old = run_old[\"epochs\"].sort_values(\"epoch\")\n",
    "\n",
    "    def compare_epoch(metric):\n",
    "        if metric not in e_new.columns or metric not in e_old.columns:\n",
    "            print(\"missing\", metric)\n",
    "            return\n",
    "        plt.figure()\n",
    "        plt.plot(e_old[\"epoch\"], e_old[metric], marker=\"o\", label=f\"{RUN_5}\")\n",
    "        plt.plot(e_new[\"epoch\"], e_new[metric], marker=\"o\", label=f\"{RUN_25}\")\n",
    "        plt.xlabel(\"epoch\"); plt.ylabel(metric)\n",
    "        plt.title(metric)\n",
    "        plt.grid(True)\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "\n",
    "    for m in [\"cls_max_mean\", \"mask_max_mean\", \"img_forged_mean\"]:\n",
    "        compare_epoch(m)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5973c12",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch, numpy as np\n",
    "from torch.utils.data import DataLoader\n",
    "from src.data.dataloader import ForgeryDataset, get_val_transform\n",
    "from src.models.mask2former_v1 import Mask2FormerForgeryModel\n",
    "from src.utils.config_utils import sanitize_model_kwargs\n",
    "import yaml\n",
    "\n",
    "cfg = yaml.safe_load(open(\"../config/base.yaml\",\"r\"))\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "ds = ForgeryDataset(transform=get_val_transform(img_size=cfg[\"data\"][\"img_size\"]))\n",
    "loader = DataLoader(ds, batch_size=cfg[\"trainer\"][\"batch_size\"], shuffle=False,\n",
    "                    collate_fn=lambda x: tuple(zip(*x)))\n",
    "\n",
    "mk = sanitize_model_kwargs(cfg[\"model\"])\n",
    "mk.pop(\"auth_gate_forged_threshold\", None)\n",
    "model = Mask2FormerForgeryModel(**mk, auth_gate_forged_threshold=-1.0).to(device)\n",
    "\n",
    "model.load_state_dict(torch.load(\"../weights/full_train/full_cls_w0.25.pth\", map_location=device))\n",
    "model.eval()\n",
    "\n",
    "all_p = []\n",
    "with torch.no_grad():\n",
    "    for images, _ in loader:\n",
    "        images = [im.to(device) for im in images]\n",
    "        _, _, img_logits = model.forward_logits(images)     # <— bypass inference/gate\n",
    "        all_p.append(torch.sigmoid(img_logits).cpu())\n",
    "all_p = torch.cat(all_p).numpy()\n",
    "\n",
    "print(\"min/median/mean/p95/max:\", np.min(all_p), np.median(all_p), np.mean(all_p), np.quantile(all_p,0.95), np.max(all_p))\n",
    "for g in [0.05, 0.1, 0.2, 0.5, 0.8, 0.9, 0.95]:\n",
    "    print(g, \"pass_frac:\", float((all_p >= g).mean()))\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
