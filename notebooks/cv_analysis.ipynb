{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "67e6b406",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cv_analysis.ipynb\n",
    "\n",
    "import json\n",
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "PROJECT_ROOT = Path(\"..\").resolve()\n",
    "\n",
    "if str(PROJECT_ROOT) not in sys.path:\n",
    "    sys.path.insert(0, str(PROJECT_ROOT))\n",
    "\n",
    "from src.data.dataloader import (\n",
    "    ForgeryDataset,\n",
    "    detection_collate_fn,\n",
    "    get_val_transform,\n",
    ")\n",
    "from src.models.mask2former_v2 import Mask2FormerForgeryModel\n",
    "from src.utils.config_utils import load_yaml, sanitize_model_kwargs\n",
    "from src.training.train_cv import build_solution_df\n",
    "from src.data.dataloader import ForgeryDataset\n",
    "from src.models.kaggle_metric import score as kaggle_score\n",
    "\n",
    "plt.style.use(\"ggplot\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1cb53e0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------\n",
    "# Constants / Paths\n",
    "# -----------------\n",
    "\n",
    "OOF_ROOT = PROJECT_ROOT / \"experiments\" / \"oof_results\"\n",
    "FULL_TRAIN_ROOT = PROJECT_ROOT / \"experiments\" / \"full_train_results\"\n",
    "\n",
    "CLS_THRESHOLD_PATH = (\n",
    "    PROJECT_ROOT / \"experiments\" / \"cls_threshold_sweep\" / \"cls_threshold_sweep.csv\"\n",
    ")\n",
    "\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "CFG_PATH = PROJECT_ROOT / \"config\" / \"base.yaml\"\n",
    "\n",
    "CLPSE_ROOT = PROJECT_ROOT / \"experiments\" / \"cls_collapse\"\n",
    "\n",
    "SAMPLEDUMP_ROOT = PROJECT_ROOT / \"experiments\" / \"oof_results\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d693608",
   "metadata": {},
   "source": [
    "### OOF CV results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a5c26d53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OOF dirs: ['anti_collapse_wcls2_strong_auth_penalty', 'auth_penalty_maskmass_only_w3', 'balanced_soft_penalty_thr0p3_temp0p3', 'base_wgroupkfold', 'cls_unclamp_test', 'gate_pass_TRUE', 'inf_thresh_off', 'loss_dice_heavy_bce0p5_dice2', 'mask_first_wmask4_wcls0p25', 'match_bce_dominant_cost2_dice0p5', 'match_dice_dominant_cost2_bce0p5', 'mini_ext_authpen_0p1', 'mini_ext_authpen_20', 'mini_ext_presence_w5', 'mini_lossv2_authpen_strong20', 'mini_lossv2_authpen_weak1', 'mini_lossv2_baseline', 'mini_lossv2_cls_up2', 'mini_lossv2_numq8_authpen10', 'mini_minmass_0p002', 'mini_presence_0p3', 'mini_presence_0p45_topk1', 'mini_presence_0p5', 'mini_qscore_0p15_minmass_0p002', 'mini_qscore_0p5', 'mini_smoke', 'mini_topk1_minmass_0p001', 'mini_topk1_minmass_0p003', 'mini_topk2_minmass_0p002', 'mini_topk_1', 'oof_lossv2_authpen_weak1_e25', 'oof_lossv2_cls_up2_authpen_weak1_e25', 'oof_lossv2_cls_up2_e25', 'sharp_auth_penalty_temp0p05_thr0p6_w2', 'soft_auth_penalty_temp1_thr0p2_w3']\n",
      "OOF loose files: ['sanity_random_200.csv']\n"
     ]
    }
   ],
   "source": [
    "# List what's in experiments/oof_results/\n",
    "oof_items = list(OOF_ROOT.iterdir())\n",
    "oof_dirs = sorted([p.name for p in oof_items if p.is_dir()])\n",
    "oof_files = sorted([p.name for p in oof_items if p.is_file()])\n",
    "\n",
    "print(\"OOF dirs:\", oof_dirs)\n",
    "if oof_files:\n",
    "    print(\"OOF loose files:\", oof_files)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "03a67ab1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded:\n",
      " - oof_lossv2_cls_up2_authpen_weak1_e25 (C:\\Users\\piiop\\Desktop\\Portfolio\\Projects\\RecodAI_LUC\\experiments\\oof_results\\oof_lossv2_cls_up2_authpen_weak1_e25)\n"
     ]
    }
   ],
   "source": [
    "def load_run(names):\n",
    "    \"\"\"\n",
    "    names:\n",
    "      - str: dir name under OOF_ROOT OR filename under OOF_ROOT\n",
    "      - list/tuple[str]: load multiple; returns dict keyed by run/filename\n",
    "    \"\"\"\n",
    "    if isinstance(names, (list, tuple)):\n",
    "        return {str(n): load_run(str(n)) for n in names}\n",
    "\n",
    "    name = str(names)\n",
    "    p = OOF_ROOT / name\n",
    "\n",
    "    # Case A: run directory\n",
    "    if p.is_dir():\n",
    "        run_dir = p\n",
    "        oof_csv = run_dir / \"oof_predictions.csv\"\n",
    "        metrics_json = run_dir / \"oof_metrics.json\"\n",
    "\n",
    "        oof_df = pd.read_csv(oof_csv) if oof_csv.exists() else None\n",
    "        metrics = json.load(metrics_json.open()) if metrics_json.exists() else None\n",
    "\n",
    "        fold_files = sorted(run_dir.glob(\"fold_*_oof.csv\"))\n",
    "        fold_dfs = {f.stem: pd.read_csv(f) for f in fold_files}\n",
    "\n",
    "        return {\"name\": run_dir.name, \"path\": run_dir, \"oof\": oof_df, \"metrics\": metrics, \"folds\": fold_dfs}\n",
    "\n",
    "    # Case B: loose file\n",
    "    if p.is_file():\n",
    "        if p.suffix.lower() == \".csv\":\n",
    "            return {\"name\": p.name, \"path\": p, \"oof\": pd.read_csv(p), \"metrics\": None, \"folds\": {}}\n",
    "        if p.suffix.lower() == \".json\":\n",
    "            return {\"name\": p.name, \"path\": p, \"oof\": None, \"metrics\": json.load(p.open()), \"folds\": {}}\n",
    "        raise ValueError(f\"Unsupported file type: {p.suffix}\")\n",
    "\n",
    "    raise FileNotFoundError(f\"Not found under OOF_ROOT: {name}\")\n",
    "\n",
    "# Use load_run(name | [names]) to load one or more CV runs or loose files from experiments/oof_results/\n",
    "runs = load_run([\"oof_lossv2_cls_up2_authpen_weak1_e25\"])  # or: load_run(\"mini_smoke\"), load_run(\"oof_predictions.csv\")\n",
    "\n",
    "print(\"Loaded:\")\n",
    "if isinstance(runs, dict) and \"name\" not in runs:\n",
    "    for k, v in runs.items():\n",
    "        print(f\" - {v['name']} ({v['path']})\")\n",
    "else:\n",
    "    print(f\" - {runs['name']} ({runs['path']})\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "eba815e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Loaded runs ===\n",
      "\n",
      "oof_lossv2_cls_up2_authpen_weak1_e25\n",
      "  Mean CV   : 0.18052878220948618\n",
      "  OOF score : 0.1805358260260567\n",
      "  Folds     : [0.21698757677842528, 0.129555247968704, 0.19504352188132928]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 700x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def show_run_metrics(names):\n",
    "    \"\"\"\n",
    "    Pass a run dir name (str) or list of names to compare.\n",
    "    \"\"\"\n",
    "    runs = load_run(names)\n",
    "    if isinstance(runs, dict) and \"name\" not in runs:\n",
    "        items = list(runs.values())\n",
    "    else:\n",
    "        items = [runs]\n",
    "\n",
    "    # Clean summary header\n",
    "    print(\"=== Loaded runs ===\")\n",
    "    for r in items:\n",
    "        m = r[\"metrics\"] or {}\n",
    "        mean_cv = m.get(\"mean_cv\", None)\n",
    "        oof_score = m.get(\"oof_score\", None)\n",
    "        fold_scores = m.get(\"fold_scores\", None)\n",
    "\n",
    "        print(f\"\\n{r['name']}\")\n",
    "        print(f\"  Mean CV   : {mean_cv}\")\n",
    "        print(f\"  OOF score : {oof_score}\")\n",
    "        if fold_scores is not None:\n",
    "            print(f\"  Folds     : {fold_scores}\")\n",
    "\n",
    "    # Comparison plot (only for runs that have fold_scores)\n",
    "    plot_items = [(r[\"name\"], (r[\"metrics\"] or {}).get(\"fold_scores\")) for r in items]\n",
    "    plot_items = [(n, fs) for (n, fs) in plot_items if fs is not None]\n",
    "\n",
    "    if plot_items:\n",
    "        plt.figure(figsize=(7, 4))\n",
    "        for name, fs in plot_items:\n",
    "            plt.plot(range(1, len(fs) + 1), fs, marker=\"o\", label=name)\n",
    "        plt.xlabel(\"Fold\")\n",
    "        plt.ylabel(\"Score\")\n",
    "        plt.title(\"Per-fold scores (comparison)\")\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "\n",
    "    return runs\n",
    "\n",
    "# Single run\n",
    "_ = show_run_metrics(\"oof_lossv2_cls_up2_authpen_weak1_e25\")\n",
    "\n",
    "# Compare multiple runs\n",
    "# _ = show_run_metrics([\"mini_smoke\", \"some_other_run\"])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc645bc2",
   "metadata": {},
   "source": [
    "## CollapseLogger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a17d44dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "== oof_predictions.csv (head) ==\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>row_id</th>\n",
       "      <th>annotation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10</td>\n",
       "      <td>[1, 5648, 5697, 376, 6137, 24, 6209, 376, 6649...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10015</td>\n",
       "      <td>[90489, 19, 91689, 19, 92889, 19, 94089, 19, 9...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10017</td>\n",
       "      <td>[65, 28, 145, 8, 157, 24, 321, 28, 401, 8, 413...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10030</td>\n",
       "      <td>[406574, 20, 407240, 20, 407906, 20, 408572, 2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10070</td>\n",
       "      <td>[143214, 22, 143926, 22, 144638, 22, 145350, 2...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   row_id                                         annotation\n",
       "0      10  [1, 5648, 5697, 376, 6137, 24, 6209, 376, 6649...\n",
       "1   10015  [90489, 19, 91689, 19, 92889, 19, 94089, 19, 9...\n",
       "2   10017  [65, 28, 145, 8, 157, 24, 321, 28, 401, 8, 413...\n",
       "3   10030  [406574, 20, 407240, 20, 407906, 20, 408572, 2...\n",
       "4   10070  [143214, 22, 143926, 22, 144638, 22, 145350, 2..."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Found fold CSVs: ['fold_1_oof', 'fold_2_oof', 'fold_3_oof']\n"
     ]
    }
   ],
   "source": [
    "# ---- Use an already-loaded run from `runs` ----\n",
    "run = runs[\"oof_lossv2_cls_up2_authpen_weak1_e25\"]  # must exist in `runs`\n",
    "\n",
    "OOF_RUN_DIR = Path(run[\"path\"])\n",
    "oof_metrics = run[\"metrics\"] or {}\n",
    "oof_predictions = run[\"oof\"]\n",
    "fold_dfs = run[\"folds\"]\n",
    "\n",
    "print(\"\\n== oof_predictions.csv (head) ==\")\n",
    "display(oof_predictions.head() if oof_predictions is not None else None)\n",
    "\n",
    "print(\"\\nFound fold CSVs:\", list(fold_dfs.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "72e30e1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "== Recomputed overall OOF score ==\n",
      "recomputed_oof: 0.032215389829571665\n",
      "\n",
      "== Recomputed per-fold scores ==\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fold</th>\n",
       "      <th>kaggle_metric</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.216988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.129555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.195044</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fold  kaggle_metric\n",
       "0     1       0.216988\n",
       "1     2       0.129555\n",
       "2     3       0.195044"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Rebuild solution_df and re-score to match train_cv additional pipeline verification\n",
    "full_dataset = ForgeryDataset(transform=None)\n",
    "solution_df = build_solution_df(full_dataset)\n",
    "\n",
    "# Overall OOF score (ALIGN BY row_id, then score)\n",
    "solution_df[\"row_id\"] = solution_df[\"row_id\"].astype(str)\n",
    "oof_predictions[\"row_id\"] = oof_predictions[\"row_id\"].astype(str)\n",
    "\n",
    "sub_aligned = (\n",
    "    solution_df[[\"row_id\"]]\n",
    "    .merge(oof_predictions[[\"row_id\", \"annotation\"]], on=\"row_id\", how=\"left\")\n",
    ")\n",
    "\n",
    "recomputed_oof = kaggle_score(\n",
    "    solution_df[[\"row_id\", \"annotation\", \"shape\"]].copy(),\n",
    "    sub_aligned[[\"row_id\", \"annotation\"]].copy(),\n",
    "    row_id_column_name=\"row_id\",\n",
    ")\n",
    "\n",
    "print(\"\\n== Recomputed overall OOF score ==\")\n",
    "print(\"recomputed_oof:\", float(recomputed_oof))\n",
    "\n",
    "# Per-fold (recompute using the saved fold CSVs if present)\n",
    "def fold_num_from_stem(stem: str) -> int:\n",
    "    m = re.search(r\"(\\d+)\", stem)\n",
    "    return int(m.group(1)) if m else -1\n",
    "\n",
    "if fold_dfs:\n",
    "    # Build stable (row_id, occ) keys on the FULL solution_df once\n",
    "    sol = solution_df.copy()\n",
    "    sol[\"row_id\"] = sol[\"row_id\"].astype(str)\n",
    "    sol[\"occ\"] = sol.groupby(\"row_id\").cumcount()\n",
    "\n",
    "    fold_scores = []\n",
    "    for stem, fdf in sorted(fold_dfs.items(), key=lambda kv: fold_num_from_stem(kv[0])):\n",
    "        fnum = fold_num_from_stem(stem)\n",
    "\n",
    "        sub = fdf.copy()\n",
    "        sub[\"row_id\"] = sub[\"row_id\"].astype(str)\n",
    "        # IMPORTANT: occ must follow the fold CSV order (this is what well score)\n",
    "        sub[\"occ\"] = sub.groupby(\"row_id\").cumcount()\n",
    "\n",
    "        # Rebuild fold solution IN THE SAME ORDER AS sub (no sorting, no isin)\n",
    "        fold_sol = sub[[\"row_id\", \"occ\"]].merge(\n",
    "            sol[[\"row_id\", \"occ\", \"annotation\", \"shape\"]],\n",
    "            on=[\"row_id\", \"occ\"],\n",
    "            how=\"left\",\n",
    "        )\n",
    "\n",
    "        # Hard sanity checks (if these fail, your saved fold CSV isn't compatible with solution_df)\n",
    "        assert len(fold_sol) == len(sub)\n",
    "        if fold_sol[\"annotation\"].isna().any() or fold_sol[\"shape\"].isna().any():\n",
    "            bad = fold_sol[fold_sol[\"annotation\"].isna() | fold_sol[\"shape\"].isna()].head(10)\n",
    "            raise RuntimeError(f\"{stem}: fold_sol has missing GT rows. Sample:\\n{bad}\")\n",
    "\n",
    "        # Submission already in correct order; kaggle_score aligns by row order\n",
    "        fold_sub = sub[[\"row_id\", \"annotation\"]].copy()\n",
    "\n",
    "        s = kaggle_score(\n",
    "            fold_sol[[\"row_id\", \"annotation\", \"shape\"]].copy(),\n",
    "            fold_sub.copy(),\n",
    "            row_id_column_name=\"row_id\",\n",
    "        )\n",
    "        fold_scores.append((fnum, float(s)))\n",
    "\n",
    "    fold_scores_df = pd.DataFrame(fold_scores, columns=[\"fold\", \"kaggle_metric\"]).sort_values(\"fold\")\n",
    "    print(\"\\n== Recomputed per-fold scores ==\")\n",
    "    display(fold_scores_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "2c4929a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded ClsCollapseLogger artifacts from:\n",
      "  C:\\Users\\piiop\\Desktop\\Portfolio\\Projects\\RecodAI_LUC\\experiments\\oof_results\\oof_lossv2_cls_up2_authpen_weak1_e25\\cv_fold1\n",
      "  C:\\Users\\piiop\\Desktop\\Portfolio\\Projects\\RecodAI_LUC\\experiments\\oof_results\\oof_lossv2_cls_up2_authpen_weak1_e25\\cv_fold2\n",
      "  C:\\Users\\piiop\\Desktop\\Portfolio\\Projects\\RecodAI_LUC\\experiments\\oof_results\\oof_lossv2_cls_up2_authpen_weak1_e25\\cv_fold3\n",
      "  C:\\Users\\piiop\\Desktop\\Portfolio\\Projects\\RecodAI_LUC\\experiments\\oof_results\\oof_lossv2_cls_up2_authpen_weak1_e25\\cv_oof_summary\n",
      "  JSON blobs : 6\n",
      "  Tables     : 10\n",
      "\n",
      "cv_fold1 tables:\n",
      "  - debug.jsonl | shape=(301954, 63) | cols=['tag', 'fold', 'epoch', 'global_step', 'img_label', 'masks_shape', 'masks_sum', 'per_image', 'mask_probs', 'class_probs', 'b', 'Q', 'Hm', 'Wm', 'tgt_shape', 'tgt_numel', 'tgt_sum', 'allowed_q', 'matched', 'reason', 'B', 'pos', 'total', 'pos_frac', 'weights_sum', 'weights_mean', 'presence_mean', 'presence_min', 'presence_max', 'loss_presence', 'presence_lse_beta', 'train_topk', 'train_min_mask_mass', 'allowed_queries_per_image', 'qscore_max', 'qscore_sum', 'qscore_max_over_sum', 'mask_mass_max', 'batch', 'fg_prob_per_query', 'fg_prob_mean', 'fg_prob_p95', 'fg_prob_max', 'authentic_frac', 'per_image_penalty_mean', 'loss_auth_penalty', 'few_queries_lambda', 'loss_few_queries', 'cost_shape', 'num_gt', 'Qa', 'val_samples', 'masks_empty', 'gate_fail', 'num_keep0', 'cls_filtered_all_fg', 'no_fg_pre_keep', 'rates', 'max_cls_prob', 'max_mask_prob', 'pred_auth_frac', 'pred_non_auth_count', 'pred_non_auth_area_ratio_mean']\n",
      "  - epoch_summary.csv | shape=(25, 14) | cols=['fold', 'epoch', 'epoch_loss', 'qscore_max_mean', 'qscore_max_p95', 'qscore_max_over_sum_mean', 'num_qscore_gt_0.05', 'num_qscore_gt_0.10', 'num_qscore_gt_0.20', 'mask_mass_max_mean', 'mask_max_mean', 'w_mask_cls', 'w_presence', 'few_queries_lambda']\n",
      "  - step_losses.csv | shape=(21575, 17) | cols=['fold', 'epoch', 'global_step', 'lr', 'loss_mask_bce', 'loss_mask_dice', 'loss_mask_cls', 'loss_presence', 'loss_auth_penalty', 'loss_total', 'w_mask_cls', 'w_presence', 'w_auth_penalty', 'train_topk', 'train_min_mask_mass', 'few_queries_lambda', 'presence_lse_beta']\n",
      "\n",
      "cv_fold2 tables:\n",
      "  - debug.jsonl | shape=(302004, 63) | cols=['tag', 'fold', 'epoch', 'global_step', 'img_label', 'masks_shape', 'masks_sum', 'per_image', 'mask_probs', 'class_probs', 'b', 'Q', 'Hm', 'Wm', 'tgt_shape', 'tgt_numel', 'tgt_sum', 'allowed_q', 'matched', 'reason', 'cost_shape', 'num_gt', 'Qa', 'B', 'pos', 'total', 'pos_frac', 'weights_sum', 'weights_mean', 'presence_mean', 'presence_min', 'presence_max', 'loss_presence', 'presence_lse_beta', 'train_topk', 'train_min_mask_mass', 'allowed_queries_per_image', 'qscore_max', 'qscore_sum', 'qscore_max_over_sum', 'mask_mass_max', 'batch', 'fg_prob_per_query', 'fg_prob_mean', 'fg_prob_p95', 'fg_prob_max', 'authentic_frac', 'per_image_penalty_mean', 'loss_auth_penalty', 'few_queries_lambda', 'loss_few_queries', 'val_samples', 'masks_empty', 'gate_fail', 'num_keep0', 'cls_filtered_all_fg', 'no_fg_pre_keep', 'rates', 'max_cls_prob', 'max_mask_prob', 'pred_auth_frac', 'pred_non_auth_count', 'pred_non_auth_area_ratio_mean']\n",
      "  - epoch_summary.csv | shape=(25, 14) | cols=['fold', 'epoch', 'epoch_loss', 'qscore_max_mean', 'qscore_max_p95', 'qscore_max_over_sum_mean', 'num_qscore_gt_0.05', 'num_qscore_gt_0.10', 'num_qscore_gt_0.20', 'mask_mass_max_mean', 'mask_max_mean', 'w_mask_cls', 'w_presence', 'few_queries_lambda']\n",
      "  - step_losses.csv | shape=(21575, 17) | cols=['fold', 'epoch', 'global_step', 'lr', 'loss_mask_bce', 'loss_mask_dice', 'loss_mask_cls', 'loss_presence', 'loss_auth_penalty', 'loss_total', 'w_mask_cls', 'w_presence', 'w_auth_penalty', 'train_topk', 'train_min_mask_mass', 'few_queries_lambda', 'presence_lse_beta']\n",
      "\n",
      "cv_fold3 tables:\n",
      "  - debug.jsonl | shape=(302004, 63) | cols=['tag', 'fold', 'epoch', 'global_step', 'img_label', 'masks_shape', 'masks_sum', 'per_image', 'mask_probs', 'class_probs', 'b', 'Q', 'Hm', 'Wm', 'tgt_shape', 'tgt_numel', 'tgt_sum', 'allowed_q', 'matched', 'reason', 'cost_shape', 'num_gt', 'Qa', 'B', 'pos', 'total', 'pos_frac', 'weights_sum', 'weights_mean', 'presence_mean', 'presence_min', 'presence_max', 'loss_presence', 'presence_lse_beta', 'train_topk', 'train_min_mask_mass', 'allowed_queries_per_image', 'qscore_max', 'qscore_sum', 'qscore_max_over_sum', 'mask_mass_max', 'batch', 'fg_prob_per_query', 'fg_prob_mean', 'fg_prob_p95', 'fg_prob_max', 'authentic_frac', 'per_image_penalty_mean', 'loss_auth_penalty', 'few_queries_lambda', 'loss_few_queries', 'val_samples', 'masks_empty', 'gate_fail', 'num_keep0', 'cls_filtered_all_fg', 'no_fg_pre_keep', 'rates', 'max_cls_prob', 'max_mask_prob', 'pred_auth_frac', 'pred_non_auth_count', 'pred_non_auth_area_ratio_mean']\n",
      "  - epoch_summary.csv | shape=(25, 14) | cols=['fold', 'epoch', 'epoch_loss', 'qscore_max_mean', 'qscore_max_p95', 'qscore_max_over_sum_mean', 'num_qscore_gt_0.05', 'num_qscore_gt_0.10', 'num_qscore_gt_0.20', 'mask_mass_max_mean', 'mask_max_mean', 'w_mask_cls', 'w_presence', 'few_queries_lambda']\n",
      "  - step_losses.csv | shape=(21575, 17) | cols=['fold', 'epoch', 'global_step', 'lr', 'loss_mask_bce', 'loss_mask_dice', 'loss_mask_cls', 'loss_presence', 'loss_auth_penalty', 'loss_total', 'w_mask_cls', 'w_presence', 'w_auth_penalty', 'train_topk', 'train_min_mask_mass', 'few_queries_lambda', 'presence_lse_beta']\n",
      "\n",
      "cv_oof_summary tables:\n",
      "  - debug.jsonl | shape=(1, 5) | cols=['tag', 'val_samples', 'pred_auth_frac', 'pred_non_auth_count', 'pred_non_auth_area_ratio_mean']\n"
     ]
    }
   ],
   "source": [
    "# ---------------------------------------------------------------------\n",
    "# Load ClsCollapseLogger outputs for the CV folds\n",
    "# (stored under experiments/oof_results/<run_name>/cv_fold*/ and cv_oof_summary/)\n",
    "# ---------------------------------------------------------------------\n",
    "\n",
    "def _read_json(p: Path):\n",
    "    with open(p, \"r\") as f:\n",
    "        return json.load(f)\n",
    "\n",
    "def _read_jsonl(p: Path):\n",
    "    rows = []\n",
    "    with open(p, \"r\") as f:\n",
    "        for line in f:\n",
    "            line = line.strip()\n",
    "            if line:\n",
    "                rows.append(json.loads(line))\n",
    "    return pd.DataFrame(rows) if rows else pd.DataFrame()\n",
    "\n",
    "def _read_table(p: Path):\n",
    "    suf = p.suffix.lower()\n",
    "    if suf == \".csv\":\n",
    "        return pd.read_csv(p)\n",
    "    if suf in (\".jsonl\", \".ndjson\"):\n",
    "        return _read_jsonl(p)\n",
    "    return None\n",
    "\n",
    "LOGGER_FILES = {\n",
    "    \"debug.jsonl\",\n",
    "    \"epoch_summary.csv\",\n",
    "    \"meta.json\",\n",
    "    \"optimizer.json\",\n",
    "    \"step_losses.csv\",\n",
    "}\n",
    "\n",
    "# Discover fold directories (cv_fold1, cv_fold2, ...) + optional cv_oof_summary\n",
    "fold_dirs = []\n",
    "if OOF_RUN_DIR.exists():\n",
    "    for d in sorted(OOF_RUN_DIR.iterdir()):\n",
    "        if d.is_dir() and (re.match(r\"cv_fold\\d+$\", d.name) or d.name == \"cv_oof_summary\"):\n",
    "            fold_dirs.append(d)\n",
    "\n",
    "collapse_json = {}    # (fold_dirname, filename) -> dict\n",
    "collapse_tables = {}  # (fold_dirname, filename) -> df\n",
    "\n",
    "for d in fold_dirs:\n",
    "    for fname in LOGGER_FILES:\n",
    "        p = d / fname\n",
    "        if not p.exists():\n",
    "            continue\n",
    "\n",
    "        if p.suffix.lower() == \".json\":\n",
    "            try:\n",
    "                collapse_json[(d.name, fname)] = _read_json(p)\n",
    "            except Exception:\n",
    "                pass\n",
    "        elif p.suffix.lower() in (\".csv\", \".jsonl\", \".ndjson\"):\n",
    "            try:\n",
    "                df = _read_table(p)\n",
    "                if df is not None and len(df) > 0:\n",
    "                    collapse_tables[(d.name, fname)] = df\n",
    "            except Exception:\n",
    "                pass\n",
    "\n",
    "print(\"Loaded ClsCollapseLogger artifacts from:\")\n",
    "for d in fold_dirs:\n",
    "    print(\" \", d)\n",
    "\n",
    "print(f\"  JSON blobs : {len(collapse_json)}\")\n",
    "print(f\"  Tables     : {len(collapse_tables)}\")\n",
    "\n",
    "if collapse_tables:\n",
    "    by_dir = {}\n",
    "    for (dname, fname), df in collapse_tables.items():\n",
    "        by_dir.setdefault(dname, []).append((fname, df))\n",
    "\n",
    "    for dname in sorted(by_dir):\n",
    "        print(f\"\\n{dname} tables:\")\n",
    "        for fname, df in sorted(by_dir[dname], key=lambda x: x[0]):\n",
    "            print(f\"  - {fname} | shape={df.shape} | cols={list(df.columns)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be951a4c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fold</th>\n",
       "      <th>epoch</th>\n",
       "      <th>global_step</th>\n",
       "      <th>lr</th>\n",
       "      <th>loss_mask_bce</th>\n",
       "      <th>loss_mask_dice</th>\n",
       "      <th>loss_mask_cls</th>\n",
       "      <th>loss_presence</th>\n",
       "      <th>loss_auth_penalty</th>\n",
       "      <th>loss_total</th>\n",
       "      <th>w_mask_cls</th>\n",
       "      <th>w_presence</th>\n",
       "      <th>w_auth_penalty</th>\n",
       "      <th>train_topk</th>\n",
       "      <th>train_min_mask_mass</th>\n",
       "      <th>few_queries_lambda</th>\n",
       "      <th>presence_lse_beta</th>\n",
       "      <th>_source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>64725.000000</td>\n",
       "      <td>64725.000000</td>\n",
       "      <td>64725.000000</td>\n",
       "      <td>6.472500e+04</td>\n",
       "      <td>64725.000000</td>\n",
       "      <td>64725.000000</td>\n",
       "      <td>64725.000000</td>\n",
       "      <td>64725.000000</td>\n",
       "      <td>64725.000000</td>\n",
       "      <td>64725.000000</td>\n",
       "      <td>64725.0</td>\n",
       "      <td>64725.0</td>\n",
       "      <td>64725.0</td>\n",
       "      <td>64725.0</td>\n",
       "      <td>6.472500e+04</td>\n",
       "      <td>6.472500e+04</td>\n",
       "      <td>64725.0</td>\n",
       "      <td>64725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>step_losses.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>64725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>10787.000000</td>\n",
       "      <td>1.000000e-04</td>\n",
       "      <td>0.310516</td>\n",
       "      <td>0.745509</td>\n",
       "      <td>0.498729</td>\n",
       "      <td>1.099827</td>\n",
       "      <td>0.013820</td>\n",
       "      <td>3.216599</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.000000e-03</td>\n",
       "      <td>1.000000e-01</td>\n",
       "      <td>10.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.816503</td>\n",
       "      <td>7.211158</td>\n",
       "      <td>6228.214135</td>\n",
       "      <td>2.710526e-20</td>\n",
       "      <td>0.329115</td>\n",
       "      <td>0.242005</td>\n",
       "      <td>0.145361</td>\n",
       "      <td>0.788796</td>\n",
       "      <td>0.012046</td>\n",
       "      <td>0.853073</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.505263e-19</td>\n",
       "      <td>1.387790e-17</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000e-04</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.000000e-03</td>\n",
       "      <td>1.000000e-01</td>\n",
       "      <td>10.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>5393.000000</td>\n",
       "      <td>1.000000e-04</td>\n",
       "      <td>0.184798</td>\n",
       "      <td>0.660113</td>\n",
       "      <td>0.412201</td>\n",
       "      <td>0.666896</td>\n",
       "      <td>0.005463</td>\n",
       "      <td>2.805620</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.000000e-03</td>\n",
       "      <td>1.000000e-01</td>\n",
       "      <td>10.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>10787.000000</td>\n",
       "      <td>1.000000e-04</td>\n",
       "      <td>0.285838</td>\n",
       "      <td>0.810492</td>\n",
       "      <td>0.492221</td>\n",
       "      <td>0.980698</td>\n",
       "      <td>0.011385</td>\n",
       "      <td>3.216248</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.000000e-03</td>\n",
       "      <td>1.000000e-01</td>\n",
       "      <td>10.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>3.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>16181.000000</td>\n",
       "      <td>1.000000e-04</td>\n",
       "      <td>0.401725</td>\n",
       "      <td>0.921236</td>\n",
       "      <td>0.578559</td>\n",
       "      <td>1.379670</td>\n",
       "      <td>0.019410</td>\n",
       "      <td>3.597664</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.000000e-03</td>\n",
       "      <td>1.000000e-01</td>\n",
       "      <td>10.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>3.000000</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>21574.000000</td>\n",
       "      <td>1.000000e-04</td>\n",
       "      <td>58.729385</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.693875</td>\n",
       "      <td>13.544704</td>\n",
       "      <td>0.540405</td>\n",
       "      <td>64.789963</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.000000e-03</td>\n",
       "      <td>1.000000e-01</td>\n",
       "      <td>10.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                fold         epoch   global_step            lr  loss_mask_bce  \\\n",
       "count   64725.000000  64725.000000  64725.000000  6.472500e+04   64725.000000   \n",
       "unique           NaN           NaN           NaN           NaN            NaN   \n",
       "top              NaN           NaN           NaN           NaN            NaN   \n",
       "freq             NaN           NaN           NaN           NaN            NaN   \n",
       "mean        2.000000     13.000000  10787.000000  1.000000e-04       0.310516   \n",
       "std         0.816503      7.211158   6228.214135  2.710526e-20       0.329115   \n",
       "min         1.000000      1.000000      0.000000  1.000000e-04      -0.000000   \n",
       "25%         1.000000      7.000000   5393.000000  1.000000e-04       0.184798   \n",
       "50%         2.000000     13.000000  10787.000000  1.000000e-04       0.285838   \n",
       "75%         3.000000     19.000000  16181.000000  1.000000e-04       0.401725   \n",
       "max         3.000000     25.000000  21574.000000  1.000000e-04      58.729385   \n",
       "\n",
       "        loss_mask_dice  loss_mask_cls  loss_presence  loss_auth_penalty  \\\n",
       "count     64725.000000   64725.000000   64725.000000       64725.000000   \n",
       "unique             NaN            NaN            NaN                NaN   \n",
       "top                NaN            NaN            NaN                NaN   \n",
       "freq               NaN            NaN            NaN                NaN   \n",
       "mean          0.745509       0.498729       1.099827           0.013820   \n",
       "std           0.242005       0.145361       0.788796           0.012046   \n",
       "min          -0.000000       0.000000       0.000001           0.000000   \n",
       "25%           0.660113       0.412201       0.666896           0.005463   \n",
       "50%           0.810492       0.492221       0.980698           0.011385   \n",
       "75%           0.921236       0.578559       1.379670           0.019410   \n",
       "max           1.000000       1.693875      13.544704           0.540405   \n",
       "\n",
       "          loss_total  w_mask_cls  w_presence  w_auth_penalty  train_topk  \\\n",
       "count   64725.000000     64725.0     64725.0         64725.0     64725.0   \n",
       "unique           NaN         NaN         NaN             NaN         NaN   \n",
       "top              NaN         NaN         NaN             NaN         NaN   \n",
       "freq             NaN         NaN         NaN             NaN         NaN   \n",
       "mean        3.216599         2.0         1.0             1.0         2.0   \n",
       "std         0.853073         0.0         0.0             0.0         0.0   \n",
       "min         0.000001         2.0         1.0             1.0         2.0   \n",
       "25%         2.805620         2.0         1.0             1.0         2.0   \n",
       "50%         3.216248         2.0         1.0             1.0         2.0   \n",
       "75%         3.597664         2.0         1.0             1.0         2.0   \n",
       "max        64.789963         2.0         1.0             1.0         2.0   \n",
       "\n",
       "        train_min_mask_mass  few_queries_lambda  presence_lse_beta  \\\n",
       "count          6.472500e+04        6.472500e+04            64725.0   \n",
       "unique                  NaN                 NaN                NaN   \n",
       "top                     NaN                 NaN                NaN   \n",
       "freq                    NaN                 NaN                NaN   \n",
       "mean           1.000000e-03        1.000000e-01               10.0   \n",
       "std            6.505263e-19        1.387790e-17                0.0   \n",
       "min            1.000000e-03        1.000000e-01               10.0   \n",
       "25%            1.000000e-03        1.000000e-01               10.0   \n",
       "50%            1.000000e-03        1.000000e-01               10.0   \n",
       "75%            1.000000e-03        1.000000e-01               10.0   \n",
       "max            1.000000e-03        1.000000e-01               10.0   \n",
       "\n",
       "                _source  \n",
       "count             64725  \n",
       "unique                1  \n",
       "top     step_losses.csv  \n",
       "freq              64725  \n",
       "mean                NaN  \n",
       "std                 NaN  \n",
       "min                 NaN  \n",
       "25%                 NaN  \n",
       "50%                 NaN  \n",
       "75%                 NaN  \n",
       "max                 NaN  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Convenience: key summaries across ALL loaded debug tables\n",
    "\n",
    "def concat_tables(name_contains: str):\n",
    "    dfs = []\n",
    "    for (fold_key, fname), df in collapse_tables.items():\n",
    "        if name_contains.lower() in fname.lower():\n",
    "            d = df.copy()\n",
    "            m = re.search(r\"(\\d+)\", str(fold_key))\n",
    "            d[\"fold\"] = int(m.group(1)) if m else fold_key  # cv_oof_summary stays as string\n",
    "            d[\"_source\"] = fname\n",
    "            dfs.append(d)\n",
    "    return pd.concat(dfs, ignore_index=True) if dfs else pd.DataFrame()\n",
    "\n",
    "\n",
    "step_losses = concat_tables(\"step\")\n",
    "epoch_summary = concat_tables(\"epoch\")\n",
    "debug_events = concat_tables(\"debug\")\n",
    "\n",
    "if len(step_losses):\n",
    "    display(step_losses.describe(include=\"all\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "1315f2ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fold</th>\n",
       "      <th>epoch</th>\n",
       "      <th>loss_mask_bce</th>\n",
       "      <th>loss_mask_dice</th>\n",
       "      <th>loss_mask_cls</th>\n",
       "      <th>loss_presence</th>\n",
       "      <th>loss_auth_penalty</th>\n",
       "      <th>loss_total</th>\n",
       "      <th>w_mask_cls</th>\n",
       "      <th>w_presence</th>\n",
       "      <th>w_auth_penalty</th>\n",
       "      <th>train_topk</th>\n",
       "      <th>train_min_mask_mass</th>\n",
       "      <th>few_queries_lambda</th>\n",
       "      <th>presence_lse_beta</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.407937</td>\n",
       "      <td>0.825026</td>\n",
       "      <td>0.594661</td>\n",
       "      <td>1.344462</td>\n",
       "      <td>0.024248</td>\n",
       "      <td>3.870088</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.1</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.368904</td>\n",
       "      <td>0.808481</td>\n",
       "      <td>0.574134</td>\n",
       "      <td>1.231361</td>\n",
       "      <td>0.020726</td>\n",
       "      <td>3.647260</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.1</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0.334583</td>\n",
       "      <td>0.791110</td>\n",
       "      <td>0.546058</td>\n",
       "      <td>1.161948</td>\n",
       "      <td>0.018502</td>\n",
       "      <td>3.460578</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.1</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0.323764</td>\n",
       "      <td>0.789866</td>\n",
       "      <td>0.532816</td>\n",
       "      <td>1.141793</td>\n",
       "      <td>0.016952</td>\n",
       "      <td>3.396384</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.1</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0.318889</td>\n",
       "      <td>0.777187</td>\n",
       "      <td>0.532457</td>\n",
       "      <td>1.143835</td>\n",
       "      <td>0.016510</td>\n",
       "      <td>3.378649</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.1</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>3</td>\n",
       "      <td>21</td>\n",
       "      <td>0.291118</td>\n",
       "      <td>0.763312</td>\n",
       "      <td>0.521120</td>\n",
       "      <td>1.091111</td>\n",
       "      <td>0.013011</td>\n",
       "      <td>3.249529</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.1</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>3</td>\n",
       "      <td>22</td>\n",
       "      <td>0.291577</td>\n",
       "      <td>0.753193</td>\n",
       "      <td>0.518273</td>\n",
       "      <td>1.100211</td>\n",
       "      <td>0.013010</td>\n",
       "      <td>3.242660</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.1</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>3</td>\n",
       "      <td>23</td>\n",
       "      <td>0.296144</td>\n",
       "      <td>0.749786</td>\n",
       "      <td>0.519641</td>\n",
       "      <td>1.094558</td>\n",
       "      <td>0.012776</td>\n",
       "      <td>3.240298</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.1</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>3</td>\n",
       "      <td>24</td>\n",
       "      <td>0.292971</td>\n",
       "      <td>0.756273</td>\n",
       "      <td>0.519412</td>\n",
       "      <td>1.079054</td>\n",
       "      <td>0.012367</td>\n",
       "      <td>3.226629</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.1</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>3</td>\n",
       "      <td>25</td>\n",
       "      <td>0.291766</td>\n",
       "      <td>0.760181</td>\n",
       "      <td>0.526326</td>\n",
       "      <td>1.093918</td>\n",
       "      <td>0.012631</td>\n",
       "      <td>3.259515</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.1</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>75 rows  15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    fold  epoch  loss_mask_bce  loss_mask_dice  loss_mask_cls  loss_presence  \\\n",
       "0      1      1       0.407937        0.825026       0.594661       1.344462   \n",
       "1      1      2       0.368904        0.808481       0.574134       1.231361   \n",
       "2      1      3       0.334583        0.791110       0.546058       1.161948   \n",
       "3      1      4       0.323764        0.789866       0.532816       1.141793   \n",
       "4      1      5       0.318889        0.777187       0.532457       1.143835   \n",
       "..   ...    ...            ...             ...            ...            ...   \n",
       "70     3     21       0.291118        0.763312       0.521120       1.091111   \n",
       "71     3     22       0.291577        0.753193       0.518273       1.100211   \n",
       "72     3     23       0.296144        0.749786       0.519641       1.094558   \n",
       "73     3     24       0.292971        0.756273       0.519412       1.079054   \n",
       "74     3     25       0.291766        0.760181       0.526326       1.093918   \n",
       "\n",
       "    loss_auth_penalty  loss_total  w_mask_cls  w_presence  w_auth_penalty  \\\n",
       "0            0.024248    3.870088         2.0         1.0             1.0   \n",
       "1            0.020726    3.647260         2.0         1.0             1.0   \n",
       "2            0.018502    3.460578         2.0         1.0             1.0   \n",
       "3            0.016952    3.396384         2.0         1.0             1.0   \n",
       "4            0.016510    3.378649         2.0         1.0             1.0   \n",
       "..                ...         ...         ...         ...             ...   \n",
       "70           0.013011    3.249529         2.0         1.0             1.0   \n",
       "71           0.013010    3.242660         2.0         1.0             1.0   \n",
       "72           0.012776    3.240298         2.0         1.0             1.0   \n",
       "73           0.012367    3.226629         2.0         1.0             1.0   \n",
       "74           0.012631    3.259515         2.0         1.0             1.0   \n",
       "\n",
       "    train_topk  train_min_mask_mass  few_queries_lambda  presence_lse_beta  \n",
       "0          2.0                0.001                 0.1               10.0  \n",
       "1          2.0                0.001                 0.1               10.0  \n",
       "2          2.0                0.001                 0.1               10.0  \n",
       "3          2.0                0.001                 0.1               10.0  \n",
       "4          2.0                0.001                 0.1               10.0  \n",
       "..         ...                  ...                 ...                ...  \n",
       "70         2.0                0.001                 0.1               10.0  \n",
       "71         2.0                0.001                 0.1               10.0  \n",
       "72         2.0                0.001                 0.1               10.0  \n",
       "73         2.0                0.001                 0.1               10.0  \n",
       "74         2.0                0.001                 0.1               10.0  \n",
       "\n",
       "[75 rows x 15 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Epoch-aggregated losses (mean over steps, per fold  epoch)\n",
    "# Updated to match collapse_logger.log_step_losses payload (loss_presence, w_presence, + train knobs)\n",
    "\n",
    "loss_cols = [\n",
    "    \"loss_mask_bce\",\n",
    "    \"loss_mask_dice\",\n",
    "    \"loss_mask_cls\",\n",
    "    \"loss_presence\",\n",
    "    \"loss_auth_penalty\",\n",
    "    \"loss_total\",\n",
    "]\n",
    "\n",
    "# (optional but useful) epoch-constant knobs / weights to aggregate too\n",
    "meta_cols = [\n",
    "    \"w_mask_cls\",\n",
    "    \"w_presence\",\n",
    "    \"w_auth_penalty\",\n",
    "    \"train_topk\",\n",
    "    \"train_min_mask_mass\",\n",
    "    \"few_queries_lambda\",\n",
    "    \"presence_lse_beta\",\n",
    "]\n",
    "\n",
    "cols = [c for c in (loss_cols + meta_cols) if c in step_losses.columns]\n",
    "\n",
    "epoch_losses = (\n",
    "    step_losses\n",
    "    .groupby([\"fold\", \"epoch\"], as_index=False)[cols]\n",
    "    .mean()\n",
    "    .sort_values([\"fold\", \"epoch\"])\n",
    ")\n",
    "\n",
    "display(epoch_losses)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "e1e35d8b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fold</th>\n",
       "      <th>epoch</th>\n",
       "      <th>epoch_loss</th>\n",
       "      <th>qscore_max_mean</th>\n",
       "      <th>qscore_max_p95</th>\n",
       "      <th>qscore_max_over_sum_mean</th>\n",
       "      <th>num_qscore_gt_0.05</th>\n",
       "      <th>num_qscore_gt_0.10</th>\n",
       "      <th>num_qscore_gt_0.20</th>\n",
       "      <th>mask_mass_max_mean</th>\n",
       "      <th>mask_max_mean</th>\n",
       "      <th>w_mask_cls</th>\n",
       "      <th>w_presence</th>\n",
       "      <th>few_queries_lambda</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>25</td>\n",
       "      <td>3.122826</td>\n",
       "      <td>0.002941</td>\n",
       "      <td>0.005844</td>\n",
       "      <td>0.067024</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.038293</td>\n",
       "      <td>0.837488</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>25</td>\n",
       "      <td>2.299850</td>\n",
       "      <td>0.185046</td>\n",
       "      <td>0.358027</td>\n",
       "      <td>0.905793</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.295917</td>\n",
       "      <td>0.759146</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>25</td>\n",
       "      <td>3.259189</td>\n",
       "      <td>0.007472</td>\n",
       "      <td>0.011360</td>\n",
       "      <td>0.066669</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.051049</td>\n",
       "      <td>0.952716</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fold  epoch  epoch_loss  qscore_max_mean  qscore_max_p95  \\\n",
       "0     1     25    3.122826         0.002941        0.005844   \n",
       "1     2     25    2.299850         0.185046        0.358027   \n",
       "2     3     25    3.259189         0.007472        0.011360   \n",
       "\n",
       "   qscore_max_over_sum_mean  num_qscore_gt_0.05  num_qscore_gt_0.10  \\\n",
       "0                  0.067024                 0.0                0.00   \n",
       "1                  0.905793                 1.0                0.75   \n",
       "2                  0.066669                 0.0                0.00   \n",
       "\n",
       "   num_qscore_gt_0.20  mask_mass_max_mean  mask_max_mean  w_mask_cls  \\\n",
       "0                 0.0            0.038293       0.837488         2.0   \n",
       "1                 0.5            0.295917       0.759146         2.0   \n",
       "2                 0.0            0.051049       0.952716         2.0   \n",
       "\n",
       "   w_presence  few_queries_lambda  \n",
       "0         1.0                 0.1  \n",
       "1         1.0                 0.1  \n",
       "2         1.0                 0.1  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>qscore_max_mean</th>\n",
       "      <td>0.065153</td>\n",
       "      <td>1.038551e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>few_queries_lambda</th>\n",
       "      <td>0.100000</td>\n",
       "      <td>1.699675e-17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>qscore_max_p95</th>\n",
       "      <td>0.125077</td>\n",
       "      <td>2.017596e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mask_mass_max_mean</th>\n",
       "      <td>0.128420</td>\n",
       "      <td>1.451971e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>num_qscore_gt_0.20</th>\n",
       "      <td>0.166667</td>\n",
       "      <td>2.886751e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>num_qscore_gt_0.10</th>\n",
       "      <td>0.250000</td>\n",
       "      <td>4.330127e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>num_qscore_gt_0.05</th>\n",
       "      <td>0.333333</td>\n",
       "      <td>5.773503e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>qscore_max_over_sum_mean</th>\n",
       "      <td>0.346495</td>\n",
       "      <td>4.843657e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mask_max_mean</th>\n",
       "      <td>0.849783</td>\n",
       "      <td>9.736880e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>w_presence</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>w_mask_cls</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>epoch_loss</th>\n",
       "      <td>2.893955</td>\n",
       "      <td>5.190081e-01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              mean           std\n",
       "qscore_max_mean           0.065153  1.038551e-01\n",
       "few_queries_lambda        0.100000  1.699675e-17\n",
       "qscore_max_p95            0.125077  2.017596e-01\n",
       "mask_mass_max_mean        0.128420  1.451971e-01\n",
       "num_qscore_gt_0.20        0.166667  2.886751e-01\n",
       "num_qscore_gt_0.10        0.250000  4.330127e-01\n",
       "num_qscore_gt_0.05        0.333333  5.773503e-01\n",
       "qscore_max_over_sum_mean  0.346495  4.843657e-01\n",
       "mask_max_mean             0.849783  9.736880e-02\n",
       "w_presence                1.000000  0.000000e+00\n",
       "w_mask_cls                2.000000  0.000000e+00\n",
       "epoch_loss                2.893955  5.190081e-01"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fold</th>\n",
       "      <th>epoch</th>\n",
       "      <th>q_dead</th>\n",
       "      <th>sparse_dead</th>\n",
       "      <th>mask_dead</th>\n",
       "      <th>dominance_bad</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>1</td>\n",
       "      <td>25</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>2</td>\n",
       "      <td>25</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>3</td>\n",
       "      <td>25</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    fold  epoch  q_dead  sparse_dead  mask_dead  dominance_bad\n",
       "24     1     25    True         True      False           True\n",
       "49     2     25   False        False      False          False\n",
       "74     3     25    True         True      False           True"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>corr_with_epoch</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>epoch_loss</th>\n",
       "      <td>-0.588075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mask_max_mean</th>\n",
       "      <td>-0.195587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>num_qscore_gt_0.05</th>\n",
       "      <td>-0.158643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mask_mass_max_mean</th>\n",
       "      <td>0.173120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>qscore_max_mean</th>\n",
       "      <td>0.229482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>qscore_max_p95</th>\n",
       "      <td>0.306586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>num_qscore_gt_0.20</th>\n",
       "      <td>0.307798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>num_qscore_gt_0.10</th>\n",
       "      <td>0.337919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>qscore_max_over_sum_mean</th>\n",
       "      <td>0.378679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>w_mask_cls</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>w_presence</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>few_queries_lambda</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          corr_with_epoch\n",
       "epoch_loss                      -0.588075\n",
       "mask_max_mean                   -0.195587\n",
       "num_qscore_gt_0.05              -0.158643\n",
       "mask_mass_max_mean               0.173120\n",
       "qscore_max_mean                  0.229482\n",
       "qscore_max_p95                   0.306586\n",
       "num_qscore_gt_0.20               0.307798\n",
       "num_qscore_gt_0.10               0.337919\n",
       "qscore_max_over_sum_mean         0.378679\n",
       "w_mask_cls                            NaN\n",
       "w_presence                            NaN\n",
       "few_queries_lambda                    NaN"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# --- Useful, compact diagnostics for epoch_summary ---\n",
    "\n",
    "es = epoch_summary.copy()\n",
    "\n",
    "num_cols = [\n",
    "    \"epoch_loss\",\n",
    "    # qscore-focused signals\n",
    "    \"qscore_max_mean\", \"qscore_max_p95\", \"qscore_max_over_sum_mean\",\n",
    "    \"num_qscore_gt_0.05\", \"num_qscore_gt_0.10\", \"num_qscore_gt_0.20\",\n",
    "    # mask signals\n",
    "    \"mask_mass_max_mean\", \"mask_max_mean\",\n",
    "    # knobs/weights logged\n",
    "    \"w_mask_cls\", \"w_presence\", \"few_queries_lambda\",\n",
    "]\n",
    "for c in num_cols:\n",
    "    if c in es.columns:\n",
    "        es[c] = pd.to_numeric(es[c], errors=\"coerce\")\n",
    "\n",
    "present_cols = [c for c in num_cols if c in es.columns]\n",
    "\n",
    "last_epoch = (\n",
    "    es.sort_values([\"fold\", \"epoch\"])\n",
    "      .groupby(\"fold\", as_index=False)\n",
    "      .tail(1)\n",
    "      .sort_values(\"fold\")\n",
    ")\n",
    "\n",
    "# Per-fold last-epoch snapshot\n",
    "display(\n",
    "    last_epoch[[\"fold\", \"epoch\"] + present_cols]\n",
    "      .sort_values(\"fold\")\n",
    "      .reset_index(drop=True)\n",
    ")\n",
    "\n",
    "# Cross-fold mean/std at last epoch\n",
    "agg = last_epoch[present_cols].agg([\"mean\", \"std\"]).T\n",
    "agg.columns = [\"mean\", \"std\"]\n",
    "display(agg.sort_values(\"mean\"))\n",
    "\n",
    "# Quick red-flag table at last epoch (qscore-era)\n",
    "flags = last_epoch.assign(\n",
    "    q_dead   = last_epoch.get(\"qscore_max_p95\", np.nan) < 0.05,\n",
    "    sparse_dead = last_epoch.get(\"num_qscore_gt_0.10\", np.nan) < 0.5,   # ~no queries above 0.10 on avg\n",
    "    mask_dead = last_epoch.get(\"mask_mass_max_mean\", np.nan) < 0.01,    # masks never get any mass\n",
    "    dominance_bad = last_epoch.get(\"qscore_max_over_sum_mean\", np.nan) < 0.6,  # no single winner\n",
    ").loc[:, [\"fold\", \"epoch\", \"q_dead\", \"sparse_dead\", \"mask_dead\", \"dominance_bad\"]]\n",
    "display(flags)\n",
    "\n",
    "# Trend vs epoch (pooled across folds): corr with epoch\n",
    "trend_cols = [\"epoch\"] + present_cols\n",
    "trend_corr = (\n",
    "    es[trend_cols]\n",
    "      .corr(numeric_only=True)[\"epoch\"]\n",
    "      .drop(\"epoch\")\n",
    "      .sort_values()\n",
    ")\n",
    "display(trend_corr.to_frame(\"corr_with_epoch\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "bf6aa621",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "debug_events shape: (905963, 64)\n",
      "cols: ['tag', 'fold', 'epoch', 'global_step', 'img_label', 'masks_shape', 'masks_sum', 'per_image', 'mask_probs', 'class_probs', 'b', 'Q', 'Hm', 'Wm', 'tgt_shape', 'tgt_numel', 'tgt_sum', 'allowed_q', 'matched', 'reason', 'B', 'pos', 'total', 'pos_frac', 'weights_sum', 'weights_mean', 'presence_mean', 'presence_min', 'presence_max', 'loss_presence', 'presence_lse_beta', 'train_topk', 'train_min_mask_mass', 'allowed_queries_per_image', 'qscore_max', 'qscore_sum', 'qscore_max_over_sum', 'mask_mass_max', 'batch', 'fg_prob_per_query', 'fg_prob_mean', 'fg_prob_p95', 'fg_prob_max', 'authentic_frac', 'per_image_penalty_mean', 'loss_auth_penalty', 'few_queries_lambda', 'loss_few_queries', 'cost_shape', 'num_gt', 'Qa', 'val_samples', 'masks_empty', 'gate_fail', 'num_keep0', 'cls_filtered_all_fg', 'no_fg_pre_keep', 'rates', 'max_cls_prob', 'max_mask_prob', 'pred_auth_frac', 'pred_non_auth_count', 'pred_non_auth_area_ratio_mean', '_source']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fold</th>\n",
       "      <th>val_samples</th>\n",
       "      <th>masks_empty</th>\n",
       "      <th>gate_fail</th>\n",
       "      <th>num_keep0</th>\n",
       "      <th>cls_filtered_all_fg</th>\n",
       "      <th>no_fg_pre_keep</th>\n",
       "      <th>rates</th>\n",
       "      <th>max_cls_prob</th>\n",
       "      <th>max_mask_prob</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>301952</th>\n",
       "      <td>1</td>\n",
       "      <td>1726.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>189.0</td>\n",
       "      <td>{'masks_empty': 0.01738122827346466, 'gate_fai...</td>\n",
       "      <td>{'mean': 0.07681334763765335, 'p95': 0.0768138...</td>\n",
       "      <td>{'mean': 0.8750499486923218, 'p95': 0.99999666...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>603956</th>\n",
       "      <td>2</td>\n",
       "      <td>1725.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>139.0</td>\n",
       "      <td>{'masks_empty': 0.06956521739130435, 'gate_fai...</td>\n",
       "      <td>{'mean': 0.6723968982696533, 'p95': 0.67358940...</td>\n",
       "      <td>{'mean': 0.8971885442733765, 'p95': 1.0, 'max'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>905960</th>\n",
       "      <td>3</td>\n",
       "      <td>1725.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>{'masks_empty': 0.0, 'gate_fail': 0.0, 'num_ke...</td>\n",
       "      <td>{'mean': 0.14636604487895966, 'p95': 0.1463660...</td>\n",
       "      <td>{'mean': 0.8955227732658386, 'p95': 0.99992275...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       fold  val_samples  masks_empty  gate_fail  num_keep0  \\\n",
       "301952    1       1726.0         30.0        0.0       30.0   \n",
       "603956    2       1725.0        120.0        0.0      120.0   \n",
       "905960    3       1725.0          0.0        0.0        0.0   \n",
       "\n",
       "        cls_filtered_all_fg  no_fg_pre_keep  \\\n",
       "301952                  0.0           189.0   \n",
       "603956                 27.0           139.0   \n",
       "905960                  0.0            52.0   \n",
       "\n",
       "                                                    rates  \\\n",
       "301952  {'masks_empty': 0.01738122827346466, 'gate_fai...   \n",
       "603956  {'masks_empty': 0.06956521739130435, 'gate_fai...   \n",
       "905960  {'masks_empty': 0.0, 'gate_fail': 0.0, 'num_ke...   \n",
       "\n",
       "                                             max_cls_prob  \\\n",
       "301952  {'mean': 0.07681334763765335, 'p95': 0.0768138...   \n",
       "603956  {'mean': 0.6723968982696533, 'p95': 0.67358940...   \n",
       "905960  {'mean': 0.14636604487895966, 'p95': 0.1463660...   \n",
       "\n",
       "                                            max_mask_prob  \n",
       "301952  {'mean': 0.8750499486923218, 'p95': 0.99999666...  \n",
       "603956  {'mean': 0.8971885442733765, 'p95': 1.0, 'max'...  \n",
       "905960  {'mean': 0.8955227732658386, 'p95': 0.99992275...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== OOF inference debug summary (per fold) ===\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fold</th>\n",
       "      <th>val_samples</th>\n",
       "      <th>masks_empty</th>\n",
       "      <th>gate_fail</th>\n",
       "      <th>num_keep0</th>\n",
       "      <th>cls_filtered_all_fg</th>\n",
       "      <th>no_fg_pre_keep</th>\n",
       "      <th>rates.masks_empty</th>\n",
       "      <th>rates.gate_fail</th>\n",
       "      <th>rates.num_keep0</th>\n",
       "      <th>rates.cls_filtered_all_fg</th>\n",
       "      <th>rates.no_fg_pre_keep</th>\n",
       "      <th>max_cls_prob.mean</th>\n",
       "      <th>max_cls_prob.p95</th>\n",
       "      <th>max_cls_prob.max</th>\n",
       "      <th>max_mask_prob.mean</th>\n",
       "      <th>max_mask_prob.p95</th>\n",
       "      <th>max_mask_prob.max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>301952</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1726.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>189.0</td>\n",
       "      <td>0.017381</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.017381</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.109502</td>\n",
       "      <td>0.076813</td>\n",
       "      <td>0.076814</td>\n",
       "      <td>0.076814</td>\n",
       "      <td>0.875050</td>\n",
       "      <td>0.999997</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>603956</th>\n",
       "      <td>2.0</td>\n",
       "      <td>1725.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>139.0</td>\n",
       "      <td>0.069565</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.069565</td>\n",
       "      <td>0.015652</td>\n",
       "      <td>0.080580</td>\n",
       "      <td>0.672397</td>\n",
       "      <td>0.673589</td>\n",
       "      <td>0.673594</td>\n",
       "      <td>0.897189</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>905960</th>\n",
       "      <td>3.0</td>\n",
       "      <td>1725.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.030145</td>\n",
       "      <td>0.146366</td>\n",
       "      <td>0.146366</td>\n",
       "      <td>0.146366</td>\n",
       "      <td>0.895523</td>\n",
       "      <td>0.999923</td>\n",
       "      <td>0.999997</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        fold  val_samples  masks_empty  gate_fail  num_keep0  \\\n",
       "301952   1.0       1726.0         30.0        0.0       30.0   \n",
       "603956   2.0       1725.0        120.0        0.0      120.0   \n",
       "905960   3.0       1725.0          0.0        0.0        0.0   \n",
       "\n",
       "        cls_filtered_all_fg  no_fg_pre_keep  rates.masks_empty  \\\n",
       "301952                  0.0           189.0           0.017381   \n",
       "603956                 27.0           139.0           0.069565   \n",
       "905960                  0.0            52.0           0.000000   \n",
       "\n",
       "        rates.gate_fail  rates.num_keep0  rates.cls_filtered_all_fg  \\\n",
       "301952              0.0         0.017381                   0.000000   \n",
       "603956              0.0         0.069565                   0.015652   \n",
       "905960              0.0         0.000000                   0.000000   \n",
       "\n",
       "        rates.no_fg_pre_keep  max_cls_prob.mean  max_cls_prob.p95  \\\n",
       "301952              0.109502           0.076813          0.076814   \n",
       "603956              0.080580           0.672397          0.673589   \n",
       "905960              0.030145           0.146366          0.146366   \n",
       "\n",
       "        max_cls_prob.max  max_mask_prob.mean  max_mask_prob.p95  \\\n",
       "301952          0.076814            0.875050           0.999997   \n",
       "603956          0.673594            0.897189           1.000000   \n",
       "905960          0.146366            0.895523           0.999923   \n",
       "\n",
       "        max_mask_prob.max  \n",
       "301952           1.000000  \n",
       "603956           1.000000  \n",
       "905960           0.999997  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== OOF inference debug summary (global weighted failure rates) ===\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>weighted_rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>masks_empty</th>\n",
       "      <td>0.028980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gate_fail</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>num_keep0</th>\n",
       "      <td>0.028980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cls_filtered_all_fg</th>\n",
       "      <td>0.005216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>no_fg_pre_keep</th>\n",
       "      <td>0.073416</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     weighted_rate\n",
       "masks_empty               0.028980\n",
       "gate_fail                 0.000000\n",
       "num_keep0                 0.028980\n",
       "cls_filtered_all_fg       0.005216\n",
       "no_fg_pre_keep            0.073416"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Presence stats (loss_presence_stats: last epoch per fold + mean/std) ===\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fold</th>\n",
       "      <th>epoch</th>\n",
       "      <th>presence_mean</th>\n",
       "      <th>presence_min</th>\n",
       "      <th>presence_max</th>\n",
       "      <th>loss_presence</th>\n",
       "      <th>presence_lse_beta</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>301948</th>\n",
       "      <td>1.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>0.153276</td>\n",
       "      <td>0.068686</td>\n",
       "      <td>0.237865</td>\n",
       "      <td>1.474919</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>603952</th>\n",
       "      <td>2.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>0.486748</td>\n",
       "      <td>0.230641</td>\n",
       "      <td>0.623679</td>\n",
       "      <td>0.813338</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>905956</th>\n",
       "      <td>3.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>0.159525</td>\n",
       "      <td>0.031258</td>\n",
       "      <td>0.313145</td>\n",
       "      <td>1.949915</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        fold  epoch  presence_mean  presence_min  presence_max  loss_presence  \\\n",
       "301948   1.0   25.0       0.153276      0.068686      0.237865       1.474919   \n",
       "603952   2.0   25.0       0.486748      0.230641      0.623679       0.813338   \n",
       "905956   3.0   25.0       0.159525      0.031258      0.313145       1.949915   \n",
       "\n",
       "        presence_lse_beta  \n",
       "301948               10.0  \n",
       "603952               10.0  \n",
       "905956               10.0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>presence_mean</th>\n",
       "      <td>0.266516</td>\n",
       "      <td>0.190752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>presence_min</th>\n",
       "      <td>0.110195</td>\n",
       "      <td>0.105974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>presence_max</th>\n",
       "      <td>0.391563</td>\n",
       "      <td>0.204512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>loss_presence</th>\n",
       "      <td>1.412724</td>\n",
       "      <td>0.570835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>presence_lse_beta</th>\n",
       "      <td>10.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        mean       std\n",
       "presence_mean       0.266516  0.190752\n",
       "presence_min        0.110195  0.105974\n",
       "presence_max        0.391563  0.204512\n",
       "loss_presence       1.412724  0.570835\n",
       "presence_lse_beta  10.000000  0.000000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Auth penalty + few-queries stats (loss_auth_penalty_stats: last epoch per fold + mean/std) ===\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fold</th>\n",
       "      <th>epoch</th>\n",
       "      <th>authentic_frac</th>\n",
       "      <th>per_image_penalty_mean</th>\n",
       "      <th>loss_auth_penalty</th>\n",
       "      <th>few_queries_lambda</th>\n",
       "      <th>loss_few_queries</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>301951</th>\n",
       "      <td>1.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.020213</td>\n",
       "      <td>0.013065</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.303201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>603955</th>\n",
       "      <td>2.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.040178</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.602668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>905959</th>\n",
       "      <td>3.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.025910</td>\n",
       "      <td>0.010645</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.388653</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        fold  epoch  authentic_frac  per_image_penalty_mean  \\\n",
       "301951   1.0   25.0        0.500000                0.020213   \n",
       "603955   2.0   25.0        0.000000                0.040178   \n",
       "905959   3.0   25.0        0.333333                0.025910   \n",
       "\n",
       "        loss_auth_penalty  few_queries_lambda  loss_few_queries  \n",
       "301951           0.013065                 0.1          0.303201  \n",
       "603955           0.000000                 0.1          0.602668  \n",
       "905959           0.010645                 0.1          0.388653  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>authentic_frac</th>\n",
       "      <td>0.277778</td>\n",
       "      <td>2.545875e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>per_image_penalty_mean</th>\n",
       "      <td>0.028767</td>\n",
       "      <td>1.028430e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>loss_auth_penalty</th>\n",
       "      <td>0.007904</td>\n",
       "      <td>6.950797e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>few_queries_lambda</th>\n",
       "      <td>0.100000</td>\n",
       "      <td>1.699675e-17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>loss_few_queries</th>\n",
       "      <td>0.431507</td>\n",
       "      <td>1.542645e-01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            mean           std\n",
       "authentic_frac          0.277778  2.545875e-01\n",
       "per_image_penalty_mean  0.028767  1.028430e-02\n",
       "loss_auth_penalty       0.007904  6.950797e-03\n",
       "few_queries_lambda      0.100000  1.699675e-17\n",
       "loss_few_queries        0.431507  1.542645e-01"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Class-target balance (loss_cls_targets) ===\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"4\" halign=\"left\">pos</th>\n",
       "      <th colspan=\"4\" halign=\"left\">total</th>\n",
       "      <th colspan=\"4\" halign=\"left\">pos_frac</th>\n",
       "      <th colspan=\"4\" halign=\"left\">weights_sum</th>\n",
       "      <th colspan=\"4\" halign=\"left\">weights_mean</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>max</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>max</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>max</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>max</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fold</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1.0</th>\n",
       "      <td>2.841530</td>\n",
       "      <td>1.476260</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>59.965238</td>\n",
       "      <td>1.020644</td>\n",
       "      <td>30.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.047382</td>\n",
       "      <td>0.024608</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>10.038227</td>\n",
       "      <td>3.165466</td>\n",
       "      <td>0.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>0.167391</td>\n",
       "      <td>0.052714</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2.0</th>\n",
       "      <td>2.860440</td>\n",
       "      <td>1.483989</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>59.982619</td>\n",
       "      <td>0.510322</td>\n",
       "      <td>45.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.047685</td>\n",
       "      <td>0.024734</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>10.022468</td>\n",
       "      <td>3.213174</td>\n",
       "      <td>1.5</td>\n",
       "      <td>21.0</td>\n",
       "      <td>0.167083</td>\n",
       "      <td>0.053536</td>\n",
       "      <td>0.025</td>\n",
       "      <td>0.35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3.0</th>\n",
       "      <td>2.796477</td>\n",
       "      <td>1.520408</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>59.982619</td>\n",
       "      <td>0.510322</td>\n",
       "      <td>45.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.046620</td>\n",
       "      <td>0.025343</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>9.869803</td>\n",
       "      <td>3.441238</td>\n",
       "      <td>0.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>0.164542</td>\n",
       "      <td>0.057349</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.35</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           pos                          total                        pos_frac  \\\n",
       "          mean       std  min  max       mean       std   min   max      mean   \n",
       "fold                                                                            \n",
       "1.0   2.841530  1.476260  0.0  8.0  59.965238  1.020644  30.0  60.0  0.047382   \n",
       "2.0   2.860440  1.483989  0.0  8.0  59.982619  0.510322  45.0  60.0  0.047685   \n",
       "3.0   2.796477  1.520408  0.0  8.0  59.982619  0.510322  45.0  60.0  0.046620   \n",
       "\n",
       "                              weights_sum                      weights_mean  \\\n",
       "           std  min       max        mean       std  min   max         mean   \n",
       "fold                                                                          \n",
       "1.0   0.024608  0.0  0.133333   10.038227  3.165466  0.0  21.0     0.167391   \n",
       "2.0   0.024734  0.0  0.133333   10.022468  3.213174  1.5  21.0     0.167083   \n",
       "3.0   0.025343  0.0  0.133333    9.869803  3.441238  0.0  21.0     0.164542   \n",
       "\n",
       "                             \n",
       "           std    min   max  \n",
       "fold                         \n",
       "1.0   0.052714  0.000  0.35  \n",
       "2.0   0.053536  0.025  0.35  \n",
       "3.0   0.057349  0.000  0.35  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Hungarian matching input health (hungarian_match_input) ===\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fold</th>\n",
       "      <th>epoch</th>\n",
       "      <th>b</th>\n",
       "      <th>Q</th>\n",
       "      <th>Hm</th>\n",
       "      <th>Wm</th>\n",
       "      <th>tgt_shape</th>\n",
       "      <th>tgt_numel</th>\n",
       "      <th>tgt_sum</th>\n",
       "      <th>allowed_q</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>258800.000000</td>\n",
       "      <td>258800.000000</td>\n",
       "      <td>258800.000000</td>\n",
       "      <td>258800.0</td>\n",
       "      <td>258800.0</td>\n",
       "      <td>258800.0</td>\n",
       "      <td>258800</td>\n",
       "      <td>258800.000000</td>\n",
       "      <td>258800.000000</td>\n",
       "      <td>258800.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[0, 256, 256]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>118850</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2.000097</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>1.499517</td>\n",
       "      <td>15.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>49493.860896</td>\n",
       "      <td>1986.291924</td>\n",
       "      <td>1.965522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.816478</td>\n",
       "      <td>7.211116</td>\n",
       "      <td>1.117950</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>55922.759045</td>\n",
       "      <td>3843.413167</td>\n",
       "      <td>0.242104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>15.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>15.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>15.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>65536.000000</td>\n",
       "      <td>212.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>3.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>15.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>65536.000000</td>\n",
       "      <td>2262.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>3.000000</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>15.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>851968.000000</td>\n",
       "      <td>34445.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 fold          epoch              b         Q        Hm  \\\n",
       "count   258800.000000  258800.000000  258800.000000  258800.0  258800.0   \n",
       "unique            NaN            NaN            NaN       NaN       NaN   \n",
       "top               NaN            NaN            NaN       NaN       NaN   \n",
       "freq              NaN            NaN            NaN       NaN       NaN   \n",
       "mean         2.000097      13.000000       1.499517      15.0      64.0   \n",
       "std          0.816478       7.211116       1.117950       0.0       0.0   \n",
       "min          1.000000       1.000000       0.000000      15.0      64.0   \n",
       "25%          1.000000       7.000000       0.000000      15.0      64.0   \n",
       "50%          2.000000      13.000000       1.000000      15.0      64.0   \n",
       "75%          3.000000      19.000000       2.000000      15.0      64.0   \n",
       "max          3.000000      25.000000       3.000000      15.0      64.0   \n",
       "\n",
       "              Wm      tgt_shape      tgt_numel        tgt_sum      allowed_q  \n",
       "count   258800.0         258800  258800.000000  258800.000000  258800.000000  \n",
       "unique       NaN              8            NaN            NaN            NaN  \n",
       "top          NaN  [0, 256, 256]            NaN            NaN            NaN  \n",
       "freq         NaN         118850            NaN            NaN            NaN  \n",
       "mean        64.0            NaN   49493.860896    1986.291924       1.965522  \n",
       "std          0.0            NaN   55922.759045    3843.413167       0.242104  \n",
       "min         64.0            NaN       0.000000       0.000000       0.000000  \n",
       "25%         64.0            NaN       0.000000       0.000000       2.000000  \n",
       "50%         64.0            NaN   65536.000000     212.000000       2.000000  \n",
       "75%         64.0            NaN   65536.000000    2262.000000       2.000000  \n",
       "max         64.0            NaN  851968.000000   34445.000000       2.000000  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Hungarian matching results (hungarian_match_result) ===\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fold</th>\n",
       "      <th>reason</th>\n",
       "      <th>rows</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>empty_gt</td>\n",
       "      <td>39625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>no_allowed_queries</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>46610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.0</td>\n",
       "      <td>empty_gt</td>\n",
       "      <td>39600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0</td>\n",
       "      <td>no_allowed_queries</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>46671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3.0</td>\n",
       "      <td>empty_gt</td>\n",
       "      <td>39625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>3.0</td>\n",
       "      <td>no_allowed_queries</td>\n",
       "      <td>955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>45695</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fold              reason   rows\n",
       "0   1.0            empty_gt  39625\n",
       "1   1.0  no_allowed_queries     15\n",
       "2   1.0                 NaN  46610\n",
       "3   2.0            empty_gt  39600\n",
       "4   2.0  no_allowed_queries      4\n",
       "5   2.0                 NaN  46671\n",
       "6   3.0            empty_gt  39625\n",
       "7   3.0  no_allowed_queries    955\n",
       "8   3.0                 NaN  45695"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fold</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1.0</th>\n",
       "      <td>0.710794</td>\n",
       "      <td>0.739154</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2.0</th>\n",
       "      <td>0.715317</td>\n",
       "      <td>0.743214</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3.0</th>\n",
       "      <td>0.699322</td>\n",
       "      <td>0.741373</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          mean       std  min  max\n",
       "fold                              \n",
       "1.0   0.710794  0.739154  0.0  2.0\n",
       "2.0   0.715317  0.743214  0.0  2.0\n",
       "3.0   0.699322  0.741373  0.0  2.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Sparsity metrics (sparsity_metrics: last epoch per fold + mean/std) ===\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fold</th>\n",
       "      <th>epoch</th>\n",
       "      <th>train_topk</th>\n",
       "      <th>train_min_mask_mass</th>\n",
       "      <th>batch.allowed_mean</th>\n",
       "      <th>batch.qmax_over_sum_mean</th>\n",
       "      <th>batch.mask_mass_max_mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>301949</th>\n",
       "      <td>1.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.001</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.456128</td>\n",
       "      <td>0.245239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>603953</th>\n",
       "      <td>2.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.001</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.857641</td>\n",
       "      <td>0.765814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>905957</th>\n",
       "      <td>3.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.001</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.360996</td>\n",
       "      <td>0.278748</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        fold  epoch  train_topk  train_min_mask_mass  batch.allowed_mean  \\\n",
       "301949   1.0   25.0         2.0                0.001                 2.0   \n",
       "603953   2.0   25.0         2.0                0.001                 2.0   \n",
       "905957   3.0   25.0         2.0                0.001                 2.0   \n",
       "\n",
       "        batch.qmax_over_sum_mean  batch.mask_mass_max_mean  \n",
       "301949                  0.456128                  0.245239  \n",
       "603953                  0.857641                  0.765814  \n",
       "905957                  0.360996                  0.278748  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>train_topk</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>train_min_mask_mass</th>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>batch.allowed_mean</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>batch.qmax_over_sum_mean</th>\n",
       "      <td>0.558255</td>\n",
       "      <td>0.263603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>batch.mask_mass_max_mean</th>\n",
       "      <td>0.429934</td>\n",
       "      <td>0.291363</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              mean       std\n",
       "train_topk                2.000000  0.000000\n",
       "train_min_mask_mass       0.001000  0.000000\n",
       "batch.allowed_mean        2.000000  0.000000\n",
       "batch.qmax_over_sum_mean  0.558255  0.263603\n",
       "batch.mask_mass_max_mean  0.429934  0.291363"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Mask-head liveness during training (train_fg_prob_per_query: last epoch) ===\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fold</th>\n",
       "      <th>epoch</th>\n",
       "      <th>Q</th>\n",
       "      <th>fg_prob_mean</th>\n",
       "      <th>fg_prob_p95</th>\n",
       "      <th>fg_prob_max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>301950</th>\n",
       "      <td>1.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0.069483</td>\n",
       "      <td>0.170437</td>\n",
       "      <td>0.216940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>603954</th>\n",
       "      <td>2.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0.077963</td>\n",
       "      <td>0.352658</td>\n",
       "      <td>0.765814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>905958</th>\n",
       "      <td>3.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0.105286</td>\n",
       "      <td>0.148209</td>\n",
       "      <td>0.163300</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        fold  epoch     Q  fg_prob_mean  fg_prob_p95  fg_prob_max\n",
       "301950   1.0   25.0  15.0      0.069483     0.170437     0.216940\n",
       "603954   2.0   25.0  15.0      0.077963     0.352658     0.765814\n",
       "905958   3.0   25.0  15.0      0.105286     0.148209     0.163300"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Mask-head per-query foreground distribution (last epoch, exploded) ===\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fold</th>\n",
       "      <th>mean</th>\n",
       "      <th>p95</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.069483</td>\n",
       "      <td>0.170437</td>\n",
       "      <td>0.216940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.0</td>\n",
       "      <td>0.077963</td>\n",
       "      <td>0.352658</td>\n",
       "      <td>0.765814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.0</td>\n",
       "      <td>0.105286</td>\n",
       "      <td>0.148209</td>\n",
       "      <td>0.163300</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fold      mean       p95       max\n",
       "0   1.0  0.069483  0.170437  0.216940\n",
       "1   2.0  0.077963  0.352658  0.765814\n",
       "2   3.0  0.105286  0.148209  0.163300"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== One-time logits/probability sanity snapshots (debug_probs) ===\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fold</th>\n",
       "      <th>epoch</th>\n",
       "      <th>global_step</th>\n",
       "      <th>mask_probs.mean</th>\n",
       "      <th>mask_probs.p95</th>\n",
       "      <th>mask_probs.max</th>\n",
       "      <th>mask_probs.frac_gt_0p5</th>\n",
       "      <th>class_probs.mean</th>\n",
       "      <th>class_probs.max</th>\n",
       "      <th>class_probs.frac_gt_0p1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.318666</td>\n",
       "      <td>0.905690</td>\n",
       "      <td>0.999982</td>\n",
       "      <td>0.274247</td>\n",
       "      <td>0.351825</td>\n",
       "      <td>0.404392</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>301956</th>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.072798</td>\n",
       "      <td>0.369959</td>\n",
       "      <td>0.999991</td>\n",
       "      <td>0.033879</td>\n",
       "      <td>0.617093</td>\n",
       "      <td>0.706293</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>603960</th>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.588462</td>\n",
       "      <td>0.995040</td>\n",
       "      <td>0.999995</td>\n",
       "      <td>0.599947</td>\n",
       "      <td>0.527064</td>\n",
       "      <td>0.603328</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        fold  epoch  global_step  mask_probs.mean  mask_probs.p95  \\\n",
       "2        1.0    1.0          0.0         0.318666        0.905690   \n",
       "301956   2.0    1.0          0.0         0.072798        0.369959   \n",
       "603960   3.0    1.0          0.0         0.588462        0.995040   \n",
       "\n",
       "        mask_probs.max  mask_probs.frac_gt_0p5  class_probs.mean  \\\n",
       "2             0.999982                0.274247          0.351825   \n",
       "301956        0.999991                0.033879          0.617093   \n",
       "603960        0.999995                0.599947          0.527064   \n",
       "\n",
       "        class_probs.max  class_probs.frac_gt_0p1  \n",
       "2              0.404392                      1.0  \n",
       "301956         0.706293                      1.0  \n",
       "603960         0.603328                      1.0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== OOF prediction distribution + area stats (oof_pred_area_stats) ===\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fold</th>\n",
       "      <th>val_samples</th>\n",
       "      <th>pred_auth_frac</th>\n",
       "      <th>pred_non_auth_count</th>\n",
       "      <th>pred_non_auth_area_ratio_mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>301953</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1726.0</td>\n",
       "      <td>0.017381</td>\n",
       "      <td>1696.0</td>\n",
       "      <td>0.041473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>603957</th>\n",
       "      <td>2.0</td>\n",
       "      <td>1725.0</td>\n",
       "      <td>0.069565</td>\n",
       "      <td>1605.0</td>\n",
       "      <td>0.580539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>905961</th>\n",
       "      <td>3.0</td>\n",
       "      <td>1725.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1725.0</td>\n",
       "      <td>0.044859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>905962</th>\n",
       "      <td>NaN</td>\n",
       "      <td>5176.0</td>\n",
       "      <td>0.028980</td>\n",
       "      <td>5026.0</td>\n",
       "      <td>0.214781</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        fold  val_samples  pred_auth_frac  pred_non_auth_count  \\\n",
       "301953   1.0       1726.0        0.017381               1696.0   \n",
       "603957   2.0       1725.0        0.069565               1605.0   \n",
       "905961   3.0       1725.0        0.000000               1725.0   \n",
       "905962   NaN       5176.0        0.028980               5026.0   \n",
       "\n",
       "        pred_non_auth_area_ratio_mean  \n",
       "301953                       0.041473  \n",
       "603957                       0.580539  \n",
       "905961                       0.044859  \n",
       "905962                       0.214781  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# --- Load ALL debug events (UPDATED for current collapse logger + train_cv tags) ---\n",
    "\n",
    "dbg = debug_events.copy() if \"debug_events\" in globals() else pd.DataFrame()\n",
    "print(\"debug_events shape:\", dbg.shape)\n",
    "print(\"cols:\", list(dbg.columns))\n",
    "\n",
    "if len(dbg) == 0:\n",
    "    raise ValueError(\"debug_events is empty\")\n",
    "\n",
    "# sanity check: OOF inference debug payload (per-fold, aggregated)\n",
    "oof_raw = dbg[dbg[\"tag\"].astype(str).eq(\"oof_inference_debug\")]\n",
    "show0 = [c for c in [\n",
    "    \"fold\",\"val_samples\",\n",
    "    \"masks_empty\",\"gate_fail\",\"num_keep0\",\"cls_filtered_all_fg\",\"no_fg_pre_keep\",\n",
    "    \"rates\",\"max_cls_prob\",\"max_mask_prob\",\n",
    "] if c in oof_raw.columns]\n",
    "display(oof_raw[show0].head(10))\n",
    "\n",
    "# ---------- helpers ----------\n",
    "def _to_bool(s):\n",
    "    if s.dtype == object:\n",
    "        return s.astype(str).str.lower().isin([\"true\", \"1\", \"yes\"])\n",
    "    return s.astype(bool)\n",
    "\n",
    "def _safe_num(df, cols):\n",
    "    for c in cols:\n",
    "        if c in df.columns:\n",
    "            df[c] = pd.to_numeric(df[c], errors=\"coerce\")\n",
    "    return df\n",
    "\n",
    "def _flatten_dict_col(df, col, prefix=None):\n",
    "    \"\"\"Flatten a dict-valued column into separate columns, preserving row alignment.\"\"\"\n",
    "    if col not in df.columns:\n",
    "        return df\n",
    "    pfx = prefix or col\n",
    "\n",
    "    ser = df[col]\n",
    "    mask = ser.apply(lambda x: isinstance(x, dict))\n",
    "    if not mask.any():\n",
    "        return df\n",
    "\n",
    "    flat = pd.json_normalize(ser[mask])\n",
    "    flat.index = ser[mask].index  # align with original rows\n",
    "    flat.columns = [f\"{pfx}.{k}\" for k in flat.columns]\n",
    "\n",
    "    df = df.drop(columns=[col])\n",
    "    df = df.join(flat, how=\"left\")\n",
    "    return df\n",
    "\n",
    "def p95(x):\n",
    "    x = pd.to_numeric(x, errors=\"coerce\").dropna()\n",
    "    return float(x.quantile(0.95)) if len(x) else np.nan\n",
    "\n",
    "# ---------- flatten nested dict payloads ----------\n",
    "# train_cv emits nested dicts for these tags\n",
    "for col in [\"rates\", \"mask_probs\", \"class_probs\", \"img_probs\", \"max_cls_prob\", \"max_mask_prob\", \"batch\", \"per_image\"]:\n",
    "    dbg = _flatten_dict_col(dbg, col)\n",
    "\n",
    "# ---------- coerce numerics (aligned to current emitted keys) ----------\n",
    "dbg = _safe_num(\n",
    "    dbg,\n",
    "    [\n",
    "        # common\n",
    "        \"fold\",\"epoch\",\"global_step\",\"b\",\"i\",\"B\",\"Q\",\"Hm\",\"Wm\",\n",
    "        \"img_label\",\"val_samples\",\n",
    "\n",
    "        # oof_inference_debug counts\n",
    "        \"masks_empty\",\"gate_fail\",\"num_keep0\",\"cls_filtered_all_fg\",\"no_fg_pre_keep\",\n",
    "\n",
    "        # oof_inference_debug flattened\n",
    "        \"rates.masks_empty\",\"rates.gate_fail\",\"rates.num_keep0\",\"rates.cls_filtered_all_fg\",\"rates.no_fg_pre_keep\",\n",
    "        \"max_cls_prob.mean\",\"max_cls_prob.p95\",\"max_cls_prob.max\",\n",
    "        \"max_mask_prob.mean\",\"max_mask_prob.p95\",\"max_mask_prob.max\",\n",
    "\n",
    "        # batch_target0 / mask_target_sanity / debug_probs\n",
    "        \"masks_sum\",\n",
    "        \"mask_probs.mean\",\"mask_probs.p95\",\"mask_probs.max\",\"mask_probs.frac_gt_0p5\",\n",
    "        \"class_probs.mean\",\"class_probs.max\",\"class_probs.frac_gt_0p1\",\n",
    "\n",
    "        # hungarian matching\n",
    "        \"tgt_numel\",\"tgt_sum\",\"allowed_q\",\"matched\",\"num_gt\",\"Qa\",\n",
    "\n",
    "        # loss_cls_targets\n",
    "        \"pos\",\"total\",\"pos_frac\",\"weights_sum\",\"weights_mean\",\n",
    "\n",
    "        # loss_presence_stats (from compute_losses)\n",
    "        \"presence_mean\",\"presence_min\",\"presence_max\",\"loss_presence\",\"presence_lse_beta\",\n",
    "\n",
    "        # sparsity_metrics (from compute_losses)\n",
    "        \"train_topk\",\"train_min_mask_mass\",\n",
    "        \"batch.allowed_mean\",\"batch.qmax_over_sum_mean\",\"batch.mask_mass_max_mean\",\n",
    "\n",
    "        # train_fg_prob_per_query (from compute_losses)\n",
    "        \"fg_prob_mean\",\"fg_prob_p95\",\"fg_prob_max\",\n",
    "\n",
    "        # loss_auth_penalty_stats (from compute_losses)\n",
    "        \"authentic_frac\",\"per_image_penalty_mean\",\"loss_auth_penalty\",\"few_queries_lambda\",\"loss_few_queries\",\n",
    "\n",
    "        # oof_pred_area_stats (from train_cv)\n",
    "        \"pred_auth_frac\",\"pred_non_auth_count\",\"pred_non_auth_area_ratio_mean\",\n",
    "    ],\n",
    ")\n",
    "\n",
    "# bool-ish flags (only include if present in your dbg)\n",
    "for c in [\"gate_pass\",\"any_fg_pre_keep\",\"any_fg_post_keep\"]:\n",
    "    if c in dbg.columns:\n",
    "        dbg[c] = _to_bool(dbg[c])\n",
    "\n",
    "\n",
    "# ---------- OOF inference debug summary (tag == oof_inference_debug) ----------\n",
    "print(\"\\n=== OOF inference debug summary (per fold) ===\")\n",
    "oof = dbg[dbg[\"tag\"].astype(str).eq(\"oof_inference_debug\")].copy()\n",
    "if len(oof):\n",
    "    show_cols = [c for c in [\n",
    "        \"fold\",\"val_samples\",\n",
    "        \"masks_empty\",\"gate_fail\",\"num_keep0\",\"cls_filtered_all_fg\",\"no_fg_pre_keep\",\n",
    "        \"rates.masks_empty\",\"rates.gate_fail\",\"rates.num_keep0\",\"rates.cls_filtered_all_fg\",\"rates.no_fg_pre_keep\",\n",
    "        \"max_cls_prob.mean\",\"max_cls_prob.p95\",\"max_cls_prob.max\",\n",
    "        \"max_mask_prob.mean\",\"max_mask_prob.p95\",\"max_mask_prob.max\",\n",
    "    ] if c in oof.columns]\n",
    "    display(oof.sort_values(\"fold\")[show_cols])\n",
    "\n",
    "    # global weighted failure rates across folds\n",
    "    print(\"\\n=== OOF inference debug summary (global weighted failure rates) ===\")\n",
    "    denom = oof[\"val_samples\"].astype(float).replace(0, np.nan)\n",
    "    global_rates = {}\n",
    "    for k in [\"masks_empty\",\"gate_fail\",\"num_keep0\",\"cls_filtered_all_fg\",\"no_fg_pre_keep\"]:\n",
    "        if k in oof.columns:\n",
    "            global_rates[k] = float(oof[k].astype(float).sum() / denom.sum())\n",
    "    display(pd.Series(global_rates, name=\"weighted_rate\").to_frame())\n",
    "\n",
    "\n",
    "# ---------- Presence stats (tag == loss_presence_stats) ----------\n",
    "print(\"\\n=== Presence stats (loss_presence_stats: last epoch per fold + mean/std) ===\")\n",
    "pres = dbg[dbg[\"tag\"].astype(str).eq(\"loss_presence_stats\")].copy()\n",
    "if len(pres):\n",
    "    cols = [c for c in [\n",
    "        \"fold\",\"epoch\",\"presence_mean\",\"presence_min\",\"presence_max\",\"loss_presence\",\"presence_lse_beta\"\n",
    "    ] if c in pres.columns]\n",
    "    per_fold_last = (pres.sort_values([\"fold\",\"epoch\"]).groupby(\"fold\", as_index=False).tail(1))[cols]\n",
    "    display(per_fold_last.sort_values(\"fold\"))\n",
    "    display(per_fold_last.drop(columns=[\"fold\",\"epoch\"], errors=\"ignore\").agg([\"mean\",\"std\"]).T)\n",
    "\n",
    "\n",
    "# ---------- Auth penalty + few-queries stats (tag == loss_auth_penalty_stats) ----------\n",
    "print(\"\\n=== Auth penalty + few-queries stats (loss_auth_penalty_stats: last epoch per fold + mean/std) ===\")\n",
    "ap = dbg[dbg[\"tag\"].astype(str).eq(\"loss_auth_penalty_stats\")].copy()\n",
    "if len(ap):\n",
    "    cols = [c for c in [\n",
    "        \"fold\",\"epoch\",\"authentic_frac\",\"per_image_penalty_mean\",\"loss_auth_penalty\",\n",
    "        \"few_queries_lambda\",\"loss_few_queries\"\n",
    "    ] if c in ap.columns]\n",
    "    per_fold_last = (ap.sort_values([\"fold\",\"epoch\"]).groupby(\"fold\", as_index=False).tail(1))[cols]\n",
    "    display(per_fold_last.sort_values(\"fold\"))\n",
    "    display(per_fold_last.drop(columns=[\"fold\",\"epoch\"], errors=\"ignore\").agg([\"mean\",\"std\"]).T)\n",
    "\n",
    "\n",
    "# ---------- Class target balance (tag == loss_cls_targets) ----------\n",
    "print(\"\\n=== Class-target balance (loss_cls_targets) ===\")\n",
    "ct = dbg[dbg[\"tag\"].astype(str).eq(\"loss_cls_targets\")].copy()\n",
    "if len(ct):\n",
    "    cols = [c for c in [\"fold\",\"epoch\",\"B\",\"Q\",\"pos\",\"total\",\"pos_frac\",\"weights_sum\",\"weights_mean\"] if c in ct.columns]\n",
    "    display(\n",
    "        ct[cols]\n",
    "          .groupby(\"fold\", dropna=False)[[c for c in cols if c not in (\"fold\",\"epoch\",\"B\",\"Q\")]]\n",
    "          .agg([\"mean\",\"std\",\"min\",\"max\"])\n",
    "    )\n",
    "\n",
    "\n",
    "# ---------- Hungarian matching health (tags == hungarian_match_*) ----------\n",
    "print(\"\\n=== Hungarian matching input health (hungarian_match_input) ===\")\n",
    "hm_in = dbg[dbg[\"tag\"].astype(str).eq(\"hungarian_match_input\")].copy()\n",
    "hm_out = dbg[dbg[\"tag\"].astype(str).eq(\"hungarian_match_result\")].copy()\n",
    "\n",
    "if len(hm_in):\n",
    "    cols = [c for c in [\"fold\",\"epoch\",\"b\",\"Q\",\"Hm\",\"Wm\",\"tgt_shape\",\"tgt_numel\",\"tgt_sum\",\"allowed_q\"] if c in hm_in.columns]\n",
    "    display(hm_in[cols].describe(include=\"all\"))\n",
    "\n",
    "if len(hm_out):\n",
    "    print(\"\\n=== Hungarian matching results (hungarian_match_result) ===\")\n",
    "    cols = [c for c in [\"fold\",\"epoch\",\"b\",\"matched\",\"num_gt\",\"Q\",\"Qa\",\"reason\",\"cost_shape.0\",\"cost_shape.1\"] if c in hm_out.columns]\n",
    "    if \"reason\" in hm_out.columns:\n",
    "        display(hm_out.groupby([\"fold\",\"reason\"], dropna=False).size().rename(\"rows\").reset_index())\n",
    "    if \"matched\" in hm_out.columns:\n",
    "        display(hm_out.groupby(\"fold\")[\"matched\"].agg([\"mean\",\"std\",\"min\",\"max\"]))\n",
    "\n",
    "\n",
    "# ---------- Sparsity metrics (tag == sparsity_metrics) ----------\n",
    "print(\"\\n=== Sparsity metrics (sparsity_metrics: last epoch per fold + mean/std) ===\")\n",
    "sp = dbg[dbg[\"tag\"].astype(str).eq(\"sparsity_metrics\")].copy()\n",
    "if len(sp):\n",
    "    cols = [c for c in [\n",
    "        \"fold\",\"epoch\",\"train_topk\",\"train_min_mask_mass\",\n",
    "        \"batch.allowed_mean\",\"batch.qmax_over_sum_mean\",\"batch.mask_mass_max_mean\",\n",
    "    ] if c in sp.columns]\n",
    "    per_fold_last = (sp.sort_values([\"fold\",\"epoch\"]).groupby(\"fold\", as_index=False).tail(1))[cols]\n",
    "    display(per_fold_last.sort_values(\"fold\"))\n",
    "    display(per_fold_last.drop(columns=[\"fold\",\"epoch\"], errors=\"ignore\").agg([\"mean\",\"std\"]).T)\n",
    "\n",
    "\n",
    "# ---------- Mask-head alive signal during training (tag == train_fg_prob_per_query) ----------\n",
    "print(\"\\n=== Mask-head liveness during training (train_fg_prob_per_query: last epoch) ===\")\n",
    "fgq = dbg[dbg[\"tag\"].astype(str).eq(\"train_fg_prob_per_query\")].copy()\n",
    "if len(fgq):\n",
    "    cols = [c for c in [\"fold\",\"epoch\",\"Q\",\"fg_prob_mean\",\"fg_prob_p95\",\"fg_prob_max\"] if c in fgq.columns]\n",
    "    per_fold_last = (fgq.sort_values([\"fold\",\"epoch\"]).groupby(\"fold\", as_index=False).tail(1))[cols]\n",
    "    display(per_fold_last.sort_values(\"fold\"))\n",
    "\n",
    "    # fg_prob_per_query is list -> explode if present\n",
    "    if \"fg_prob_per_query\" in fgq.columns:\n",
    "        last = fgq.sort_values([\"fold\",\"epoch\"]).groupby(\"fold\", as_index=False).tail(1)\n",
    "        s = last[[\"fold\",\"epoch\",\"fg_prob_per_query\"]].dropna().explode(\"fg_prob_per_query\")\n",
    "        s[\"fg_prob_per_query\"] = pd.to_numeric(s[\"fg_prob_per_query\"], errors=\"coerce\")\n",
    "        print(\"\\n=== Mask-head per-query foreground distribution (last epoch, exploded) ===\")\n",
    "        display(\n",
    "            s.groupby(\"fold\")[\"fg_prob_per_query\"]\n",
    "             .agg(mean=\"mean\", p95=p95, max=\"max\")\n",
    "             .reset_index()\n",
    "             .sort_values(\"fold\")\n",
    "        )\n",
    "\n",
    "\n",
    "# ---------- One-time logits/prob snapshots (tag == debug_probs) ----------\n",
    "print(\"\\n=== One-time logits/probability sanity snapshots (debug_probs) ===\")\n",
    "dp = dbg[dbg[\"tag\"].astype(str).eq(\"debug_probs\")].copy()\n",
    "if len(dp):\n",
    "    cols = [c for c in dp.columns if c.startswith((\"mask_probs.\",\"class_probs.\",\"img_probs.\"))]\n",
    "    show = [c for c in [\"fold\",\"epoch\",\"global_step\"] if c in dp.columns] + cols\n",
    "    display(dp.sort_values([c for c in [\"fold\",\"epoch\",\"global_step\"] if c in dp.columns]).head(20)[show])\n",
    "\n",
    "\n",
    "# ---------- OOF pred distribution + area stats (tag == oof_pred_area_stats) ----------\n",
    "print(\"\\n=== OOF prediction distribution + area stats (oof_pred_area_stats) ===\")\n",
    "oa = dbg[dbg[\"tag\"].astype(str).eq(\"oof_pred_area_stats\")].copy()\n",
    "if len(oa):\n",
    "    cols = [c for c in [\"fold\",\"val_samples\",\"pred_auth_frac\",\"pred_non_auth_count\",\"pred_non_auth_area_ratio_mean\"] if c in oa.columns]\n",
    "    display(oa.sort_values([c for c in [\"fold\"] if c in oa.columns])[cols])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "ad6efd21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fold</th>\n",
       "      <th>val_samples</th>\n",
       "      <th>rates.masks_empty</th>\n",
       "      <th>rates.num_keep0</th>\n",
       "      <th>rates.no_fg_pre_keep</th>\n",
       "      <th>rates.cls_filtered_all_fg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>301952</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1726.0</td>\n",
       "      <td>0.017381</td>\n",
       "      <td>0.017381</td>\n",
       "      <td>0.109502</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>603956</th>\n",
       "      <td>2.0</td>\n",
       "      <td>1725.0</td>\n",
       "      <td>0.069565</td>\n",
       "      <td>0.069565</td>\n",
       "      <td>0.080580</td>\n",
       "      <td>0.015652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>905960</th>\n",
       "      <td>3.0</td>\n",
       "      <td>1725.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.030145</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        fold  val_samples  rates.masks_empty  rates.num_keep0  \\\n",
       "301952   1.0       1726.0           0.017381         0.017381   \n",
       "603956   2.0       1725.0           0.069565         0.069565   \n",
       "905960   3.0       1725.0           0.000000         0.000000   \n",
       "\n",
       "        rates.no_fg_pre_keep  rates.cls_filtered_all_fg  \n",
       "301952              0.109502                   0.000000  \n",
       "603956              0.080580                   0.015652  \n",
       "905960              0.030145                   0.000000  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>weighted_rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>rates.masks_empty</th>\n",
       "      <td>0.028980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rates.num_keep0</th>\n",
       "      <td>0.028980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rates.no_fg_pre_keep</th>\n",
       "      <td>0.073416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rates.cls_filtered_all_fg</th>\n",
       "      <td>0.005216</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           weighted_rate\n",
       "rates.masks_empty               0.028980\n",
       "rates.num_keep0                 0.028980\n",
       "rates.no_fg_pre_keep            0.073416\n",
       "rates.cls_filtered_all_fg       0.005216"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Explicit view of the 4 rates you care about (per fold + weighted mean)\n",
    "oof = dbg[dbg[\"tag\"].astype(str).eq(\"oof_inference_debug\")].copy()\n",
    "\n",
    "cols = [\"fold\",\"val_samples\",\"rates.masks_empty\",\"rates.num_keep0\",\"rates.no_fg_pre_keep\",\"rates.cls_filtered_all_fg\"]\n",
    "cols = [c for c in cols if c in oof.columns]\n",
    "display(oof.sort_values(\"fold\")[cols])\n",
    "\n",
    "w = oof[\"val_samples\"].astype(float).replace(0, np.nan)\n",
    "rate_cols = [c for c in cols if c.startswith(\"rates.\")]\n",
    "weighted = {c: float((oof[c].astype(float) * w).sum() / w.sum()) for c in rate_cols}\n",
    "display(pd.Series(weighted, name=\"weighted_rate\").to_frame())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "5f8387ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fold</th>\n",
       "      <th>epoch</th>\n",
       "      <th>loss_mask_bce</th>\n",
       "      <th>loss_mask_dice</th>\n",
       "      <th>loss_mask_cls</th>\n",
       "      <th>loss_presence</th>\n",
       "      <th>loss_auth_penalty</th>\n",
       "      <th>loss_total</th>\n",
       "      <th>w_mask_cls</th>\n",
       "      <th>w_presence</th>\n",
       "      <th>w_auth_penalty</th>\n",
       "      <th>val_samples</th>\n",
       "      <th>pred_auth_frac</th>\n",
       "      <th>pred_non_auth_count</th>\n",
       "      <th>pred_non_auth_area_ratio_mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>25</td>\n",
       "      <td>0.298466</td>\n",
       "      <td>0.747724</td>\n",
       "      <td>0.493089</td>\n",
       "      <td>1.035382</td>\n",
       "      <td>0.011144</td>\n",
       "      <td>3.122791</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1726.0</td>\n",
       "      <td>0.017381</td>\n",
       "      <td>1696.0</td>\n",
       "      <td>0.041473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>25</td>\n",
       "      <td>0.270808</td>\n",
       "      <td>0.592168</td>\n",
       "      <td>0.374126</td>\n",
       "      <td>0.648230</td>\n",
       "      <td>0.006792</td>\n",
       "      <td>2.299740</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1725.0</td>\n",
       "      <td>0.069565</td>\n",
       "      <td>1605.0</td>\n",
       "      <td>0.580539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>25</td>\n",
       "      <td>0.291766</td>\n",
       "      <td>0.760181</td>\n",
       "      <td>0.526326</td>\n",
       "      <td>1.093918</td>\n",
       "      <td>0.012631</td>\n",
       "      <td>3.259515</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1725.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1725.0</td>\n",
       "      <td>0.044859</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  fold  epoch  loss_mask_bce  loss_mask_dice  loss_mask_cls  loss_presence  \\\n",
       "0    1     25       0.298466        0.747724       0.493089       1.035382   \n",
       "1    2     25       0.270808        0.592168       0.374126       0.648230   \n",
       "2    3     25       0.291766        0.760181       0.526326       1.093918   \n",
       "\n",
       "   loss_auth_penalty  loss_total  w_mask_cls  w_presence  w_auth_penalty  \\\n",
       "0           0.011144    3.122791         2.0         1.0             1.0   \n",
       "1           0.006792    2.299740         2.0         1.0             1.0   \n",
       "2           0.012631    3.259515         2.0         1.0             1.0   \n",
       "\n",
       "   val_samples  pred_auth_frac  pred_non_auth_count  \\\n",
       "0       1726.0        0.017381               1696.0   \n",
       "1       1725.0        0.069565               1605.0   \n",
       "2       1725.0        0.000000               1725.0   \n",
       "\n",
       "   pred_non_auth_area_ratio_mean  \n",
       "0                       0.041473  \n",
       "1                       0.580539  \n",
       "2                       0.044859  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Join last-epoch losses/weights with OOF behavior summaries (per fold)\n",
    "\n",
    "loss_keep = [\n",
    "    \"fold\",\"epoch\",\n",
    "    \"loss_mask_bce\",\"loss_mask_dice\",\"loss_mask_cls\",\"loss_presence\",\"loss_auth_penalty\",\"loss_total\",\n",
    "    \"w_mask_cls\",\"w_presence\",\"w_auth_penalty\",\n",
    "]\n",
    "loss_keep = [c for c in loss_keep if c in epoch_losses.columns]\n",
    "\n",
    "last_loss = (\n",
    "    epoch_losses.sort_values([\"fold\",\"epoch\"])\n",
    "    .groupby(\"fold\", as_index=False)\n",
    "    .tail(1)[loss_keep]\n",
    ")\n",
    "\n",
    "dbg = debug_events.copy()\n",
    "\n",
    "oof_inf = dbg[dbg[\"tag\"].astype(str).eq(\"oof_inference_debug\")].copy()\n",
    "oof_area = dbg[dbg[\"tag\"].astype(str).eq(\"oof_pred_area_stats\")].copy()\n",
    "\n",
    "# keep only fold-level summary cols\n",
    "oof_inf_cols = [c for c in [\n",
    "    \"fold\",\"val_samples\",\n",
    "    \"rates.num_keep0\",\"rates.gate_fail\",\"rates.masks_empty\",\n",
    "    \"max_cls_prob.p95\",\"max_mask_prob.p95\",\n",
    "] if c in oof_inf.columns]\n",
    "\n",
    "oof_area_cols = [c for c in [\n",
    "    \"fold\",\"pred_auth_frac\",\"pred_non_auth_count\",\"pred_non_auth_area_ratio_mean\",\n",
    "] if c in oof_area.columns]\n",
    "\n",
    "# (flattened cols may not exist if you didn't flatten; fallback to raw)\n",
    "if \"rates.num_keep0\" not in oof_inf.columns and \"rates\" in oof_inf.columns:\n",
    "    oof_inf = pd.concat([oof_inf.drop(columns=[\"rates\"]), pd.json_normalize(oof_inf[\"rates\"]).add_prefix(\"rates.\")], axis=1)\n",
    "\n",
    "if \"max_cls_prob.p95\" not in oof_inf.columns and \"max_cls_prob\" in oof_inf.columns:\n",
    "    oof_inf = pd.concat([oof_inf.drop(columns=[\"max_cls_prob\"]), pd.json_normalize(oof_inf[\"max_cls_prob\"]).add_prefix(\"max_cls_prob.\")], axis=1)\n",
    "\n",
    "if \"max_mask_prob.p95\" not in oof_inf.columns and \"max_mask_prob\" in oof_inf.columns:\n",
    "    oof_inf = pd.concat([oof_inf.drop(columns=[\"max_mask_prob\"]), pd.json_normalize(oof_inf[\"max_mask_prob\"]).add_prefix(\"max_mask_prob.\")], axis=1)\n",
    "\n",
    "oof_inf_cols = [c for c in oof_inf_cols if c in oof_inf.columns]\n",
    "\n",
    "summary = (\n",
    "    last_loss\n",
    "    .merge(oof_inf[oof_inf_cols].drop_duplicates(\"fold\"), on=\"fold\", how=\"left\")\n",
    "    .merge(oof_area[oof_area_cols].drop_duplicates(\"fold\"), on=\"fold\", how=\"left\")\n",
    "    .sort_values(\"fold\")\n",
    "    .reset_index(drop=True)\n",
    ")\n",
    "\n",
    "display(summary)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6a3f5cae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fold</th>\n",
       "      <th>val_samples</th>\n",
       "      <th>masks_empty</th>\n",
       "      <th>gate_fail</th>\n",
       "      <th>num_keep0</th>\n",
       "      <th>cls_filtered_all_fg</th>\n",
       "      <th>no_fg_pre_keep</th>\n",
       "      <th>rates.masks_empty</th>\n",
       "      <th>rates.gate_fail</th>\n",
       "      <th>rates.num_keep0</th>\n",
       "      <th>rates.cls_filtered_all_fg</th>\n",
       "      <th>rates.no_fg_pre_keep</th>\n",
       "      <th>max_cls_prob.mean</th>\n",
       "      <th>max_cls_prob.p95</th>\n",
       "      <th>max_cls_prob.max</th>\n",
       "      <th>max_mask_prob.mean</th>\n",
       "      <th>max_mask_prob.p95</th>\n",
       "      <th>max_mask_prob.max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>224302</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1726.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.082758</td>\n",
       "      <td>0.104919</td>\n",
       "      <td>0.104920</td>\n",
       "      <td>0.843239</td>\n",
       "      <td>0.999987</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>448646</th>\n",
       "      <td>2.0</td>\n",
       "      <td>1725.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.458606</td>\n",
       "      <td>0.791333</td>\n",
       "      <td>0.830455</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>672990</th>\n",
       "      <td>3.0</td>\n",
       "      <td>1725.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.089422</td>\n",
       "      <td>0.089422</td>\n",
       "      <td>0.089422</td>\n",
       "      <td>0.792666</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        fold  val_samples  masks_empty  gate_fail  num_keep0  \\\n",
       "224302   1.0       1726.0          0.0        0.0        0.0   \n",
       "448646   2.0       1725.0          0.0        0.0        0.0   \n",
       "672990   3.0       1725.0          0.0        0.0        0.0   \n",
       "\n",
       "        cls_filtered_all_fg  no_fg_pre_keep  rates.masks_empty  \\\n",
       "224302                  0.0             0.0                0.0   \n",
       "448646                  0.0             0.0                0.0   \n",
       "672990                  0.0             0.0                0.0   \n",
       "\n",
       "        rates.gate_fail  rates.num_keep0  rates.cls_filtered_all_fg  \\\n",
       "224302              0.0              0.0                        0.0   \n",
       "448646              0.0              0.0                        0.0   \n",
       "672990              0.0              0.0                        0.0   \n",
       "\n",
       "        rates.no_fg_pre_keep  max_cls_prob.mean  max_cls_prob.p95  \\\n",
       "224302                   0.0           0.082758          0.104919   \n",
       "448646                   0.0           0.458606          0.791333   \n",
       "672990                   0.0           0.089422          0.089422   \n",
       "\n",
       "        max_cls_prob.max  max_mask_prob.mean  max_mask_prob.p95  \\\n",
       "224302          0.104920            0.843239           0.999987   \n",
       "448646          0.830455            1.000000           1.000000   \n",
       "672990          0.089422            0.792666           1.000000   \n",
       "\n",
       "        max_mask_prob.max  \n",
       "224302                1.0  \n",
       "448646                1.0  \n",
       "672990                1.0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\piiop\\AppData\\Local\\Temp\\ipykernel_24968\\1258777682.py:62: FutureWarning: errors='ignore' is deprecated and will raise in a future version. Use to_numeric without passing `errors` and catch exceptions explicitly instead\n",
      "  oof_area_view[c] = pd.to_numeric(oof_area_view[c], errors=\"ignore\")\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fold</th>\n",
       "      <th>val_samples</th>\n",
       "      <th>pred_auth_frac</th>\n",
       "      <th>pred_non_auth_count</th>\n",
       "      <th>pred_non_auth_area_ratio_mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>224303</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1726.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1726.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>448647</th>\n",
       "      <td>2.0</td>\n",
       "      <td>1725.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1725.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>672991</th>\n",
       "      <td>3.0</td>\n",
       "      <td>1725.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1725.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>672992</th>\n",
       "      <td>NaN</td>\n",
       "      <td>5176.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5176.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        fold  val_samples  pred_auth_frac  pred_non_auth_count  \\\n",
       "224303   1.0       1726.0             0.0               1726.0   \n",
       "448647   2.0       1725.0             0.0               1725.0   \n",
       "672991   3.0       1725.0             0.0               1725.0   \n",
       "672992   NaN       5176.0             0.0               5176.0   \n",
       "\n",
       "        pred_non_auth_area_ratio_mean  \n",
       "224303                            1.0  \n",
       "448647                            1.0  \n",
       "672991                            1.0  \n",
       "672992                            1.0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Fold-level val_loader debug counts (from oof_inference_debug events)\n",
    "def _extract_debug_event(df: pd.DataFrame, tag: str) -> pd.DataFrame:\n",
    "    if df is None or len(df) == 0:\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    # Most common format: columns include [\"tag\", \"payload\", ...]\n",
    "    if \"tag\" in df.columns:\n",
    "        ev = df[df[\"tag\"].astype(str) == tag].copy()\n",
    "    else:\n",
    "        # fallback if tag was flattened into a column name\n",
    "        ev = df.copy()\n",
    "\n",
    "    if len(ev) == 0:\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    if \"payload\" in ev.columns:\n",
    "        # payload is a dict -> flatten\n",
    "        payloads = ev[\"payload\"].tolist()\n",
    "        flat = pd.json_normalize(payloads, sep=\".\")\n",
    "        # preserve fold if present as a top-level col too\n",
    "        return flat\n",
    "    else:\n",
    "        # already flattened\n",
    "        return ev\n",
    "\n",
    "# dbg should already exist from your earlier \"debug*.jsonl\" concat\n",
    "oof_inf = _extract_debug_event(dbg, \"oof_inference_debug\")\n",
    "oof_area = _extract_debug_event(dbg, \"oof_pred_area_stats\")\n",
    "\n",
    "if len(oof_inf) == 0:\n",
    "    print(\"No oof_inference_debug events found in dbg (check debug jsonl ingestion).\")\n",
    "else:\n",
    "    cols = [\n",
    "        \"fold\", \"val_samples\",\n",
    "        \"masks_empty\", \"gate_fail\", \"num_keep0\", \"cls_filtered_all_fg\", \"no_fg_pre_keep\",\n",
    "        \"rates.masks_empty\", \"rates.gate_fail\", \"rates.num_keep0\", \"rates.cls_filtered_all_fg\", \"rates.no_fg_pre_keep\",\n",
    "        \"max_cls_prob.mean\", \"max_cls_prob.p95\", \"max_cls_prob.max\",\n",
    "        \"max_mask_prob.mean\", \"max_mask_prob.p95\", \"max_mask_prob.max\",\n",
    "    ]\n",
    "    keep = [c for c in cols if c in oof_inf.columns]\n",
    "    oof_inf_view = oof_inf[keep].copy()\n",
    "\n",
    "    for c in oof_inf_view.columns:\n",
    "        if c == \"fold\":\n",
    "            continue\n",
    "        try:\n",
    "            oof_inf_view[c] = pd.to_numeric(oof_inf_view[c])\n",
    "        except Exception:\n",
    "            pass\n",
    "\n",
    "    if \"fold\" in oof_inf_view.columns:\n",
    "        oof_inf_view = oof_inf_view.sort_values(\"fold\")\n",
    "\n",
    "    display(oof_inf_view)\n",
    "\n",
    "if len(oof_area):\n",
    "    cols = [\"fold\", \"val_samples\", \"pred_auth_frac\", \"pred_non_auth_count\", \"pred_non_auth_area_ratio_mean\"]\n",
    "    keep = [c for c in cols if c in oof_area.columns]\n",
    "    oof_area_view = oof_area[keep].copy()\n",
    "    for c in oof_area_view.columns:\n",
    "        if c != \"fold\":\n",
    "            oof_area_view[c] = pd.to_numeric(oof_area_view[c], errors=\"ignore\")\n",
    "    oof_area_view = oof_area_view.sort_values(\"fold\") if \"fold\" in oof_area_view.columns else oof_area_view\n",
    "    display(oof_area_view)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "951e6360",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# --- Plots: mask_max_mean, mask_max_p95, cls_max_mean vs epoch ---\n",
    "\n",
    "es_plot = epoch_summary.copy()\n",
    "\n",
    "need = [\"fold\", \"epoch\", \"mask_max_mean\", \"cls_max_mean\"]\n",
    "missing = [c for c in need if c not in es_plot.columns]\n",
    "if missing:\n",
    "    raise ValueError(f\"epoch_summary missing required columns: {missing}\")\n",
    "\n",
    "# coerce numeric\n",
    "for c in [\"fold\", \"epoch\", \"mask_max_mean\", \"cls_max_mean\"]:\n",
    "    es_plot[c] = pd.to_numeric(es_plot[c], errors=\"coerce\")\n",
    "\n",
    "es_plot = es_plot.dropna(subset=[\"epoch\", \"mask_max_mean\", \"cls_max_mean\"])\n",
    "\n",
    "# aggregate across folds per epoch\n",
    "g = es_plot.groupby(\"epoch\", as_index=False).agg(\n",
    "    mask_max_mean=(\"mask_max_mean\", \"mean\"),\n",
    "    mask_max_p95=(\"mask_max_mean\", lambda s: s.quantile(0.95)),\n",
    "    cls_max_mean=(\"cls_max_mean\", \"mean\"),\n",
    ")\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(g[\"epoch\"], g[\"mask_max_mean\"], marker=\"o\", label=\"mask_max_mean\")\n",
    "plt.plot(g[\"epoch\"], g[\"mask_max_p95\"], marker=\"o\", label=\"mask_max_p95 (over folds)\")\n",
    "plt.plot(g[\"epoch\"], g[\"cls_max_mean\"], marker=\"o\", label=\"cls_max_mean\")\n",
    "plt.xlabel(\"epoch\")\n",
    "plt.ylabel(\"value\")\n",
    "plt.title(\"Epoch trends (pooled across folds)\")\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e08e2c02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sanity_random_200 check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "883e8ec8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>rows</th>\n",
       "      <td>200.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>forged_folder_rate</th>\n",
       "      <td>0.545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>image_label_rate</th>\n",
       "      <td>0.545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>any_instances_rate</th>\n",
       "      <td>0.545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean_union_sum</th>\n",
       "      <td>30973.545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean_max_instance_sum</th>\n",
       "      <td>26154.455</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           value\n",
       "rows                     200.000\n",
       "forged_folder_rate         0.545\n",
       "image_label_rate           0.545\n",
       "any_instances_rate         0.545\n",
       "mean_union_sum         30973.545\n",
       "mean_max_instance_sum  26154.455"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "csvs = sorted(SAMPLEDUMP_ROOT.rglob(\"sanity_random_200.csv\"))\n",
    "assert csvs, \"No sanity_random_200.csv found under sanity_dumps\"\n",
    "\n",
    "df = pd.read_csv(csvs[-1])\n",
    "\n",
    "summary = {\n",
    "    \"rows\": len(df),\n",
    "    \"forged_folder_rate\": df[\"is_forged_folder\"].mean(),\n",
    "    \"image_label_rate\": df[\"image_label\"].mean(),\n",
    "    \"any_instances_rate\": (df[\"num_instances\"] > 0).mean(),\n",
    "    \"mean_union_sum\": df[\"union_sum\"].mean(),\n",
    "    \"mean_max_instance_sum\": df[\"max_instance_sum\"].mean(),\n",
    "}\n",
    "\n",
    "display(pd.Series(summary, name=\"value\").to_frame())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "af122e99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>image_label</th>\n",
       "      <th>0.0</th>\n",
       "      <th>1.0</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>is_forged_folder</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>False</th>\n",
       "      <td>91</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <td>0</td>\n",
       "      <td>109</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "image_label       0.0  1.0\n",
       "is_forged_folder          \n",
       "False              91    0\n",
       "True                0  109"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cross-tab: are forged-folder images ever labeled authentic?\n",
    "pd.crosstab(df[\"is_forged_folder\"], df[\"image_label\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bb1cd480",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# How often do we have forged-folder but zero instances?\n",
    "df.query(\"is_forged_folder == True and num_instances == 0\").shape[0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
