{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "67e6b406",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cv_analysis.ipynb\n",
    "\n",
    "import json\n",
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from ipywidgets import Dropdown, HBox, IntSlider, VBox, interact\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "PROJECT_ROOT = Path(\"..\").resolve()\n",
    "\n",
    "if str(PROJECT_ROOT) not in sys.path:\n",
    "    sys.path.insert(0, str(PROJECT_ROOT))\n",
    "\n",
    "from src.data.dataloader import (\n",
    "    ForgeryDataset,\n",
    "    detection_collate_fn,\n",
    "    get_val_transform,\n",
    ")\n",
    "from src.models.mask2former_v1 import Mask2FormerForgeryModel\n",
    "from src.utils.config_utils import load_yaml, sanitize_model_kwargs\n",
    "\n",
    "plt.style.use(\"ggplot\")\n",
    "\n",
    "# -----------------\n",
    "# Constants / Paths\n",
    "# -----------------\n",
    "\n",
    "OOF_ROOT = PROJECT_ROOT / \"experiments\" / \"oof_results\"\n",
    "FULL_TRAIN_ROOT = PROJECT_ROOT / \"experiments\" / \"full_train_results\"\n",
    "\n",
    "CLS_THRESHOLD_PATH = (\n",
    "    PROJECT_ROOT / \"experiments\" / \"cls_threshold_sweep\" / \"cls_threshold_sweep.csv\"\n",
    ")\n",
    "\n",
    "WEIGHTS = PROJECT_ROOT / \"weights\" / \"full_train\" / \"model_full_data_baseline.pth\"\n",
    "\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "CFG_PATH = PROJECT_ROOT / \"config\" / \"base.yaml\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d693608",
   "metadata": {},
   "source": [
    "### OOF CV results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "a5c26d53",
   "metadata": {},
   "outputs": [],
   "source": [
    "def available_runs(root=OOF_ROOT):\n",
    "    # only directories that actually look like CV runs\n",
    "    return [\n",
    "        p.name\n",
    "        for p in root.iterdir()\n",
    "        if p.is_dir() and (p / \"oof_predictions.csv\").exists()\n",
    "    ]\n",
    "\n",
    "def load_run(run_name):\n",
    "    run_dir = OOF_ROOT / run_name\n",
    "    oof_csv = run_dir / \"oof_predictions.csv\"\n",
    "    metrics_json = run_dir / \"oof_metrics.json\"\n",
    "\n",
    "    oof_df = pd.read_csv(oof_csv)\n",
    "    with metrics_json.open() as f:\n",
    "        metrics = json.load(f)\n",
    "\n",
    "    # Optionally load per-fold CSVs\n",
    "    fold_files = sorted(run_dir.glob(\"fold_*_oof.csv\"))\n",
    "    fold_dfs = {f.stem: pd.read_csv(f) for f in fold_files}\n",
    "\n",
    "    return oof_df, metrics, fold_dfs\n",
    "\n",
    "\n",
    "def load_full_train_results(root=FULL_TRAIN_ROOT):\n",
    "    \"\"\"\n",
    "    Expected structure:\n",
    "        experiments/full_train_results/\n",
    "            run_A/\n",
    "                val_predictions.csv\n",
    "                metrics.json\n",
    "            run_B/\n",
    "                ...\n",
    "    \"\"\"\n",
    "    if not root.exists():\n",
    "        return {}\n",
    "    runs = {}\n",
    "    for sub in root.iterdir():\n",
    "        if not sub.is_dir():\n",
    "            continue\n",
    "        preds = sub / \"val_predictions.csv\"\n",
    "        met = sub / \"metrics.json\"\n",
    "        if preds.exists() and met.exists():\n",
    "            runs[sub.name] = {\n",
    "                \"predictions\": pd.read_csv(preds),\n",
    "                \"metrics\": json.load(open(met)),\n",
    "            }\n",
    "    return runs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "03a67ab1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV Runs: ['mini_smoke']\n",
      "Full-train Runs: []\n"
     ]
    }
   ],
   "source": [
    "cv_runs = available_runs()\n",
    "full_train_runs = load_full_train_results()\n",
    "\n",
    "print(\"CV Runs:\", cv_runs)\n",
    "print(\"Full-train Runs:\", list(full_train_runs.keys()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "4dc43695",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e0442aa8da634741ae09085f27b03e37",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Dropdown(description='CV Run:', options=('mini_smoke',), value='mini_smoke')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "run_dropdown = Dropdown(options=cv_runs, description=\"CV Run:\")\n",
    "display(run_dropdown)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "eba815e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6793e7ad85cc40468a90b964f1b19e9d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Dropdown(description='CV Run:', options=('mini_smoke',), value='mini_smoke'), Output()),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.show_run_metrics(run_name)>"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def show_run_metrics(run_name):\n",
    "    oof_df, metrics, fold_dfs = load_run(run_name)\n",
    "    print(f\"=== {run_name} ===\")\n",
    "    print(\"Mean CV:\", metrics[\"mean_cv\"])\n",
    "    print(\"OOF score:\", metrics[\"oof_score\"])\n",
    "    print(\"\\nPer-fold scores:\", metrics[\"fold_scores\"])\n",
    "\n",
    "    plt.figure(figsize=(6,4))\n",
    "    plt.bar(range(1, len(metrics[\"fold_scores\"])+1), metrics[\"fold_scores\"])\n",
    "    plt.xlabel(\"Fold\")\n",
    "    plt.ylabel(\"Score\")\n",
    "    plt.title(f\"Per-fold Scores: {run_name}\")\n",
    "    plt.show()\n",
    "\n",
    "    return oof_df, metrics, fold_dfs\n",
    "\n",
    "interact(show_run_metrics, run_name=run_dropdown)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "096beb70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GT_PATH = \"data/train_solution.csv\"  # or generate same as build_solution_df\n",
    "# gt_df = pd.read_csv(GT_PATH)\n",
    "\n",
    "# def compute_errors(pred_df, gt_df):\n",
    "#     merged = gt_df.merge(pred_df, on=\"row_id\", suffixes=(\"_gt\", \"_pred\"))\n",
    "#     merged[\"is_correct\"] = merged[\"annotation_gt\"] == merged[\"annotation_pred\"]\n",
    "#     return merged\n",
    "\n",
    "# def show_error_stats(run_name):\n",
    "#     pred_df, metrics, _ = load_run(run_name)\n",
    "#     merged = compute_errors(pred_df, gt_df)\n",
    "\n",
    "#     acc = merged[\"is_correct\"].mean()\n",
    "#     print(f\"Accuracy (strict equality): {acc:.4f}\")\n",
    "\n",
    "#     forged_gt = merged[merged[\"annotation_gt\"]!=\"authentic\"]\n",
    "#     authentic_gt = merged[merged[\"annotation_gt\"]==\"authentic\"]\n",
    "\n",
    "#     forged_acc = (forged_gt[\"annotation_gt\"] == forged_gt[\"annotation_pred\"]).mean()\n",
    "#     authentic_acc = (authentic_gt[\"annotation_gt\"] == authentic_gt[\"annotation_pred\"]).mean()\n",
    "\n",
    "#     print(\"Forged accuracy:\", forged_acc)\n",
    "#     print(\"Authentic accuracy:\", authentic_acc)\n",
    "\n",
    "#     # display bar chart\n",
    "#     plt.figure(figsize=(6,4))\n",
    "#     plt.bar([\"All\",\"Forged\",\"Authentic\"], [acc, forged_acc, authentic_acc])\n",
    "#     plt.title(f\"Error breakdown: {run_name}\")\n",
    "#     plt.ylim(0, 1)\n",
    "#     plt.show()\n",
    "\n",
    "# interact(show_error_stats, run_name=run_dropdown)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "ed1cdf61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def misclassified_viewer(run_name):\n",
    "#     pred_df, metrics, _ = load_run(run_name)\n",
    "#     merged = compute_errors(pred_df, gt_df)\n",
    "#     mis = merged[~merged[\"is_correct\"]]\n",
    "\n",
    "#     ids = mis[\"row_id\"].tolist()\n",
    "#     if not ids:\n",
    "#         print(\"No misclassifications—nice!\")\n",
    "#         return\n",
    "    \n",
    "#     def show_sample(row_id):\n",
    "#         row = mis[mis[\"row_id\"] == row_id].iloc[0]\n",
    "#         print(\"GT:\", row[\"annotation_gt\"])\n",
    "#         print(\"Pred:\", row[\"annotation_pred\"])\n",
    "#         # optionally show the image and masks\n",
    "#         # display(Image.open(path_to_image(row_id)))\n",
    "    \n",
    "#     interact(show_sample, row_id=Dropdown(options=ids, description=\"row_id\"))\n",
    "\n",
    "# interact(misclassified_viewer, run_name=run_dropdown)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "0550b476",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "10a8cfc232fe4283971ffa4c4c9192a2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Dropdown(description='run_a', options=('mini_smoke',), value='mini_smoke'), Dropdown(des…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.compare_runs(run_a, run_b)>"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def compare_runs(run_a, run_b):\n",
    "    a_df, a_met, _ = load_run(run_a)\n",
    "    b_df, b_met, _ = load_run(run_b)\n",
    "\n",
    "    print(f\"{run_a} – OOF: {a_met['oof_score']}\")\n",
    "    print(f\"{run_b} – OOF: {b_met['oof_score']}\")\n",
    "\n",
    "    plt.figure(figsize=(6,4))\n",
    "    plt.bar([\"A\",\"B\"], [a_met[\"oof_score\"], b_met[\"oof_score\"]])\n",
    "    plt.title(\"OOF Comparison\")\n",
    "    plt.show()\n",
    "\n",
    "interact(compare_runs,\n",
    "         run_a=Dropdown(options=cv_runs),\n",
    "         run_b=Dropdown(options=cv_runs))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "0a11d436",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "149d7982217240a8bfc41b735197402c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Dropdown(description='cv_run', options=('mini_smoke',), value='mini_smoke'), Dropdown(de…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.compare_cv_full(cv_run, full_run)>"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def compare_cv_full(cv_run, full_run):\n",
    "    pred_df, cv_metrics, _ = load_run(cv_run)\n",
    "    f = full_train_runs[full_run]\n",
    "\n",
    "    print(\"CV OOF:\", cv_metrics[\"oof_score\"])\n",
    "    print(\"Full-train validation:\", f[\"metrics\"].get(\"val_score\", \"N/A\"))\n",
    "\n",
    "    plt.figure(figsize=(6,4))\n",
    "    plt.bar([\"CV OOF\", \"Full Train\"], [cv_metrics[\"oof_score\"], f[\"metrics\"][\"val_score\"]])\n",
    "    plt.title(f\"{cv_run} vs {full_run}\")\n",
    "    plt.show()\n",
    "\n",
    "interact(compare_cv_full,\n",
    "         cv_run=Dropdown(options=cv_runs),\n",
    "         full_run=Dropdown(options=list(full_train_runs.keys())))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "ffa3e274",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "106ea99eb91b49be8c336fb093e34c8b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Dropdown(description='CV Run:', options=('mini_smoke',), value='mini_smoke'), IntSlider(…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.fold_drill(run_name, fold_number)>"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def fold_drill(run_name, fold_number):\n",
    "    _, _, fold_dfs = load_run(run_name)\n",
    "    key = f\"fold_{fold_number}_oof\"\n",
    "    if key not in fold_dfs:\n",
    "        print(\"No per-fold file found.\")\n",
    "        return\n",
    "\n",
    "    fold_df = fold_dfs[key]\n",
    "    print(\"Rows:\", len(fold_df))\n",
    "    display(fold_df.head())\n",
    "\n",
    "interact(\n",
    "    fold_drill,\n",
    "    run_name=run_dropdown,\n",
    "    fold_number=IntSlider(min=1, max=5, step=1, value=1)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "0ef9389d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gate</th>\n",
       "      <th>cls_threshold</th>\n",
       "      <th>mask_threshold</th>\n",
       "      <th>idx_in_batch</th>\n",
       "      <th>gate_pass</th>\n",
       "      <th>num_keep</th>\n",
       "      <th>max_cls_prob</th>\n",
       "      <th>max_mask_prob</th>\n",
       "      <th>any_fg_pre_keep</th>\n",
       "      <th>any_fg_post_keep</th>\n",
       "      <th>image_forged_prob</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>0.130176</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.613294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>0.201880</td>\n",
       "      <td>0.999997</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.474688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.5</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.029606</td>\n",
       "      <td>0.998738</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.186493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.5</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.020249</td>\n",
       "      <td>0.999816</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.017884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>0.162346</td>\n",
       "      <td>0.632276</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.607723</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   gate  cls_threshold  mask_threshold  idx_in_batch  gate_pass  num_keep  \\\n",
       "0  -1.0           0.05             0.5             0          1        15   \n",
       "1  -1.0           0.05             0.5             1          1        15   \n",
       "2  -1.0           0.05             0.5             2          1         0   \n",
       "3  -1.0           0.05             0.5             3          1         0   \n",
       "4  -1.0           0.05             0.5             0          1        15   \n",
       "\n",
       "   max_cls_prob  max_mask_prob  any_fg_pre_keep  any_fg_post_keep  \\\n",
       "0      0.130176       1.000000                1                 1   \n",
       "1      0.201880       0.999997                1                 1   \n",
       "2      0.029606       0.998738                1                 0   \n",
       "3      0.020249       0.999816                1                 0   \n",
       "4      0.162346       0.632276                1                 1   \n",
       "\n",
       "   image_forged_prob  \n",
       "0           0.613294  \n",
       "1           0.474688  \n",
       "2           0.186493  \n",
       "3           0.017884  \n",
       "4           0.607723  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 51760 rows\n",
      "['gate', 'cls_threshold', 'mask_threshold', 'idx_in_batch', 'gate_pass', 'num_keep', 'max_cls_prob', 'max_mask_prob', 'any_fg_pre_keep', 'any_fg_post_keep', 'image_forged_prob']\n"
     ]
    }
   ],
   "source": [
    "# -----------------\n",
    "# Load cls_threshold\n",
    "# -----------------\n",
    "cls_threshold = pd.read_csv(CLS_THRESHOLD_PATH)\n",
    "\n",
    "# Quick sanity check\n",
    "display(cls_threshold.head())\n",
    "print(f\"Loaded {len(cls_threshold)} rows\")\n",
    "print(cls_threshold.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "5a5370ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "cls_threshold\n",
       "0.05    5176\n",
       "0.10    5176\n",
       "0.20    5176\n",
       "0.30    5176\n",
       "0.40    5176\n",
       "0.50    5176\n",
       "0.60    5176\n",
       "0.70    5176\n",
       "0.80    5176\n",
       "0.90    5176\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cls_threshold['cls_threshold'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "70038efa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cls_threshold</th>\n",
       "      <th>gate_pass_rate</th>\n",
       "      <th>avg_num_keep</th>\n",
       "      <th>any_fg_pre_rate</th>\n",
       "      <th>any_fg_post_rate</th>\n",
       "      <th>avg_max_cls_prob</th>\n",
       "      <th>avg_max_mask_prob</th>\n",
       "      <th>avg_image_forged_prob</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.05</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.989181</td>\n",
       "      <td>0.96194</td>\n",
       "      <td>0.729328</td>\n",
       "      <td>0.135911</td>\n",
       "      <td>0.95336</td>\n",
       "      <td>0.527448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.518740</td>\n",
       "      <td>0.96194</td>\n",
       "      <td>0.641422</td>\n",
       "      <td>0.135911</td>\n",
       "      <td>0.95336</td>\n",
       "      <td>0.527448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.20</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.935085</td>\n",
       "      <td>0.96194</td>\n",
       "      <td>0.232419</td>\n",
       "      <td>0.135911</td>\n",
       "      <td>0.95336</td>\n",
       "      <td>0.527448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.30</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.96194</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.135911</td>\n",
       "      <td>0.95336</td>\n",
       "      <td>0.527448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.40</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.96194</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.135911</td>\n",
       "      <td>0.95336</td>\n",
       "      <td>0.527448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.50</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.96194</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.135911</td>\n",
       "      <td>0.95336</td>\n",
       "      <td>0.527448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.60</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.96194</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.135911</td>\n",
       "      <td>0.95336</td>\n",
       "      <td>0.527448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.70</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.96194</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.135911</td>\n",
       "      <td>0.95336</td>\n",
       "      <td>0.527448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.80</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.96194</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.135911</td>\n",
       "      <td>0.95336</td>\n",
       "      <td>0.527448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.90</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.96194</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.135911</td>\n",
       "      <td>0.95336</td>\n",
       "      <td>0.527448</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   cls_threshold  gate_pass_rate  avg_num_keep  any_fg_pre_rate  \\\n",
       "0           0.05             1.0     10.989181          0.96194   \n",
       "1           0.10             1.0      9.518740          0.96194   \n",
       "2           0.20             1.0      0.935085          0.96194   \n",
       "3           0.30             1.0      0.000000          0.96194   \n",
       "4           0.40             1.0      0.000000          0.96194   \n",
       "5           0.50             1.0      0.000000          0.96194   \n",
       "6           0.60             1.0      0.000000          0.96194   \n",
       "7           0.70             1.0      0.000000          0.96194   \n",
       "8           0.80             1.0      0.000000          0.96194   \n",
       "9           0.90             1.0      0.000000          0.96194   \n",
       "\n",
       "   any_fg_post_rate  avg_max_cls_prob  avg_max_mask_prob  \\\n",
       "0          0.729328          0.135911            0.95336   \n",
       "1          0.641422          0.135911            0.95336   \n",
       "2          0.232419          0.135911            0.95336   \n",
       "3          0.000000          0.135911            0.95336   \n",
       "4          0.000000          0.135911            0.95336   \n",
       "5          0.000000          0.135911            0.95336   \n",
       "6          0.000000          0.135911            0.95336   \n",
       "7          0.000000          0.135911            0.95336   \n",
       "8          0.000000          0.135911            0.95336   \n",
       "9          0.000000          0.135911            0.95336   \n",
       "\n",
       "   avg_image_forged_prob  \n",
       "0               0.527448  \n",
       "1               0.527448  \n",
       "2               0.527448  \n",
       "3               0.527448  \n",
       "4               0.527448  \n",
       "5               0.527448  \n",
       "6               0.527448  \n",
       "7               0.527448  \n",
       "8               0.527448  \n",
       "9               0.527448  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# aggregate per cls_threshold across all images\n",
    "summary = (\n",
    "    cls_threshold.groupby(\"cls_threshold\")\n",
    "      .agg(\n",
    "          gate_pass_rate=(\"gate_pass\", \"mean\"),\n",
    "          avg_num_keep=(\"num_keep\", \"mean\"),\n",
    "          any_fg_pre_rate=(\"any_fg_pre_keep\", \"mean\"),\n",
    "          any_fg_post_rate=(\"any_fg_post_keep\", \"mean\"),\n",
    "          avg_max_cls_prob=(\"max_cls_prob\", \"mean\"),\n",
    "          avg_max_mask_prob=(\"max_mask_prob\", \"mean\"),\n",
    "          avg_image_forged_prob=(\"image_forged_prob\", \"mean\"),\n",
    "      )\n",
    "      .reset_index()\n",
    "      .sort_values(\"cls_threshold\")\n",
    ")\n",
    "\n",
    "display(summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "4349ca21",
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = load_yaml(str(CFG_PATH))\n",
    "model_cfg = cfg.get(\"model\", {})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "8bc83275",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num keys: 432\n",
      "sample keys: ['backbone.body.0.0.weight', 'backbone.body.0.0.bias', 'backbone.body.0.1.weight', 'backbone.body.0.1.bias', 'backbone.body.1.0.layer_scale', 'backbone.body.1.0.block.0.weight', 'backbone.body.1.0.block.0.bias', 'backbone.body.1.0.block.2.weight', 'backbone.body.1.0.block.2.bias', 'backbone.body.1.0.block.3.weight', 'backbone.body.1.0.block.3.bias', 'backbone.body.1.0.block.5.weight', 'backbone.body.1.0.block.5.bias', 'backbone.body.1.1.layer_scale', 'backbone.body.1.1.block.0.weight', 'backbone.body.1.1.block.0.bias', 'backbone.body.1.1.block.2.weight', 'backbone.body.1.1.block.2.bias', 'backbone.body.1.1.block.3.weight', 'backbone.body.1.1.block.3.bias']\n",
      "has pixel_decoder: True\n",
      "has mask_feature_proj: False\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "state = torch.load(WEIGHTS, map_location=\"cpu\")\n",
    "\n",
    "# unwrap common checkpoint formats\n",
    "if isinstance(state, dict) and \"state_dict\" in state:\n",
    "    sd = state[\"state_dict\"]\n",
    "elif isinstance(state, dict) and \"model\" in state:\n",
    "    sd = state[\"model\"]\n",
    "else:\n",
    "    sd = state  # assume it's already a state_dict\n",
    "\n",
    "keys = list(sd.keys())\n",
    "print(\"num keys:\", len(keys))\n",
    "print(\"sample keys:\", keys[:20])\n",
    "print(\"has pixel_decoder:\", any(k.startswith(\"pixel_decoder.\") for k in keys))\n",
    "print(\"has mask_feature_proj:\", any(k.startswith(\"mask_feature_proj.\") for k in keys))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "fc206abe",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Error(s) in loading state_dict for Mask2FormerForgeryModel:\n\tMissing key(s) in state_dict: \"mask_feature_proj.weight\", \"mask_feature_proj.bias\". \n\tUnexpected key(s) in state_dict: \"pixel_decoder.level_embed\", \"pixel_decoder.input_proj.0.weight\", \"pixel_decoder.input_proj.0.bias\", \"pixel_decoder.input_proj.1.weight\", \"pixel_decoder.input_proj.1.bias\", \"pixel_decoder.input_proj.2.weight\", \"pixel_decoder.input_proj.2.bias\", \"pixel_decoder.input_proj.3.weight\", \"pixel_decoder.input_proj.3.bias\", \"pixel_decoder.encoder.0.self_attn.sampling_offsets.weight\", \"pixel_decoder.encoder.0.self_attn.sampling_offsets.bias\", \"pixel_decoder.encoder.0.self_attn.attention_weights.weight\", \"pixel_decoder.encoder.0.self_attn.attention_weights.bias\", \"pixel_decoder.encoder.0.self_attn.value_proj.weight\", \"pixel_decoder.encoder.0.self_attn.value_proj.bias\", \"pixel_decoder.encoder.0.self_attn.output_proj.weight\", \"pixel_decoder.encoder.0.self_attn.output_proj.bias\", \"pixel_decoder.encoder.0.norm1.weight\", \"pixel_decoder.encoder.0.norm1.bias\", \"pixel_decoder.encoder.0.linear1.weight\", \"pixel_decoder.encoder.0.linear1.bias\", \"pixel_decoder.encoder.0.linear2.weight\", \"pixel_decoder.encoder.0.linear2.bias\", \"pixel_decoder.encoder.0.norm2.weight\", \"pixel_decoder.encoder.0.norm2.bias\", \"pixel_decoder.encoder.1.self_attn.sampling_offsets.weight\", \"pixel_decoder.encoder.1.self_attn.sampling_offsets.bias\", \"pixel_decoder.encoder.1.self_attn.attention_weights.weight\", \"pixel_decoder.encoder.1.self_attn.attention_weights.bias\", \"pixel_decoder.encoder.1.self_attn.value_proj.weight\", \"pixel_decoder.encoder.1.self_attn.value_proj.bias\", \"pixel_decoder.encoder.1.self_attn.output_proj.weight\", \"pixel_decoder.encoder.1.self_attn.output_proj.bias\", \"pixel_decoder.encoder.1.norm1.weight\", \"pixel_decoder.encoder.1.norm1.bias\", \"pixel_decoder.encoder.1.linear1.weight\", \"pixel_decoder.encoder.1.linear1.bias\", \"pixel_decoder.encoder.1.linear2.weight\", \"pixel_decoder.encoder.1.linear2.bias\", \"pixel_decoder.encoder.1.norm2.weight\", \"pixel_decoder.encoder.1.norm2.bias\", \"pixel_decoder.encoder.2.self_attn.sampling_offsets.weight\", \"pixel_decoder.encoder.2.self_attn.sampling_offsets.bias\", \"pixel_decoder.encoder.2.self_attn.attention_weights.weight\", \"pixel_decoder.encoder.2.self_attn.attention_weights.bias\", \"pixel_decoder.encoder.2.self_attn.value_proj.weight\", \"pixel_decoder.encoder.2.self_attn.value_proj.bias\", \"pixel_decoder.encoder.2.self_attn.output_proj.weight\", \"pixel_decoder.encoder.2.self_attn.output_proj.bias\", \"pixel_decoder.encoder.2.norm1.weight\", \"pixel_decoder.encoder.2.norm1.bias\", \"pixel_decoder.encoder.2.linear1.weight\", \"pixel_decoder.encoder.2.linear1.bias\", \"pixel_decoder.encoder.2.linear2.weight\", \"pixel_decoder.encoder.2.linear2.bias\", \"pixel_decoder.encoder.2.norm2.weight\", \"pixel_decoder.encoder.2.norm2.bias\", \"pixel_decoder.encoder.3.self_attn.sampling_offsets.weight\", \"pixel_decoder.encoder.3.self_attn.sampling_offsets.bias\", \"pixel_decoder.encoder.3.self_attn.attention_weights.weight\", \"pixel_decoder.encoder.3.self_attn.attention_weights.bias\", \"pixel_decoder.encoder.3.self_attn.value_proj.weight\", \"pixel_decoder.encoder.3.self_attn.value_proj.bias\", \"pixel_decoder.encoder.3.self_attn.output_proj.weight\", \"pixel_decoder.encoder.3.self_attn.output_proj.bias\", \"pixel_decoder.encoder.3.norm1.weight\", \"pixel_decoder.encoder.3.norm1.bias\", \"pixel_decoder.encoder.3.linear1.weight\", \"pixel_decoder.encoder.3.linear1.bias\", \"pixel_decoder.encoder.3.linear2.weight\", \"pixel_decoder.encoder.3.linear2.bias\", \"pixel_decoder.encoder.3.norm2.weight\", \"pixel_decoder.encoder.3.norm2.bias\", \"pixel_decoder.encoder.4.self_attn.sampling_offsets.weight\", \"pixel_decoder.encoder.4.self_attn.sampling_offsets.bias\", \"pixel_decoder.encoder.4.self_attn.attention_weights.weight\", \"pixel_decoder.encoder.4.self_attn.attention_weights.bias\", \"pixel_decoder.encoder.4.self_attn.value_proj.weight\", \"pixel_decoder.encoder.4.self_attn.value_proj.bias\", \"pixel_decoder.encoder.4.self_attn.output_proj.weight\", \"pixel_decoder.encoder.4.self_attn.output_proj.bias\", \"pixel_decoder.encoder.4.norm1.weight\", \"pixel_decoder.encoder.4.norm1.bias\", \"pixel_decoder.encoder.4.linear1.weight\", \"pixel_decoder.encoder.4.linear1.bias\", \"pixel_decoder.encoder.4.linear2.weight\", \"pixel_decoder.encoder.4.linear2.bias\", \"pixel_decoder.encoder.4.norm2.weight\", \"pixel_decoder.encoder.4.norm2.bias\", \"pixel_decoder.encoder.5.self_attn.sampling_offsets.weight\", \"pixel_decoder.encoder.5.self_attn.sampling_offsets.bias\", \"pixel_decoder.encoder.5.self_attn.attention_weights.weight\", \"pixel_decoder.encoder.5.self_attn.attention_weights.bias\", \"pixel_decoder.encoder.5.self_attn.value_proj.weight\", \"pixel_decoder.encoder.5.self_attn.value_proj.bias\", \"pixel_decoder.encoder.5.self_attn.output_proj.weight\", \"pixel_decoder.encoder.5.self_attn.output_proj.bias\", \"pixel_decoder.encoder.5.norm1.weight\", \"pixel_decoder.encoder.5.norm1.bias\", \"pixel_decoder.encoder.5.linear1.weight\", \"pixel_decoder.encoder.5.linear1.bias\", \"pixel_decoder.encoder.5.linear2.weight\", \"pixel_decoder.encoder.5.linear2.bias\", \"pixel_decoder.encoder.5.norm2.weight\", \"pixel_decoder.encoder.5.norm2.bias\", \"pixel_decoder.lateral_convs.0.weight\", \"pixel_decoder.lateral_convs.0.bias\", \"pixel_decoder.lateral_convs.1.weight\", \"pixel_decoder.lateral_convs.1.bias\", \"pixel_decoder.lateral_convs.2.weight\", \"pixel_decoder.lateral_convs.2.bias\", \"pixel_decoder.output_convs.0.0.weight\", \"pixel_decoder.output_convs.0.0.bias\", \"pixel_decoder.output_convs.1.0.weight\", \"pixel_decoder.output_convs.1.0.bias\", \"pixel_decoder.output_convs.2.0.weight\", \"pixel_decoder.output_convs.2.0.bias\", \"pixel_decoder.mask_out.weight\", \"pixel_decoder.mask_out.bias\". ",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[106]\u001b[39m\u001b[32m, line 143\u001b[39m\n\u001b[32m    137\u001b[39m \u001b[38;5;66;03m# ---------------------------\u001b[39;00m\n\u001b[32m    138\u001b[39m \u001b[38;5;66;03m# Run it\u001b[39;00m\n\u001b[32m    139\u001b[39m \u001b[38;5;66;03m# ---------------------------\u001b[39;00m\n\u001b[32m    142\u001b[39m ds, loader = build_full_eval_loader(img_size=\u001b[32m256\u001b[39m, batch_size=\u001b[32m4\u001b[39m, num_workers=\u001b[32m4\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m143\u001b[39m model = \u001b[43mload_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mWEIGHTS\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mDEVICE\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    145\u001b[39m df_img, df_query = collect_logit_stats(model, loader, DEVICE, num_batches=\u001b[32m50\u001b[39m)\n\u001b[32m    146\u001b[39m display(df_img.head())\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[106]\u001b[39m\u001b[32m, line 34\u001b[39m, in \u001b[36mload_model\u001b[39m\u001b[34m(weights_path, device)\u001b[39m\n\u001b[32m     29\u001b[39m model = Mask2FormerForgeryModel(\n\u001b[32m     30\u001b[39m     **mk\n\u001b[32m     31\u001b[39m ).to(device)\n\u001b[32m     33\u001b[39m state = torch.load(weights_path, map_location=device)\n\u001b[32m---> \u001b[39m\u001b[32m34\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mload_state_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstate\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     35\u001b[39m model.eval()\n\u001b[32m     36\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m model\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\piiop\\miniconda3\\envs\\dev\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2629\u001b[39m, in \u001b[36mModule.load_state_dict\u001b[39m\u001b[34m(self, state_dict, strict, assign)\u001b[39m\n\u001b[32m   2621\u001b[39m         error_msgs.insert(\n\u001b[32m   2622\u001b[39m             \u001b[32m0\u001b[39m,\n\u001b[32m   2623\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mMissing key(s) in state_dict: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[33m. \u001b[39m\u001b[33m\"\u001b[39m.format(\n\u001b[32m   2624\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33m, \u001b[39m\u001b[33m\"\u001b[39m.join(\u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mk\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\u001b[33m'\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m missing_keys)\n\u001b[32m   2625\u001b[39m             ),\n\u001b[32m   2626\u001b[39m         )\n\u001b[32m   2628\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(error_msgs) > \u001b[32m0\u001b[39m:\n\u001b[32m-> \u001b[39m\u001b[32m2629\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[32m   2630\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mError(s) in loading state_dict for \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[33m:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[33m\"\u001b[39m.format(\n\u001b[32m   2631\u001b[39m             \u001b[38;5;28mself\u001b[39m.\u001b[34m__class__\u001b[39m.\u001b[34m__name__\u001b[39m, \u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[33m\"\u001b[39m.join(error_msgs)\n\u001b[32m   2632\u001b[39m         )\n\u001b[32m   2633\u001b[39m     )\n\u001b[32m   2634\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m _IncompatibleKeys(missing_keys, unexpected_keys)\n",
      "\u001b[31mRuntimeError\u001b[39m: Error(s) in loading state_dict for Mask2FormerForgeryModel:\n\tMissing key(s) in state_dict: \"mask_feature_proj.weight\", \"mask_feature_proj.bias\". \n\tUnexpected key(s) in state_dict: \"pixel_decoder.level_embed\", \"pixel_decoder.input_proj.0.weight\", \"pixel_decoder.input_proj.0.bias\", \"pixel_decoder.input_proj.1.weight\", \"pixel_decoder.input_proj.1.bias\", \"pixel_decoder.input_proj.2.weight\", \"pixel_decoder.input_proj.2.bias\", \"pixel_decoder.input_proj.3.weight\", \"pixel_decoder.input_proj.3.bias\", \"pixel_decoder.encoder.0.self_attn.sampling_offsets.weight\", \"pixel_decoder.encoder.0.self_attn.sampling_offsets.bias\", \"pixel_decoder.encoder.0.self_attn.attention_weights.weight\", \"pixel_decoder.encoder.0.self_attn.attention_weights.bias\", \"pixel_decoder.encoder.0.self_attn.value_proj.weight\", \"pixel_decoder.encoder.0.self_attn.value_proj.bias\", \"pixel_decoder.encoder.0.self_attn.output_proj.weight\", \"pixel_decoder.encoder.0.self_attn.output_proj.bias\", \"pixel_decoder.encoder.0.norm1.weight\", \"pixel_decoder.encoder.0.norm1.bias\", \"pixel_decoder.encoder.0.linear1.weight\", \"pixel_decoder.encoder.0.linear1.bias\", \"pixel_decoder.encoder.0.linear2.weight\", \"pixel_decoder.encoder.0.linear2.bias\", \"pixel_decoder.encoder.0.norm2.weight\", \"pixel_decoder.encoder.0.norm2.bias\", \"pixel_decoder.encoder.1.self_attn.sampling_offsets.weight\", \"pixel_decoder.encoder.1.self_attn.sampling_offsets.bias\", \"pixel_decoder.encoder.1.self_attn.attention_weights.weight\", \"pixel_decoder.encoder.1.self_attn.attention_weights.bias\", \"pixel_decoder.encoder.1.self_attn.value_proj.weight\", \"pixel_decoder.encoder.1.self_attn.value_proj.bias\", \"pixel_decoder.encoder.1.self_attn.output_proj.weight\", \"pixel_decoder.encoder.1.self_attn.output_proj.bias\", \"pixel_decoder.encoder.1.norm1.weight\", \"pixel_decoder.encoder.1.norm1.bias\", \"pixel_decoder.encoder.1.linear1.weight\", \"pixel_decoder.encoder.1.linear1.bias\", \"pixel_decoder.encoder.1.linear2.weight\", \"pixel_decoder.encoder.1.linear2.bias\", \"pixel_decoder.encoder.1.norm2.weight\", \"pixel_decoder.encoder.1.norm2.bias\", \"pixel_decoder.encoder.2.self_attn.sampling_offsets.weight\", \"pixel_decoder.encoder.2.self_attn.sampling_offsets.bias\", \"pixel_decoder.encoder.2.self_attn.attention_weights.weight\", \"pixel_decoder.encoder.2.self_attn.attention_weights.bias\", \"pixel_decoder.encoder.2.self_attn.value_proj.weight\", \"pixel_decoder.encoder.2.self_attn.value_proj.bias\", \"pixel_decoder.encoder.2.self_attn.output_proj.weight\", \"pixel_decoder.encoder.2.self_attn.output_proj.bias\", \"pixel_decoder.encoder.2.norm1.weight\", \"pixel_decoder.encoder.2.norm1.bias\", \"pixel_decoder.encoder.2.linear1.weight\", \"pixel_decoder.encoder.2.linear1.bias\", \"pixel_decoder.encoder.2.linear2.weight\", \"pixel_decoder.encoder.2.linear2.bias\", \"pixel_decoder.encoder.2.norm2.weight\", \"pixel_decoder.encoder.2.norm2.bias\", \"pixel_decoder.encoder.3.self_attn.sampling_offsets.weight\", \"pixel_decoder.encoder.3.self_attn.sampling_offsets.bias\", \"pixel_decoder.encoder.3.self_attn.attention_weights.weight\", \"pixel_decoder.encoder.3.self_attn.attention_weights.bias\", \"pixel_decoder.encoder.3.self_attn.value_proj.weight\", \"pixel_decoder.encoder.3.self_attn.value_proj.bias\", \"pixel_decoder.encoder.3.self_attn.output_proj.weight\", \"pixel_decoder.encoder.3.self_attn.output_proj.bias\", \"pixel_decoder.encoder.3.norm1.weight\", \"pixel_decoder.encoder.3.norm1.bias\", \"pixel_decoder.encoder.3.linear1.weight\", \"pixel_decoder.encoder.3.linear1.bias\", \"pixel_decoder.encoder.3.linear2.weight\", \"pixel_decoder.encoder.3.linear2.bias\", \"pixel_decoder.encoder.3.norm2.weight\", \"pixel_decoder.encoder.3.norm2.bias\", \"pixel_decoder.encoder.4.self_attn.sampling_offsets.weight\", \"pixel_decoder.encoder.4.self_attn.sampling_offsets.bias\", \"pixel_decoder.encoder.4.self_attn.attention_weights.weight\", \"pixel_decoder.encoder.4.self_attn.attention_weights.bias\", \"pixel_decoder.encoder.4.self_attn.value_proj.weight\", \"pixel_decoder.encoder.4.self_attn.value_proj.bias\", \"pixel_decoder.encoder.4.self_attn.output_proj.weight\", \"pixel_decoder.encoder.4.self_attn.output_proj.bias\", \"pixel_decoder.encoder.4.norm1.weight\", \"pixel_decoder.encoder.4.norm1.bias\", \"pixel_decoder.encoder.4.linear1.weight\", \"pixel_decoder.encoder.4.linear1.bias\", \"pixel_decoder.encoder.4.linear2.weight\", \"pixel_decoder.encoder.4.linear2.bias\", \"pixel_decoder.encoder.4.norm2.weight\", \"pixel_decoder.encoder.4.norm2.bias\", \"pixel_decoder.encoder.5.self_attn.sampling_offsets.weight\", \"pixel_decoder.encoder.5.self_attn.sampling_offsets.bias\", \"pixel_decoder.encoder.5.self_attn.attention_weights.weight\", \"pixel_decoder.encoder.5.self_attn.attention_weights.bias\", \"pixel_decoder.encoder.5.self_attn.value_proj.weight\", \"pixel_decoder.encoder.5.self_attn.value_proj.bias\", \"pixel_decoder.encoder.5.self_attn.output_proj.weight\", \"pixel_decoder.encoder.5.self_attn.output_proj.bias\", \"pixel_decoder.encoder.5.norm1.weight\", \"pixel_decoder.encoder.5.norm1.bias\", \"pixel_decoder.encoder.5.linear1.weight\", \"pixel_decoder.encoder.5.linear1.bias\", \"pixel_decoder.encoder.5.linear2.weight\", \"pixel_decoder.encoder.5.linear2.bias\", \"pixel_decoder.encoder.5.norm2.weight\", \"pixel_decoder.encoder.5.norm2.bias\", \"pixel_decoder.lateral_convs.0.weight\", \"pixel_decoder.lateral_convs.0.bias\", \"pixel_decoder.lateral_convs.1.weight\", \"pixel_decoder.lateral_convs.1.bias\", \"pixel_decoder.lateral_convs.2.weight\", \"pixel_decoder.lateral_convs.2.bias\", \"pixel_decoder.output_convs.0.0.weight\", \"pixel_decoder.output_convs.0.0.bias\", \"pixel_decoder.output_convs.1.0.weight\", \"pixel_decoder.output_convs.1.0.bias\", \"pixel_decoder.output_convs.2.0.weight\", \"pixel_decoder.output_convs.2.0.bias\", \"pixel_decoder.mask_out.weight\", \"pixel_decoder.mask_out.bias\". "
     ]
    }
   ],
   "source": [
    "def build_full_eval_loader(\n",
    "    img_size=256,\n",
    "    batch_size=4,\n",
    "    num_workers=4,\n",
    "):\n",
    "\n",
    "\n",
    "    ds = ForgeryDataset(\n",
    "        transform=get_val_transform(img_size=img_size),\n",
    "        is_train=False,\n",
    "    )\n",
    "\n",
    "    loader = DataLoader(\n",
    "        ds,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=True,  # shuffle so repeated runs don't stare at same few images\n",
    "        num_workers=num_workers,\n",
    "        pin_memory=True,\n",
    "        collate_fn=detection_collate_fn,  # list[Tensor], list[dict]\n",
    "        persistent_workers=(num_workers > 0),\n",
    "    )\n",
    "    return ds, loader\n",
    "\n",
    "\n",
    "def load_model(weights_path, device):\n",
    "    mk = sanitize_model_kwargs(model_cfg)\n",
    "\n",
    "    # Disable gate for analysis unless you're explicitly studying gating\n",
    "    model = Mask2FormerForgeryModel(\n",
    "        **mk\n",
    "    ).to(device)\n",
    "\n",
    "    state = torch.load(weights_path, map_location=device)\n",
    "    model.load_state_dict(state)\n",
    "    model.eval()\n",
    "    return model\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def collect_logit_stats(model, loader, device, num_batches=50, cls_thrs=(0.1, 0.2, 0.3)):\n",
    "    \"\"\"\n",
    "    Returns:\n",
    "      df_img: per-image rows (best for plotting / debugging collapse)\n",
    "      df_query: optional per-query rows (heavier; use only if needed)\n",
    "    \"\"\"\n",
    "    rows_img = []\n",
    "    rows_query = []\n",
    "\n",
    "    it = iter(loader)\n",
    "    for b in range(num_batches):\n",
    "        images, targets = next(it)\n",
    "        images = [x.to(device, non_blocking=True) for x in images]\n",
    "\n",
    "        mask_logits, class_logits, img_logits = model.forward_logits(images)\n",
    "\n",
    "        cls_probs = class_logits.sigmoid()               # [B,Q]\n",
    "        img_probs = img_logits.sigmoid()                 # [B]\n",
    "        mask_probs = mask_logits.sigmoid().flatten(2)    # [B,Q,HW]\n",
    "\n",
    "        # image-level summaries (mirrors train_full debug intent)\n",
    "        cls_max = cls_probs.max(dim=1).values            # [B]\n",
    "        mask_max = mask_probs.max(dim=2).values.max(dim=1).values  # [B]\n",
    "        cls_mean = cls_probs.mean(dim=1)                 # [B]\n",
    "        cls_std  = cls_probs.std(dim=1)                  # [B]\n",
    "\n",
    "        # target info (authentic vs forged)\n",
    "        y = torch.stack([t[\"image_label\"].float() for t in targets]).cpu().numpy()\n",
    "\n",
    "        for i in range(len(images)):\n",
    "            r = {\n",
    "                \"batch\": b,\n",
    "                \"i\": i,\n",
    "                \"image_label\": float(y[i]),                 # 0 authentic / 1 forged\n",
    "                \"img_forged_prob\": float(img_probs[i].item()),\n",
    "                \"cls_max\": float(cls_max[i].item()),\n",
    "                \"cls_mean\": float(cls_mean[i].item()),\n",
    "                \"cls_std\": float(cls_std[i].item()),\n",
    "                \"mask_max\": float(mask_max[i].item()),\n",
    "            }\n",
    "            for thr in cls_thrs:\n",
    "                r[f\"keep_rate@{thr}\"] = float((cls_probs[i] > thr).float().mean().item())\n",
    "                r[f\"num_keep@{thr}\"] = int((cls_probs[i] > thr).sum().item())\n",
    "            rows_img.append(r)\n",
    "\n",
    "        # per-query (optional but useful if collapse is “all queries identical”)\n",
    "        # comment this block out if you want it lighter\n",
    "        B, Q = cls_probs.shape\n",
    "        for bi in range(B):\n",
    "            for q in range(Q):\n",
    "                rows_query.append({\n",
    "                    \"batch\": b,\n",
    "                    \"i\": bi,\n",
    "                    \"q\": q,\n",
    "                    \"image_label\": float(y[bi]),\n",
    "                    \"img_forged_prob\": float(img_probs[bi].item()),\n",
    "                    \"cls_prob\": float(cls_probs[bi, q].item()),\n",
    "                    \"mask_prob_mean\": float(mask_probs[bi, q].mean().item()),\n",
    "                    \"mask_prob_max\": float(mask_probs[bi, q].max().item()),\n",
    "                })\n",
    "\n",
    "    df_img = pd.DataFrame(rows_img)\n",
    "    df_query = pd.DataFrame(rows_query)\n",
    "    return df_img, df_query\n",
    "\n",
    "\n",
    "def quick_plots(df_img):\n",
    "    # 1) forged-prob distribution split by label\n",
    "    for lbl in [0.0, 1.0]:\n",
    "        sub = df_img[df_img[\"image_label\"] == lbl]\n",
    "        plt.figure()\n",
    "        plt.hist(sub[\"img_forged_prob\"].values, bins=40)\n",
    "        plt.title(f\"img_forged_prob (label={int(lbl)})\")\n",
    "        plt.xlabel(\"prob(forged)\")\n",
    "        plt.ylabel(\"count\")\n",
    "        plt.show()\n",
    "\n",
    "    # 2) cls_max and mask_max (collapse detectors)\n",
    "    for col in [\"cls_max\", \"mask_max\"]:\n",
    "        plt.figure()\n",
    "        plt.hist(df_img[col].values, bins=40)\n",
    "        plt.title(col)\n",
    "        plt.xlabel(col)\n",
    "        plt.ylabel(\"count\")\n",
    "        plt.show()\n",
    "\n",
    "    # 3) keep-rate sanity\n",
    "    keep_cols = [c for c in df_img.columns if c.startswith(\"keep_rate@\")]\n",
    "    for col in keep_cols:\n",
    "        plt.figure()\n",
    "        plt.hist(df_img[col].values, bins=40)\n",
    "        plt.title(col)\n",
    "        plt.xlabel(col)\n",
    "        plt.ylabel(\"count\")\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "# ---------------------------\n",
    "# Run it\n",
    "# ---------------------------\n",
    "\n",
    "\n",
    "ds, loader = build_full_eval_loader(img_size=256, batch_size=4, num_workers=4)\n",
    "model = load_model(WEIGHTS, DEVICE)\n",
    "\n",
    "df_img, df_query = collect_logit_stats(model, loader, DEVICE, num_batches=50)\n",
    "display(df_img.head())\n",
    "display(df_img.describe(percentiles=[0.5, 0.9, 0.95, 0.99]))\n",
    "\n",
    "quick_plots(df_img)\n",
    "\n",
    "# Useful “collapse checks” at a glance:\n",
    "summary = {\n",
    "    \"img_forged_prob_mean\": df_img[\"img_forged_prob\"].mean(),\n",
    "    \"img_forged_prob_p95\": df_img[\"img_forged_prob\"].quantile(0.95),\n",
    "    \"cls_max_mean\": df_img[\"cls_max\"].mean(),\n",
    "    \"cls_max_p95\": df_img[\"cls_max\"].quantile(0.95),\n",
    "    \"mask_max_mean\": df_img[\"mask_max\"].mean(),\n",
    "    \"mask_max_p95\": df_img[\"mask_max\"].quantile(0.95),\n",
    "}\n",
    "print(pd.Series(summary).sort_index())\n",
    "\n",
    "# If you suspect \"all queries are the same\", check per-image variance across queries:\n",
    "per_image_cls_std = df_query.groupby([\"batch\",\"i\"])[\"cls_prob\"].std()\n",
    "print(\"per-image cls_prob std: mean=\", per_image_cls_std.mean(), \" p05=\", per_image_cls_std.quantile(0.05))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45f59fa2",
   "metadata": {},
   "source": [
    "Baseline run:\n",
    "\n",
    "cls_max_mean            0.092840\n",
    "cls_max_p95             0.146033\n",
    "img_forged_prob_mean    0.547529\n",
    "img_forged_prob_p95     0.999904\n",
    "mask_max_mean           0.456716\n",
    "mask_max_p95            0.981398\n",
    "dtype: float64\n",
    "per-image cls_prob std: mean= 0.0018325206584260529  p05= 0.000333666384610696"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
