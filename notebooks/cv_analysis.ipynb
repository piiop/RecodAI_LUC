{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "67e6b406",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cv_analysis.ipynb\n",
    "\n",
    "import json\n",
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "PROJECT_ROOT = Path(\"..\").resolve()\n",
    "\n",
    "if str(PROJECT_ROOT) not in sys.path:\n",
    "    sys.path.insert(0, str(PROJECT_ROOT))\n",
    "\n",
    "from src.data.dataloader import (\n",
    "    ForgeryDataset,\n",
    "    detection_collate_fn,\n",
    "    get_val_transform,\n",
    ")\n",
    "from src.models.mask2former_v1 import Mask2FormerForgeryModel\n",
    "from src.utils.config_utils import load_yaml, sanitize_model_kwargs\n",
    "from src.training.train_cv import build_solution_df\n",
    "from src.data.dataloader import ForgeryDataset\n",
    "from src.models.kaggle_metric import score as kaggle_score\n",
    "\n",
    "plt.style.use(\"ggplot\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1cb53e0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------\n",
    "# Constants / Paths\n",
    "# -----------------\n",
    "\n",
    "OOF_ROOT = PROJECT_ROOT / \"experiments\" / \"oof_results\"\n",
    "FULL_TRAIN_ROOT = PROJECT_ROOT / \"experiments\" / \"full_train_results\"\n",
    "\n",
    "CLS_THRESHOLD_PATH = (\n",
    "    PROJECT_ROOT / \"experiments\" / \"cls_threshold_sweep\" / \"cls_threshold_sweep.csv\"\n",
    ")\n",
    "\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "CFG_PATH = PROJECT_ROOT / \"config\" / \"base.yaml\"\n",
    "\n",
    "CLPSE_ROOT = PROJECT_ROOT / \"experiments\" / \"cls_collapse\"\n",
    "\n",
    "SAMPLEDUMP_ROOT = PROJECT_ROOT / \"experiments\" / \"oof_results\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d693608",
   "metadata": {},
   "source": [
    "### OOF CV results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a5c26d53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OOF dirs: ['base_wgroupkfold', 'gate_pass_TRUE', 'mini_smoke']\n",
      "OOF loose files: ['sanity_random_200.csv']\n"
     ]
    }
   ],
   "source": [
    "# List what's in experiments/oof_results/\n",
    "oof_items = list(OOF_ROOT.iterdir())\n",
    "oof_dirs = sorted([p.name for p in oof_items if p.is_dir()])\n",
    "oof_files = sorted([p.name for p in oof_items if p.is_file()])\n",
    "\n",
    "print(\"OOF dirs:\", oof_dirs)\n",
    "if oof_files:\n",
    "    print(\"OOF loose files:\", oof_files)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "03a67ab1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded:\n",
      " - gate_pass_TRUE (C:\\Users\\piiop\\Desktop\\Portfolio\\Projects\\RecodAI_LUC\\experiments\\oof_results\\gate_pass_TRUE)\n"
     ]
    }
   ],
   "source": [
    "def load_run(names):\n",
    "    \"\"\"\n",
    "    names:\n",
    "      - str: dir name under OOF_ROOT OR filename under OOF_ROOT\n",
    "      - list/tuple[str]: load multiple; returns dict keyed by run/filename\n",
    "    \"\"\"\n",
    "    if isinstance(names, (list, tuple)):\n",
    "        return {str(n): load_run(str(n)) for n in names}\n",
    "\n",
    "    name = str(names)\n",
    "    p = OOF_ROOT / name\n",
    "\n",
    "    # Case A: run directory\n",
    "    if p.is_dir():\n",
    "        run_dir = p\n",
    "        oof_csv = run_dir / \"oof_predictions.csv\"\n",
    "        metrics_json = run_dir / \"oof_metrics.json\"\n",
    "\n",
    "        oof_df = pd.read_csv(oof_csv) if oof_csv.exists() else None\n",
    "        metrics = json.load(metrics_json.open()) if metrics_json.exists() else None\n",
    "\n",
    "        fold_files = sorted(run_dir.glob(\"fold_*_oof.csv\"))\n",
    "        fold_dfs = {f.stem: pd.read_csv(f) for f in fold_files}\n",
    "\n",
    "        return {\"name\": run_dir.name, \"path\": run_dir, \"oof\": oof_df, \"metrics\": metrics, \"folds\": fold_dfs}\n",
    "\n",
    "    # Case B: loose file\n",
    "    if p.is_file():\n",
    "        if p.suffix.lower() == \".csv\":\n",
    "            return {\"name\": p.name, \"path\": p, \"oof\": pd.read_csv(p), \"metrics\": None, \"folds\": {}}\n",
    "        if p.suffix.lower() == \".json\":\n",
    "            return {\"name\": p.name, \"path\": p, \"oof\": None, \"metrics\": json.load(p.open()), \"folds\": {}}\n",
    "        raise ValueError(f\"Unsupported file type: {p.suffix}\")\n",
    "\n",
    "    raise FileNotFoundError(f\"Not found under OOF_ROOT: {name}\")\n",
    "\n",
    "# Use load_run(name | [names]) to load one or more CV runs or loose files from experiments/oof_results/\n",
    "runs = load_run([\"gate_pass_TRUE\"])  # or: load_run(\"mini_smoke\"), load_run(\"oof_predictions.csv\")\n",
    "\n",
    "print(\"Loaded:\")\n",
    "if isinstance(runs, dict) and \"name\" not in runs:\n",
    "    for k, v in runs.items():\n",
    "        print(f\" - {v['name']} ({v['path']})\")\n",
    "else:\n",
    "    print(f\" - {runs['name']} ({runs['path']})\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "eba815e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Loaded runs ===\n",
      "\n",
      "gate_pass_TRUE\n",
      "  Mean CV   : 0.42342663216943294\n",
      "  OOF score : 0.42343347872937315\n",
      "  Folds     : [0.45886442641946695, 0.3413575555143108, 0.47005791457452123]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 700x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def show_run_metrics(names):\n",
    "    \"\"\"\n",
    "    Pass a run dir name (str) or list of names to compare.\n",
    "    \"\"\"\n",
    "    runs = load_run(names)\n",
    "    if isinstance(runs, dict) and \"name\" not in runs:\n",
    "        items = list(runs.values())\n",
    "    else:\n",
    "        items = [runs]\n",
    "\n",
    "    # Clean summary header\n",
    "    print(\"=== Loaded runs ===\")\n",
    "    for r in items:\n",
    "        m = r[\"metrics\"] or {}\n",
    "        mean_cv = m.get(\"mean_cv\", None)\n",
    "        oof_score = m.get(\"oof_score\", None)\n",
    "        fold_scores = m.get(\"fold_scores\", None)\n",
    "\n",
    "        print(f\"\\n{r['name']}\")\n",
    "        print(f\"  Mean CV   : {mean_cv}\")\n",
    "        print(f\"  OOF score : {oof_score}\")\n",
    "        if fold_scores is not None:\n",
    "            print(f\"  Folds     : {fold_scores}\")\n",
    "\n",
    "    # Comparison plot (only for runs that have fold_scores)\n",
    "    plot_items = [(r[\"name\"], (r[\"metrics\"] or {}).get(\"fold_scores\")) for r in items]\n",
    "    plot_items = [(n, fs) for (n, fs) in plot_items if fs is not None]\n",
    "\n",
    "    if plot_items:\n",
    "        plt.figure(figsize=(7, 4))\n",
    "        for name, fs in plot_items:\n",
    "            plt.plot(range(1, len(fs) + 1), fs, marker=\"o\", label=name)\n",
    "        plt.xlabel(\"Fold\")\n",
    "        plt.ylabel(\"Score\")\n",
    "        plt.title(\"Per-fold scores (comparison)\")\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "\n",
    "    return runs\n",
    "\n",
    "# Single run\n",
    "_ = show_run_metrics(\"gate_pass_TRUE\")\n",
    "\n",
    "# Compare multiple runs\n",
    "# _ = show_run_metrics([\"mini_smoke\", \"some_other_run\"])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc645bc2",
   "metadata": {},
   "source": [
    "## CollapseLogger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a17d44dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "== oof_predictions.csv (head) ==\n",
      "\n",
      "Found fold CSVs: ['fold_1_oof', 'fold_2_oof', 'fold_3_oof']\n"
     ]
    }
   ],
   "source": [
    "# ---- Use an already-loaded run from `runs` ----\n",
    "run = runs[\"gate_pass_TRUE\"]  # must exist in `runs`\n",
    "\n",
    "OOF_RUN_DIR = run[\"path\"]\n",
    "oof_metrics = run[\"metrics\"] or {}\n",
    "oof_predictions = run[\"oof\"]\n",
    "fold_dfs = run[\"folds\"]\n",
    "\n",
    "print(\"\\n== oof_predictions.csv (head) ==\")\n",
    "\n",
    "print(\"\\nFound fold CSVs:\", list(fold_dfs.keys()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "72e30e1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "== Recomputed overall OOF score ==\n",
      "recomputed_oof: 0.3430849049390142\n",
      "\n",
      "== Recomputed per-fold scores ==\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fold</th>\n",
       "      <th>kaggle_metric</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.458864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.341358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.470058</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fold  kaggle_metric\n",
       "0     1       0.458864\n",
       "1     2       0.341358\n",
       "2     3       0.470058"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Rebuild solution_df and re-score to match train_cv additional pipeline verification\n",
    "\n",
    "full_dataset = ForgeryDataset(transform=None)\n",
    "solution_df = build_solution_df(full_dataset)\n",
    "\n",
    "# Overall OOF score (ALIGN BY row_id, then score)\n",
    "solution_df[\"row_id\"] = solution_df[\"row_id\"].astype(str)\n",
    "oof_predictions[\"row_id\"] = oof_predictions[\"row_id\"].astype(str)\n",
    "sub_aligned = (\n",
    "    solution_df[[\"row_id\"]]\n",
    "    .merge(oof_predictions[[\"row_id\", \"annotation\"]], on=\"row_id\", how=\"left\")\n",
    ")\n",
    "\n",
    "recomputed_oof = kaggle_score(\n",
    "    solution_df[[\"row_id\", \"annotation\", \"shape\"]].copy(),\n",
    "    sub_aligned[[\"row_id\", \"annotation\"]].copy(),\n",
    "    row_id_column_name=\"row_id\",\n",
    ")\n",
    "\n",
    "print(\"\\n== Recomputed overall OOF score ==\")\n",
    "print(\"recomputed_oof:\", float(recomputed_oof))\n",
    "\n",
    "# Per-fold (recompute using the saved fold CSVs if present)\n",
    "def fold_num_from_stem(stem: str) -> int:\n",
    "    m = re.search(r\"(\\d+)\", stem)\n",
    "    return int(m.group(1)) if m else -1\n",
    "\n",
    "if fold_dfs:\n",
    "    # Build stable (row_id, occ) keys on the FULL solution_df once\n",
    "    sol = solution_df.copy()\n",
    "    sol[\"row_id\"] = sol[\"row_id\"].astype(str)\n",
    "    sol[\"occ\"] = sol.groupby(\"row_id\").cumcount()\n",
    "\n",
    "    fold_scores = []\n",
    "    for stem, fdf in sorted(fold_dfs.items(), key=lambda kv: fold_num_from_stem(kv[0])):\n",
    "        fnum = fold_num_from_stem(stem)\n",
    "\n",
    "        sub = fdf.copy()\n",
    "        sub[\"row_id\"] = sub[\"row_id\"].astype(str)\n",
    "        # IMPORTANT: occ must follow the fold CSV order (this is what well score)\n",
    "        sub[\"occ\"] = sub.groupby(\"row_id\").cumcount()\n",
    "\n",
    "        # Rebuild fold solution IN THE SAME ORDER AS sub (no sorting, no isin)\n",
    "        fold_sol = sub[[\"row_id\", \"occ\"]].merge(\n",
    "            sol[[\"row_id\", \"occ\", \"annotation\", \"shape\"]],\n",
    "            on=[\"row_id\", \"occ\"],\n",
    "            how=\"left\",\n",
    "        )\n",
    "\n",
    "        # Hard sanity checks (if these fail, your saved fold CSV isn't compatible with solution_df)\n",
    "        assert len(fold_sol) == len(sub)\n",
    "        if fold_sol[\"annotation\"].isna().any() or fold_sol[\"shape\"].isna().any():\n",
    "            bad = fold_sol[fold_sol[\"annotation\"].isna() | fold_sol[\"shape\"].isna()].head(10)\n",
    "            raise RuntimeError(f\"{stem}: fold_sol has missing GT rows. Sample:\\n{bad}\")\n",
    "\n",
    "        # Submission already in correct order; kaggle_score aligns by row order\n",
    "        fold_sub = sub[[\"row_id\", \"annotation\"]].copy()\n",
    "\n",
    "        s = kaggle_score(\n",
    "            fold_sol[[\"row_id\", \"annotation\", \"shape\"]].copy(),\n",
    "            fold_sub.copy(),\n",
    "            row_id_column_name=\"row_id\",\n",
    "        )\n",
    "        fold_scores.append((fnum, float(s)))\n",
    "\n",
    "    fold_scores_df = pd.DataFrame(fold_scores, columns=[\"fold\", \"kaggle_metric\"]).sort_values(\"fold\")\n",
    "    print(\"\\n== Recomputed per-fold scores ==\")\n",
    "    display(fold_scores_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "2c4929a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded ClsCollapseLogger artifacts for folds: [1, 2, 3]\n",
      "  JSON blobs : 6\n",
      "  Tables     : 9\n",
      "\n",
      "fold1 tables:\n",
      "  - cv_fold1\\debug.jsonl | shape=(1290096, 53) | cols=['tag', 'fold', 'epoch', 'global_step', 'img_label', 'masks_shape', 'masks_sum', 'b', 'Q', 'Hm', 'Wm', 'tgt_shape', 'tgt_numel', 'tgt_sum', 'cost_shape', 'matched', 'num_gt', 'B', 'pos', 'total', 'pos_frac', 'thr', 'temp', 'authentic_frac', 'per_image_penalty_mean', 'loss_auth_penalty', 'reason', 'per_image', 'mask_probs', 'class_probs', 'img_probs', 'val_samples', 'masks_empty', 'gate_fail', 'num_keep0', 'cls_filtered_all_fg', 'rates', 'max_cls_prob', 'max_mask_prob', 'presence_mean', 'presence_min', 'presence_max', 'tau', 'loss_presence_auth', 'loss_forged_presence', 'fg_prob_per_query', 'fg_prob_mean', 'fg_prob_p95', 'fg_prob_max', 'no_fg_pre_keep', 'pred_auth_frac', 'pred_non_auth_count', 'pred_non_auth_area_ratio_mean']\n",
      "  - cv_fold1\\epoch_summary.csv | shape=(160, 11) | cols=['fold', 'epoch', 'epoch_loss', 'cls_max_mean', 'cls_max_p95', 'keep_rate@0.1', 'keep_rate@0.2', 'keep_rate@0.3', 'img_forged_mean', 'mask_max_mean', 'w_mask_cls']\n",
      "  - cv_fold1\\step_losses.csv | shape=(138080, 12) | cols=['fold', 'epoch', 'global_step', 'lr', 'loss_mask_bce', 'loss_mask_dice', 'loss_mask_cls', 'loss_img_auth', 'loss_auth_penalty', 'loss_total', 'w_mask_cls', 'w_auth_penalty']\n",
      "\n",
      "fold2 tables:\n",
      "  - cv_fold2\\debug.jsonl | shape=(1613519, 53) | cols=['tag', 'fold', 'epoch', 'global_step', 'img_label', 'masks_shape', 'masks_sum', 'per_image', 'mask_probs', 'class_probs', 'img_probs', 'b', 'Q', 'Hm', 'Wm', 'tgt_shape', 'tgt_numel', 'tgt_sum', 'matched', 'reason', 'cost_shape', 'num_gt', 'B', 'pos', 'total', 'pos_frac', 'thr', 'temp', 'authentic_frac', 'per_image_penalty_mean', 'loss_auth_penalty', 'val_samples', 'masks_empty', 'gate_fail', 'num_keep0', 'cls_filtered_all_fg', 'rates', 'max_cls_prob', 'max_mask_prob', 'presence_mean', 'presence_min', 'presence_max', 'tau', 'loss_presence_auth', 'loss_forged_presence', 'fg_prob_per_query', 'fg_prob_mean', 'fg_prob_p95', 'fg_prob_max', 'no_fg_pre_keep', 'pred_auth_frac', 'pred_non_auth_count', 'pred_non_auth_area_ratio_mean']\n",
      "  - cv_fold2\\epoch_summary.csv | shape=(160, 11) | cols=['fold', 'epoch', 'epoch_loss', 'cls_max_mean', 'cls_max_p95', 'keep_rate@0.1', 'keep_rate@0.2', 'keep_rate@0.3', 'img_forged_mean', 'mask_max_mean', 'w_mask_cls']\n",
      "  - cv_fold2\\step_losses.csv | shape=(138080, 12) | cols=['fold', 'epoch', 'global_step', 'lr', 'loss_mask_bce', 'loss_mask_dice', 'loss_mask_cls', 'loss_img_auth', 'loss_auth_penalty', 'loss_total', 'w_mask_cls', 'w_auth_penalty']\n",
      "\n",
      "fold3 tables:\n",
      "  - cv_fold3\\debug.jsonl | shape=(1613519, 53) | cols=['tag', 'fold', 'epoch', 'global_step', 'img_label', 'masks_shape', 'masks_sum', 'per_image', 'mask_probs', 'class_probs', 'img_probs', 'b', 'Q', 'Hm', 'Wm', 'tgt_shape', 'tgt_numel', 'tgt_sum', 'cost_shape', 'matched', 'num_gt', 'B', 'pos', 'total', 'pos_frac', 'thr', 'temp', 'authentic_frac', 'per_image_penalty_mean', 'loss_auth_penalty', 'reason', 'val_samples', 'masks_empty', 'gate_fail', 'num_keep0', 'cls_filtered_all_fg', 'rates', 'max_cls_prob', 'max_mask_prob', 'presence_mean', 'presence_min', 'presence_max', 'tau', 'loss_presence_auth', 'loss_forged_presence', 'fg_prob_per_query', 'fg_prob_mean', 'fg_prob_p95', 'fg_prob_max', 'no_fg_pre_keep', 'pred_auth_frac', 'pred_non_auth_count', 'pred_non_auth_area_ratio_mean']\n",
      "  - cv_fold3\\epoch_summary.csv | shape=(160, 11) | cols=['fold', 'epoch', 'epoch_loss', 'cls_max_mean', 'cls_max_p95', 'keep_rate@0.1', 'keep_rate@0.2', 'keep_rate@0.3', 'img_forged_mean', 'mask_max_mean', 'w_mask_cls']\n",
      "  - cv_fold3\\step_losses.csv | shape=(138080, 12) | cols=['fold', 'epoch', 'global_step', 'lr', 'loss_mask_bce', 'loss_mask_dice', 'loss_mask_cls', 'loss_img_auth', 'loss_auth_penalty', 'loss_total', 'w_mask_cls', 'w_auth_penalty']\n"
     ]
    }
   ],
   "source": [
    "# Load ClsCollapseLogger outputs for the CV folds (from experiments/cls_collapse)\n",
    "\n",
    "def _read_json(p: Path):\n",
    "    with open(p, \"r\") as f:\n",
    "        return json.load(f)\n",
    "\n",
    "def _read_jsonl(p: Path):\n",
    "    rows = []\n",
    "    with open(p, \"r\") as f:\n",
    "        for line in f:\n",
    "            line = line.strip()\n",
    "            if line:\n",
    "                rows.append(json.loads(line))\n",
    "    return pd.DataFrame(rows) if rows else pd.DataFrame()\n",
    "\n",
    "def _read_table(p: Path):\n",
    "    suf = p.suffix.lower()\n",
    "    if suf == \".csv\":\n",
    "        return pd.read_csv(p)\n",
    "    if suf in (\".jsonl\", \".ndjson\"):\n",
    "        return _read_jsonl(p)\n",
    "    return None\n",
    "\n",
    "def _fold_numbers_from_loaded_run(fold_dfs, oof_metrics):\n",
    "    nums = []\n",
    "    for k in (fold_dfs or {}).keys():\n",
    "        m = re.search(r\"(\\d+)\", str(k))\n",
    "        if m:\n",
    "            nums.append(int(m.group(1)))\n",
    "    if nums:\n",
    "        return sorted(set(nums))\n",
    "    fs = (oof_metrics or {}).get(\"fold_scores\", None)\n",
    "    return list(range(1, len(fs) + 1)) if fs else []\n",
    "\n",
    "fold_nums = _fold_numbers_from_loaded_run(fold_dfs, oof_metrics)\n",
    "\n",
    "collapse_json = {}    # (fold, relpath) -> dict\n",
    "collapse_tables = {}  # (fold, relpath) -> df\n",
    "\n",
    "for fnum in fold_nums:\n",
    "    run_name = f\"cv_fold{fnum}\"\n",
    "    fold_dir = CLPSE_ROOT / run_name\n",
    "\n",
    "    if fold_dir.is_dir():\n",
    "        files = [p for p in fold_dir.rglob(\"*\") if p.is_file()]\n",
    "    else:\n",
    "        files = [p for p in CLPSE_ROOT.rglob(f\"*{run_name}*\") if p.is_file()]\n",
    "\n",
    "    for p in files:\n",
    "        rel = str(p.relative_to(CLPSE_ROOT))\n",
    "        suf = p.suffix.lower()\n",
    "\n",
    "        if suf == \".json\":\n",
    "            try:\n",
    "                collapse_json[(fnum, rel)] = _read_json(p)\n",
    "            except Exception:\n",
    "                pass\n",
    "        elif suf in (\".csv\", \".jsonl\", \".ndjson\"):\n",
    "            try:\n",
    "                df = _read_table(p)\n",
    "                if df is not None and len(df) > 0:\n",
    "                    collapse_tables[(fnum, rel)] = df\n",
    "            except Exception:\n",
    "                pass\n",
    "\n",
    "# concise inventory  \n",
    "print(f\"Loaded ClsCollapseLogger artifacts for folds: {fold_nums}\")\n",
    "print(f\"  JSON blobs : {len(collapse_json)}\")\n",
    "print(f\"  Tables     : {len(collapse_tables)}\")\n",
    "\n",
    "if collapse_tables:\n",
    "    by_fold = {}\n",
    "    for (fnum, rel), df in collapse_tables.items():\n",
    "        by_fold.setdefault(fnum, []).append((rel, df))\n",
    "\n",
    "    for fnum in sorted(by_fold):\n",
    "        print(f\"\\nfold{fnum} tables:\")\n",
    "        for rel, df in sorted(by_fold[fnum], key=lambda x: x[0]):\n",
    "            print(f\"  - {rel} | shape={df.shape} | cols={list(df.columns)}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "be951a4c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fold</th>\n",
       "      <th>epoch</th>\n",
       "      <th>global_step</th>\n",
       "      <th>lr</th>\n",
       "      <th>loss_mask_bce</th>\n",
       "      <th>loss_mask_dice</th>\n",
       "      <th>loss_mask_cls</th>\n",
       "      <th>loss_img_auth</th>\n",
       "      <th>loss_auth_penalty</th>\n",
       "      <th>loss_total</th>\n",
       "      <th>w_mask_cls</th>\n",
       "      <th>w_auth_penalty</th>\n",
       "      <th>_source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>414240.000000</td>\n",
       "      <td>414240.000000</td>\n",
       "      <td>414240.000000</td>\n",
       "      <td>414240.0000</td>\n",
       "      <td>414240.000000</td>\n",
       "      <td>414240.000000</td>\n",
       "      <td>414240.000000</td>\n",
       "      <td>414240.000000</td>\n",
       "      <td>4.142400e+05</td>\n",
       "      <td>414240.000000</td>\n",
       "      <td>414240.0</td>\n",
       "      <td>414240.0</td>\n",
       "      <td>414240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>cv_fold1\\step_losses.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>138080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>11.281250</td>\n",
       "      <td>9303.718750</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.114467</td>\n",
       "      <td>0.599369</td>\n",
       "      <td>0.282055</td>\n",
       "      <td>0.446334</td>\n",
       "      <td>1.450464e-03</td>\n",
       "      <td>1.571257</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.816498</td>\n",
       "      <td>7.058843</td>\n",
       "      <td>6096.873728</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.234665</td>\n",
       "      <td>0.230853</td>\n",
       "      <td>0.123640</td>\n",
       "      <td>0.263075</td>\n",
       "      <td>1.110385e-02</td>\n",
       "      <td>0.592269</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.001061</td>\n",
       "      <td>0.000032</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.006600</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>3835.000000</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.037324</td>\n",
       "      <td>0.464178</td>\n",
       "      <td>0.195315</td>\n",
       "      <td>0.251441</td>\n",
       "      <td>6.944162e-16</td>\n",
       "      <td>1.187516</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>10.500000</td>\n",
       "      <td>8629.500000</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.078897</td>\n",
       "      <td>0.614560</td>\n",
       "      <td>0.262592</td>\n",
       "      <td>0.419446</td>\n",
       "      <td>8.139001e-13</td>\n",
       "      <td>1.551096</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>3.000000</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>14383.000000</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.145433</td>\n",
       "      <td>0.764700</td>\n",
       "      <td>0.349438</td>\n",
       "      <td>0.615183</td>\n",
       "      <td>1.861562e-07</td>\n",
       "      <td>1.925323</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>3.000000</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>21574.000000</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>41.467186</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.426446</td>\n",
       "      <td>3.941484</td>\n",
       "      <td>1.129112e+00</td>\n",
       "      <td>43.669540</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 fold          epoch    global_step           lr  \\\n",
       "count   414240.000000  414240.000000  414240.000000  414240.0000   \n",
       "unique            NaN            NaN            NaN          NaN   \n",
       "top               NaN            NaN            NaN          NaN   \n",
       "freq              NaN            NaN            NaN          NaN   \n",
       "mean         2.000000      11.281250    9303.718750       0.0001   \n",
       "std          0.816498       7.058843    6096.873728       0.0000   \n",
       "min          1.000000       1.000000       0.000000       0.0001   \n",
       "25%          1.000000       5.000000    3835.000000       0.0001   \n",
       "50%          2.000000      10.500000    8629.500000       0.0001   \n",
       "75%          3.000000      17.000000   14383.000000       0.0001   \n",
       "max          3.000000      25.000000   21574.000000       0.0001   \n",
       "\n",
       "        loss_mask_bce  loss_mask_dice  loss_mask_cls  loss_img_auth  \\\n",
       "count   414240.000000   414240.000000  414240.000000  414240.000000   \n",
       "unique            NaN             NaN            NaN            NaN   \n",
       "top               NaN             NaN            NaN            NaN   \n",
       "freq              NaN             NaN            NaN            NaN   \n",
       "mean         0.114467        0.599369       0.282055       0.446334   \n",
       "std          0.234665        0.230853       0.123640       0.263075   \n",
       "min         -0.000000       -0.000000       0.001061       0.000032   \n",
       "25%          0.037324        0.464178       0.195315       0.251441   \n",
       "50%          0.078897        0.614560       0.262592       0.419446   \n",
       "75%          0.145433        0.764700       0.349438       0.615183   \n",
       "max         41.467186        1.000000       1.426446       3.941484   \n",
       "\n",
       "        loss_auth_penalty     loss_total  w_mask_cls  w_auth_penalty  \\\n",
       "count        4.142400e+05  414240.000000    414240.0        414240.0   \n",
       "unique                NaN            NaN         NaN             NaN   \n",
       "top                   NaN            NaN         NaN             NaN   \n",
       "freq                  NaN            NaN         NaN             NaN   \n",
       "mean         1.450464e-03       1.571257         1.0             1.0   \n",
       "std          1.110385e-02       0.592269         0.0             0.0   \n",
       "min          0.000000e+00       0.006600         1.0             1.0   \n",
       "25%          6.944162e-16       1.187516         1.0             1.0   \n",
       "50%          8.139001e-13       1.551096         1.0             1.0   \n",
       "75%          1.861562e-07       1.925323         1.0             1.0   \n",
       "max          1.129112e+00      43.669540         1.0             1.0   \n",
       "\n",
       "                         _source  \n",
       "count                     414240  \n",
       "unique                         3  \n",
       "top     cv_fold1\\step_losses.csv  \n",
       "freq                      138080  \n",
       "mean                         NaN  \n",
       "std                          NaN  \n",
       "min                          NaN  \n",
       "25%                          NaN  \n",
       "50%                          NaN  \n",
       "75%                          NaN  \n",
       "max                          NaN  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Convenience: key summaries across ALL loaded debug tables\n",
    "\n",
    "def concat_tables(name_contains: str):\n",
    "    dfs = []\n",
    "    for (fold, rel), df in collapse_tables.items():\n",
    "        if name_contains.lower() in rel.lower():\n",
    "            d = df.copy()\n",
    "            d[\"fold\"] = fold\n",
    "            d[\"_source\"] = rel\n",
    "            dfs.append(d)\n",
    "    return pd.concat(dfs, ignore_index=True) if dfs else pd.DataFrame()\n",
    "\n",
    "step_losses = concat_tables(\"step\")\n",
    "epoch_summary = concat_tables(\"epoch\")\n",
    "debug_events = concat_tables(\"debug\")\n",
    "\n",
    "if len(step_losses):\n",
    "    display(step_losses.describe(include=\"all\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "e1e35d8b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fold</th>\n",
       "      <th>epoch</th>\n",
       "      <th>epoch_loss</th>\n",
       "      <th>cls_max_mean</th>\n",
       "      <th>cls_max_p95</th>\n",
       "      <th>keep_rate@0.1</th>\n",
       "      <th>keep_rate@0.2</th>\n",
       "      <th>keep_rate@0.3</th>\n",
       "      <th>img_forged_mean</th>\n",
       "      <th>mask_max_mean</th>\n",
       "      <th>w_mask_cls</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>25</td>\n",
       "      <td>1.106284</td>\n",
       "      <td>0.041141</td>\n",
       "      <td>0.041141</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.459946</td>\n",
       "      <td>0.979579</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>25</td>\n",
       "      <td>1.099362</td>\n",
       "      <td>0.018741</td>\n",
       "      <td>0.058184</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.216331</td>\n",
       "      <td>0.900513</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>25</td>\n",
       "      <td>1.081480</td>\n",
       "      <td>0.041497</td>\n",
       "      <td>0.041497</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.096023</td>\n",
       "      <td>0.633171</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fold  epoch  epoch_loss  cls_max_mean  cls_max_p95  keep_rate@0.1  \\\n",
       "0     1     25    1.106284      0.041141     0.041141            0.0   \n",
       "1     2     25    1.099362      0.018741     0.058184            0.0   \n",
       "2     3     25    1.081480      0.041497     0.041497            0.0   \n",
       "\n",
       "   keep_rate@0.2  keep_rate@0.3  img_forged_mean  mask_max_mean  w_mask_cls  \n",
       "0            0.0            0.0         0.459946       0.979579         1.0  \n",
       "1            0.0            0.0         0.216331       0.900513         1.0  \n",
       "2            0.0            0.0         0.096023       0.633171         1.0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>keep_rate@0.1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>keep_rate@0.2</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>keep_rate@0.3</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cls_max_mean</th>\n",
       "      <td>0.033793</td>\n",
       "      <td>0.013036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cls_max_p95</th>\n",
       "      <td>0.046940</td>\n",
       "      <td>0.009738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>img_forged_mean</th>\n",
       "      <td>0.257433</td>\n",
       "      <td>0.185410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mask_max_mean</th>\n",
       "      <td>0.837754</td>\n",
       "      <td>0.181531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>w_mask_cls</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>epoch_loss</th>\n",
       "      <td>1.095709</td>\n",
       "      <td>0.012799</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     mean       std\n",
       "keep_rate@0.1    0.000000  0.000000\n",
       "keep_rate@0.2    0.000000  0.000000\n",
       "keep_rate@0.3    0.000000  0.000000\n",
       "cls_max_mean     0.033793  0.013036\n",
       "cls_max_p95      0.046940  0.009738\n",
       "img_forged_mean  0.257433  0.185410\n",
       "mask_max_mean    0.837754  0.181531\n",
       "w_mask_cls       1.000000  0.000000\n",
       "epoch_loss       1.095709  0.012799"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fold</th>\n",
       "      <th>epoch</th>\n",
       "      <th>cls_dead</th>\n",
       "      <th>keep_dead</th>\n",
       "      <th>mask_dead</th>\n",
       "      <th>auth_all_auth</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>1</td>\n",
       "      <td>25</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>259</th>\n",
       "      <td>2</td>\n",
       "      <td>25</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>419</th>\n",
       "      <td>3</td>\n",
       "      <td>25</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     fold  epoch  cls_dead  keep_dead  mask_dead  auth_all_auth\n",
       "99      1     25      True       True      False          False\n",
       "259     2     25     False       True      False          False\n",
       "419     3     25      True       True      False          False"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>corr_with_epoch</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>epoch_loss</th>\n",
       "      <td>-0.748837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>img_forged_mean</th>\n",
       "      <td>-0.415205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cls_max_mean</th>\n",
       "      <td>-0.215075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>keep_rate@0.1</th>\n",
       "      <td>-0.194959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>keep_rate@0.3</th>\n",
       "      <td>-0.155680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cls_max_p95</th>\n",
       "      <td>-0.133178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>keep_rate@0.2</th>\n",
       "      <td>-0.132255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mask_max_mean</th>\n",
       "      <td>0.061727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>w_mask_cls</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 corr_with_epoch\n",
       "epoch_loss             -0.748837\n",
       "img_forged_mean        -0.415205\n",
       "cls_max_mean           -0.215075\n",
       "keep_rate@0.1          -0.194959\n",
       "keep_rate@0.3          -0.155680\n",
       "cls_max_p95            -0.133178\n",
       "keep_rate@0.2          -0.132255\n",
       "mask_max_mean           0.061727\n",
       "w_mask_cls                   NaN"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# --- Useful, compact diagnostics for epoch_summary ---\n",
    "\n",
    "es = epoch_summary.copy()\n",
    "\n",
    "num_cols = [\n",
    "    \"epoch_loss\", \"cls_max_mean\", \"cls_max_p95\",\n",
    "    \"keep_rate@0.1\", \"keep_rate@0.2\", \"keep_rate@0.3\",\n",
    "    \"img_forged_mean\", \"mask_max_mean\", \"w_mask_cls\",\n",
    "]\n",
    "for c in num_cols:\n",
    "    es[c] = pd.to_numeric(es[c], errors=\"coerce\")\n",
    "\n",
    "last_epoch = (\n",
    "    es.sort_values([\"fold\", \"epoch\"])\n",
    "      .groupby(\"fold\", as_index=False)\n",
    "      .tail(1)\n",
    "      .sort_values(\"fold\")\n",
    ")\n",
    "\n",
    "# Per-fold last-epoch snapshot\n",
    "display(\n",
    "    last_epoch[[\"fold\", \"epoch\"] + num_cols]\n",
    "      .sort_values(\"fold\")\n",
    "      .reset_index(drop=True)\n",
    ")\n",
    "\n",
    "# Cross-fold mean/std at last epoch\n",
    "agg = last_epoch[num_cols].agg([\"mean\", \"std\"]).T\n",
    "agg.columns = [\"mean\", \"std\"]\n",
    "display(agg.sort_values(\"mean\"))\n",
    "\n",
    "# Quick red-flag table at last epoch\n",
    "flags = last_epoch.assign(\n",
    "    cls_dead = last_epoch[\"cls_max_p95\"] < 0.05,\n",
    "    keep_dead = last_epoch[\"keep_rate@0.2\"] < 0.01,\n",
    "    mask_dead = last_epoch[\"mask_max_mean\"] < 0.05,\n",
    "    auth_all_auth = last_epoch[\"img_forged_mean\"] < 0.05,\n",
    ").loc[:, [\"fold\", \"epoch\", \"cls_dead\", \"keep_dead\", \"mask_dead\", \"auth_all_auth\"]]\n",
    "display(flags)\n",
    "\n",
    "# Trend vs epoch (pooled across folds): corr with epoch\n",
    "trend_cols = [\"epoch\"] + num_cols\n",
    "trend_corr = es[trend_cols].corr(numeric_only=True)[\"epoch\"].drop(\"epoch\").sort_values()\n",
    "display(trend_corr.to_frame(\"corr_with_epoch\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "bf6aa621",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "debug_events shape: (4517134, 54)\n",
      "cols: ['tag', 'fold', 'epoch', 'global_step', 'img_label', 'masks_shape', 'masks_sum', 'b', 'Q', 'Hm', 'Wm', 'tgt_shape', 'tgt_numel', 'tgt_sum', 'cost_shape', 'matched', 'num_gt', 'B', 'pos', 'total', 'pos_frac', 'thr', 'temp', 'authentic_frac', 'per_image_penalty_mean', 'loss_auth_penalty', 'reason', 'per_image', 'mask_probs', 'class_probs', 'img_probs', 'val_samples', 'masks_empty', 'gate_fail', 'num_keep0', 'cls_filtered_all_fg', 'rates', 'max_cls_prob', 'max_mask_prob', 'presence_mean', 'presence_min', 'presence_max', 'tau', 'loss_presence_auth', 'loss_forged_presence', 'fg_prob_per_query', 'fg_prob_mean', 'fg_prob_p95', 'fg_prob_max', 'no_fg_pre_keep', 'pred_auth_frac', 'pred_non_auth_count', 'pred_non_auth_area_ratio_mean', '_source']\n",
      "\n",
      "=== OOF inference debug summary (per fold: counts, rates, max probs) ===\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fold</th>\n",
       "      <th>val_samples</th>\n",
       "      <th>masks_empty</th>\n",
       "      <th>gate_fail</th>\n",
       "      <th>num_keep0</th>\n",
       "      <th>cls_filtered_all_fg</th>\n",
       "      <th>no_fg_pre_keep</th>\n",
       "      <th>rates.masks_empty</th>\n",
       "      <th>rates.gate_fail</th>\n",
       "      <th>rates.num_keep0</th>\n",
       "      <th>rates.cls_filtered_all_fg</th>\n",
       "      <th>rates.no_fg_pre_keep</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>388578</th>\n",
       "      <td>1</td>\n",
       "      <td>1726.0</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.504056</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.477404</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>625806</th>\n",
       "      <td>1</td>\n",
       "      <td>1726.0</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.461182</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.973349</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>729329</th>\n",
       "      <td>1</td>\n",
       "      <td>1726.0</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.600232</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.904983</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>953632</th>\n",
       "      <td>1</td>\n",
       "      <td>1726.0</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.396871</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.855736</td>\n",
       "      <td>0.144264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1009711</th>\n",
       "      <td>1</td>\n",
       "      <td>1726.0</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0.437428</td>\n",
       "      <td>0.437428</td>\n",
       "      <td>0.196408</td>\n",
       "      <td>0.437428</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1234015</th>\n",
       "      <td>1</td>\n",
       "      <td>1726.0</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0.355156</td>\n",
       "      <td>0.355156</td>\n",
       "      <td>0.012746</td>\n",
       "      <td>0.355156</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1290094</th>\n",
       "      <td>1</td>\n",
       "      <td>1726.0</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.408459</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.833140</td>\n",
       "      <td>0.166860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2001927</th>\n",
       "      <td>2</td>\n",
       "      <td>1725.0</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.379130</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2239205</th>\n",
       "      <td>2</td>\n",
       "      <td>1725.0</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.436522</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.899710</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2342748</th>\n",
       "      <td>2</td>\n",
       "      <td>1725.0</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>0.442319</td>\n",
       "      <td>0.442319</td>\n",
       "      <td>0.313623</td>\n",
       "      <td>0.442319</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2567091</th>\n",
       "      <td>2</td>\n",
       "      <td>1725.0</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0.543768</td>\n",
       "      <td>0.543768</td>\n",
       "      <td>0.416812</td>\n",
       "      <td>0.543768</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2623180</th>\n",
       "      <td>2</td>\n",
       "      <td>1725.0</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.206957</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.998841</td>\n",
       "      <td>0.001159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2847524</th>\n",
       "      <td>2</td>\n",
       "      <td>1725.0</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0.461449</td>\n",
       "      <td>0.461449</td>\n",
       "      <td>0.316522</td>\n",
       "      <td>0.461449</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2903613</th>\n",
       "      <td>2</td>\n",
       "      <td>1725.0</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0.415072</td>\n",
       "      <td>0.415072</td>\n",
       "      <td>0.079420</td>\n",
       "      <td>0.415072</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3615446</th>\n",
       "      <td>3</td>\n",
       "      <td>1725.0</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.409275</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.949565</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3852724</th>\n",
       "      <td>3</td>\n",
       "      <td>1725.0</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.426087</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.722319</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3956267</th>\n",
       "      <td>3</td>\n",
       "      <td>1725.0</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>0.913623</td>\n",
       "      <td>0.740290</td>\n",
       "      <td>0.913623</td>\n",
       "      <td>0.786087</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4180610</th>\n",
       "      <td>3</td>\n",
       "      <td>1725.0</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0.386087</td>\n",
       "      <td>0.386087</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.386087</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4236699</th>\n",
       "      <td>3</td>\n",
       "      <td>1725.0</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>0.780290</td>\n",
       "      <td>0.282899</td>\n",
       "      <td>0.779710</td>\n",
       "      <td>0.779710</td>\n",
       "      <td>0.000580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4461043</th>\n",
       "      <td>3</td>\n",
       "      <td>1725.0</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.410435</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.804638</td>\n",
       "      <td>0.195362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4517132</th>\n",
       "      <td>3</td>\n",
       "      <td>1725.0</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>0.738551</td>\n",
       "      <td>0.281739</td>\n",
       "      <td>0.738551</td>\n",
       "      <td>0.729275</td>\n",
       "      <td>0.009275</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         fold  val_samples  masks_empty  gate_fail  num_keep0  \\\n",
       "388578      1       1726.0         True       True       True   \n",
       "625806      1       1726.0         True       True       True   \n",
       "729329      1       1726.0         True       True       True   \n",
       "953632      1       1726.0         True       True       True   \n",
       "1009711     1       1726.0         True       True       True   \n",
       "1234015     1       1726.0         True       True       True   \n",
       "1290094     1       1726.0         True       True       True   \n",
       "2001927     2       1725.0         True       True       True   \n",
       "2239205     2       1725.0         True       True       True   \n",
       "2342748     2       1725.0         True       True       True   \n",
       "2567091     2       1725.0         True       True       True   \n",
       "2623180     2       1725.0         True       True       True   \n",
       "2847524     2       1725.0         True       True       True   \n",
       "2903613     2       1725.0         True       True       True   \n",
       "3615446     3       1725.0         True       True       True   \n",
       "3852724     3       1725.0         True       True       True   \n",
       "3956267     3       1725.0         True       True       True   \n",
       "4180610     3       1725.0         True       True      False   \n",
       "4236699     3       1725.0         True       True       True   \n",
       "4461043     3       1725.0         True       True       True   \n",
       "4517132     3       1725.0         True       True       True   \n",
       "\n",
       "         cls_filtered_all_fg  no_fg_pre_keep  rates.masks_empty  \\\n",
       "388578                  True            True           1.000000   \n",
       "625806                  True            True           1.000000   \n",
       "729329                  True            True           1.000000   \n",
       "953632                  True            True           1.000000   \n",
       "1009711                 True           False           0.437428   \n",
       "1234015                 True           False           0.355156   \n",
       "1290094                 True            True           1.000000   \n",
       "2001927                 True            True           1.000000   \n",
       "2239205                 True            True           1.000000   \n",
       "2342748                 True            True           0.442319   \n",
       "2567091                 True           False           0.543768   \n",
       "2623180                 True            True           1.000000   \n",
       "2847524                 True           False           0.461449   \n",
       "2903613                 True           False           0.415072   \n",
       "3615446                 True            True           1.000000   \n",
       "3852724                 True            True           1.000000   \n",
       "3956267                 True            True           0.913623   \n",
       "4180610                 True           False           0.386087   \n",
       "4236699                 True            True           0.780290   \n",
       "4461043                 True            True           1.000000   \n",
       "4517132                 True            True           0.738551   \n",
       "\n",
       "         rates.gate_fail  rates.num_keep0  rates.cls_filtered_all_fg  \\\n",
       "388578          0.504056         1.000000                   0.477404   \n",
       "625806          0.461182         1.000000                   0.973349   \n",
       "729329          0.600232         1.000000                   0.904983   \n",
       "953632          0.396871         1.000000                   0.855736   \n",
       "1009711         0.437428         0.196408                   0.437428   \n",
       "1234015         0.355156         0.012746                   0.355156   \n",
       "1290094         0.408459         1.000000                   0.833140   \n",
       "2001927         0.379130         1.000000                   1.000000   \n",
       "2239205         0.436522         1.000000                   0.899710   \n",
       "2342748         0.442319         0.313623                   0.442319   \n",
       "2567091         0.543768         0.416812                   0.543768   \n",
       "2623180         0.206957         1.000000                   0.998841   \n",
       "2847524         0.461449         0.316522                   0.461449   \n",
       "2903613         0.415072         0.079420                   0.415072   \n",
       "3615446         0.409275         1.000000                   0.949565   \n",
       "3852724         0.426087         1.000000                   0.722319   \n",
       "3956267         0.740290         0.913623                   0.786087   \n",
       "4180610         0.386087         0.000000                   0.386087   \n",
       "4236699         0.282899         0.779710                   0.779710   \n",
       "4461043         0.410435         1.000000                   0.804638   \n",
       "4517132         0.281739         0.738551                   0.729275   \n",
       "\n",
       "         rates.no_fg_pre_keep  \n",
       "388578                    NaN  \n",
       "625806                    NaN  \n",
       "729329                    NaN  \n",
       "953632               0.144264  \n",
       "1009711              0.000000  \n",
       "1234015              0.000000  \n",
       "1290094              0.166860  \n",
       "2001927                   NaN  \n",
       "2239205                   NaN  \n",
       "2342748                   NaN  \n",
       "2567091              0.000000  \n",
       "2623180              0.001159  \n",
       "2847524              0.000000  \n",
       "2903613              0.000000  \n",
       "3615446                   NaN  \n",
       "3852724                   NaN  \n",
       "3956267                   NaN  \n",
       "4180610              0.000000  \n",
       "4236699              0.000580  \n",
       "4461043              0.195362  \n",
       "4517132              0.009275  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== OOF inference debug summary (global weighted failure rates) ===\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>weighted_rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>masks_empty</th>\n",
       "      <td>0.000580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gate_fail</th>\n",
       "      <td>0.000580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>num_keep0</th>\n",
       "      <td>0.000552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cls_filtered_all_fg</th>\n",
       "      <td>0.000580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>no_fg_pre_keep</th>\n",
       "      <td>0.000414</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     weighted_rate\n",
       "masks_empty               0.000580\n",
       "gate_fail                 0.000580\n",
       "num_keep0                 0.000552\n",
       "cls_filtered_all_fg       0.000580\n",
       "no_fg_pre_keep            0.000414"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Presence coupling stats (loss_presence_stats: last epoch per fold + mean/std) ===\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fold</th>\n",
       "      <th>epoch</th>\n",
       "      <th>presence_mean</th>\n",
       "      <th>presence_min</th>\n",
       "      <th>presence_max</th>\n",
       "      <th>tau</th>\n",
       "      <th>loss_presence_auth</th>\n",
       "      <th>loss_forged_presence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1234013</th>\n",
       "      <td>1</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.685354</td>\n",
       "      <td>0.474314</td>\n",
       "      <td>0.896393</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.427631</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2847522</th>\n",
       "      <td>2</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.537691</td>\n",
       "      <td>0.341625</td>\n",
       "      <td>0.870654</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.574902</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4461041</th>\n",
       "      <td>3</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.199717</td>\n",
       "      <td>0.055489</td>\n",
       "      <td>0.287395</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.888506</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         fold  epoch  presence_mean  presence_min  presence_max  tau  \\\n",
       "1234013     1   20.0       0.685354      0.474314      0.896393  0.1   \n",
       "2847522     2   20.0       0.537691      0.341625      0.870654  0.1   \n",
       "4461041     3   20.0       0.199717      0.055489      0.287395  0.1   \n",
       "\n",
       "         loss_presence_auth  loss_forged_presence  \n",
       "1234013            0.427631                   0.0  \n",
       "2847522            0.574902                   0.0  \n",
       "4461041            0.888506                   0.0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>presence_mean</th>\n",
       "      <td>0.474254</td>\n",
       "      <td>2.489555e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>presence_min</th>\n",
       "      <td>0.290476</td>\n",
       "      <td>2.140459e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>presence_max</th>\n",
       "      <td>0.684814</td>\n",
       "      <td>3.444154e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tau</th>\n",
       "      <td>0.100000</td>\n",
       "      <td>1.699675e-17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>loss_presence_auth</th>\n",
       "      <td>0.630346</td>\n",
       "      <td>2.353868e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>loss_forged_presence</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          mean           std\n",
       "presence_mean         0.474254  2.489555e-01\n",
       "presence_min          0.290476  2.140459e-01\n",
       "presence_max          0.684814  3.444154e-01\n",
       "tau                   0.100000  1.699675e-17\n",
       "loss_presence_auth    0.630346  2.353868e-01\n",
       "loss_forged_presence  0.000000  0.000000e+00"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Authenticity penalty stats (loss_auth_penalty_stats: last epoch per fold + mean/std) ===\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fold</th>\n",
       "      <th>epoch</th>\n",
       "      <th>thr</th>\n",
       "      <th>temp</th>\n",
       "      <th>authentic_frac</th>\n",
       "      <th>per_image_penalty_mean</th>\n",
       "      <th>loss_auth_penalty</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>625805</th>\n",
       "      <td>1</td>\n",
       "      <td>25.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.198248e-17</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2239204</th>\n",
       "      <td>2</td>\n",
       "      <td>25.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>1.384936e-15</td>\n",
       "      <td>8.648611e-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3852723</th>\n",
       "      <td>3</td>\n",
       "      <td>25.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>9.730406e-17</td>\n",
       "      <td>1.960069e-17</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         fold  epoch  thr  temp  authentic_frac  per_image_penalty_mean  \\\n",
       "625805      1   25.0  0.5   0.1        0.000000            8.198248e-17   \n",
       "2239204     2   25.0  0.5   0.1        0.333333            1.384936e-15   \n",
       "3852723     3   25.0  0.5   0.1        0.333333            9.730406e-17   \n",
       "\n",
       "         loss_auth_penalty  \n",
       "625805        0.000000e+00  \n",
       "2239204       8.648611e-16  \n",
       "3852723       1.960069e-17  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>thr</th>\n",
       "      <td>5.000000e-01</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>temp</th>\n",
       "      <td>1.000000e-01</td>\n",
       "      <td>1.699675e-17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>authentic_frac</th>\n",
       "      <td>2.222222e-01</td>\n",
       "      <td>1.924501e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>per_image_penalty_mean</th>\n",
       "      <td>5.214076e-16</td>\n",
       "      <td>7.478769e-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>loss_auth_penalty</th>\n",
       "      <td>2.948206e-16</td>\n",
       "      <td>4.937668e-16</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                mean           std\n",
       "thr                     5.000000e-01  0.000000e+00\n",
       "temp                    1.000000e-01  1.699675e-17\n",
       "authentic_frac          2.222222e-01  1.924501e-01\n",
       "per_image_penalty_mean  5.214076e-16  7.478769e-16\n",
       "loss_auth_penalty       2.948206e-16  4.937668e-16"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Class-target balance (loss_cls_targets: pos_frac across folds) ===\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"4\" halign=\"left\">pos_frac</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fold</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.068194</td>\n",
       "      <td>0.050033</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.483333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.076852</td>\n",
       "      <td>0.055463</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.516667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.076432</td>\n",
       "      <td>0.055638</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      pos_frac                         \n",
       "          mean       std  min       max\n",
       "fold                                   \n",
       "1     0.068194  0.050033  0.0  0.483333\n",
       "2     0.076852  0.055463  0.0  0.516667\n",
       "3     0.076432  0.055638  0.0  0.500000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Hungarian matching input health (tgt masks: numel / sum / shape) ===\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fold</th>\n",
       "      <th>epoch</th>\n",
       "      <th>tgt_numel</th>\n",
       "      <th>tgt_sum</th>\n",
       "      <th>tgt_shape</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1.538848e+06</td>\n",
       "      <td>1.538848e+06</td>\n",
       "      <td>1.538848e+06</td>\n",
       "      <td>1.538848e+06</td>\n",
       "      <td>1538848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[0, 256, 256]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>710259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2.076442e+00</td>\n",
       "      <td>1.131180e+01</td>\n",
       "      <td>7.303582e+04</td>\n",
       "      <td>1.984829e+03</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>7.970842e-01</td>\n",
       "      <td>7.044080e+00</td>\n",
       "      <td>9.580103e+04</td>\n",
       "      <td>3.839342e+03</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>5.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>2.000000e+00</td>\n",
       "      <td>1.100000e+01</td>\n",
       "      <td>6.553600e+04</td>\n",
       "      <td>2.040000e+02</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>3.000000e+00</td>\n",
       "      <td>1.700000e+01</td>\n",
       "      <td>1.310720e+05</td>\n",
       "      <td>2.263000e+03</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>3.000000e+00</td>\n",
       "      <td>2.500000e+01</td>\n",
       "      <td>1.245184e+06</td>\n",
       "      <td>3.444500e+04</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                fold         epoch     tgt_numel       tgt_sum      tgt_shape\n",
       "count   1.538848e+06  1.538848e+06  1.538848e+06  1.538848e+06        1538848\n",
       "unique           NaN           NaN           NaN           NaN             16\n",
       "top              NaN           NaN           NaN           NaN  [0, 256, 256]\n",
       "freq             NaN           NaN           NaN           NaN         710259\n",
       "mean    2.076442e+00  1.131180e+01  7.303582e+04  1.984829e+03            NaN\n",
       "std     7.970842e-01  7.044080e+00  9.580103e+04  3.839342e+03            NaN\n",
       "min     1.000000e+00  1.000000e+00  0.000000e+00  0.000000e+00            NaN\n",
       "25%     1.000000e+00  5.000000e+00  0.000000e+00  0.000000e+00            NaN\n",
       "50%     2.000000e+00  1.100000e+01  6.553600e+04  2.040000e+02            NaN\n",
       "75%     3.000000e+00  1.700000e+01  1.310720e+05  2.263000e+03            NaN\n",
       "max     3.000000e+00  2.500000e+01  1.245184e+06  3.444500e+04            NaN"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Hungarian matching results (matched vs num_gt, empty_gt reasons) ===\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fold</th>\n",
       "      <th>reason</th>\n",
       "      <th>rows</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>empty_gt</td>\n",
       "      <td>200469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>234059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>empty_gt</td>\n",
       "      <td>255165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>296995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>empty_gt</td>\n",
       "      <td>254625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>297535</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fold    reason    rows\n",
       "0     1  empty_gt  200469\n",
       "1     1       NaN  234059\n",
       "2     2  empty_gt  255165\n",
       "3     2       NaN  296995\n",
       "4     3  empty_gt  254625\n",
       "5     3       NaN  297535"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fold</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.022963</td>\n",
       "      <td>1.342090</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.152791</td>\n",
       "      <td>1.496995</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.146443</td>\n",
       "      <td>1.495714</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          mean       std  min   max\n",
       "fold                               \n",
       "1     1.022963  1.342090  0.0  15.0\n",
       "2     1.152791  1.496995  0.0  15.0\n",
       "3     1.146443  1.495714  0.0  15.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Mask-head liveness during training (train_fg_prob_per_query: last epoch) ===\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fold</th>\n",
       "      <th>epoch</th>\n",
       "      <th>Q</th>\n",
       "      <th>fg_prob_mean</th>\n",
       "      <th>fg_prob_p95</th>\n",
       "      <th>fg_prob_max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1234012</th>\n",
       "      <td>1</td>\n",
       "      <td>20.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0.536614</td>\n",
       "      <td>0.995169</td>\n",
       "      <td>0.995221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2847521</th>\n",
       "      <td>2</td>\n",
       "      <td>20.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0.090145</td>\n",
       "      <td>0.419214</td>\n",
       "      <td>0.999983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4461040</th>\n",
       "      <td>3</td>\n",
       "      <td>20.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0.410109</td>\n",
       "      <td>0.736051</td>\n",
       "      <td>0.872851</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         fold  epoch     Q  fg_prob_mean  fg_prob_p95  fg_prob_max\n",
       "1234012     1   20.0  15.0      0.536614     0.995169     0.995221\n",
       "2847521     2   20.0  15.0      0.090145     0.419214     0.999983\n",
       "4461040     3   20.0  15.0      0.410109     0.736051     0.872851"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Mask-head per-query foreground distribution (last epoch, exploded) ===\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fold</th>\n",
       "      <th>mean</th>\n",
       "      <th>p95</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.536614</td>\n",
       "      <td>0.995169</td>\n",
       "      <td>0.995221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.090145</td>\n",
       "      <td>0.419214</td>\n",
       "      <td>0.999983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.410108</td>\n",
       "      <td>0.736051</td>\n",
       "      <td>0.872851</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fold      mean       p95       max\n",
       "0     1  0.536614  0.995169  0.995221\n",
       "1     2  0.090145  0.419214  0.999983\n",
       "2     3  0.410108  0.736051  0.872851"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== One-time logits/probability sanity snapshots (debug_probs) ===\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fold</th>\n",
       "      <th>epoch</th>\n",
       "      <th>global_step</th>\n",
       "      <th>mask_probs.mean</th>\n",
       "      <th>mask_probs.p95</th>\n",
       "      <th>mask_probs.max</th>\n",
       "      <th>mask_probs.frac_gt_0p5</th>\n",
       "      <th>class_probs.mean</th>\n",
       "      <th>class_probs.max</th>\n",
       "      <th>class_probs.frac_gt_0p1</th>\n",
       "      <th>img_probs.mean</th>\n",
       "      <th>img_probs.max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>151353</th>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.326855</td>\n",
       "      <td>0.951958</td>\n",
       "      <td>0.999967</td>\n",
       "      <td>0.294145</td>\n",
       "      <td>0.343201</td>\n",
       "      <td>0.398486</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.512244</td>\n",
       "      <td>0.515834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>388581</th>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.336805</td>\n",
       "      <td>0.954254</td>\n",
       "      <td>0.999995</td>\n",
       "      <td>0.308744</td>\n",
       "      <td>0.348552</td>\n",
       "      <td>0.409816</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.513045</td>\n",
       "      <td>0.519819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>625809</th>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.282438</td>\n",
       "      <td>0.929600</td>\n",
       "      <td>0.999995</td>\n",
       "      <td>0.255082</td>\n",
       "      <td>0.344200</td>\n",
       "      <td>0.409816</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.512113</td>\n",
       "      <td>0.517592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>729332</th>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.308088</td>\n",
       "      <td>0.950631</td>\n",
       "      <td>0.999999</td>\n",
       "      <td>0.283683</td>\n",
       "      <td>0.346655</td>\n",
       "      <td>0.398486</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.512678</td>\n",
       "      <td>0.520946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>953636</th>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.312324</td>\n",
       "      <td>0.949372</td>\n",
       "      <td>0.999966</td>\n",
       "      <td>0.287016</td>\n",
       "      <td>0.339520</td>\n",
       "      <td>0.398486</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.511916</td>\n",
       "      <td>0.517365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1009715</th>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.302411</td>\n",
       "      <td>0.946386</td>\n",
       "      <td>0.999967</td>\n",
       "      <td>0.279248</td>\n",
       "      <td>0.341467</td>\n",
       "      <td>0.398486</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.511783</td>\n",
       "      <td>0.517365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1234019</th>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.298773</td>\n",
       "      <td>0.945339</td>\n",
       "      <td>0.999967</td>\n",
       "      <td>0.278674</td>\n",
       "      <td>0.346324</td>\n",
       "      <td>0.398486</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.513472</td>\n",
       "      <td>0.519819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1290098</th>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.680387</td>\n",
       "      <td>0.998619</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.715739</td>\n",
       "      <td>0.365509</td>\n",
       "      <td>0.435480</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.497880</td>\n",
       "      <td>0.511066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1527375</th>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.688203</td>\n",
       "      <td>0.999112</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.721704</td>\n",
       "      <td>0.366493</td>\n",
       "      <td>0.437016</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.496629</td>\n",
       "      <td>0.505066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1764652</th>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.749124</td>\n",
       "      <td>0.999781</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.785486</td>\n",
       "      <td>0.365972</td>\n",
       "      <td>0.431055</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.492477</td>\n",
       "      <td>0.498755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2001930</th>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.758492</td>\n",
       "      <td>0.999828</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.790906</td>\n",
       "      <td>0.368057</td>\n",
       "      <td>0.434608</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.491302</td>\n",
       "      <td>0.495456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2239208</th>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.553269</td>\n",
       "      <td>0.976719</td>\n",
       "      <td>0.999995</td>\n",
       "      <td>0.575387</td>\n",
       "      <td>0.598913</td>\n",
       "      <td>0.682038</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.523003</td>\n",
       "      <td>0.526959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2342751</th>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.058101</td>\n",
       "      <td>0.349999</td>\n",
       "      <td>0.990789</td>\n",
       "      <td>0.029232</td>\n",
       "      <td>0.616394</td>\n",
       "      <td>0.702232</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.497535</td>\n",
       "      <td>0.504413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2567095</th>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.884733</td>\n",
       "      <td>0.999837</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.924585</td>\n",
       "      <td>0.436227</td>\n",
       "      <td>0.515985</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.514641</td>\n",
       "      <td>0.517240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2623184</th>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.053815</td>\n",
       "      <td>0.321875</td>\n",
       "      <td>0.984451</td>\n",
       "      <td>0.026274</td>\n",
       "      <td>0.617752</td>\n",
       "      <td>0.705796</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.496012</td>\n",
       "      <td>0.504413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2847528</th>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.886822</td>\n",
       "      <td>0.999854</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.923873</td>\n",
       "      <td>0.435675</td>\n",
       "      <td>0.510864</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.515253</td>\n",
       "      <td>0.518362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2903617</th>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.034498</td>\n",
       "      <td>0.195017</td>\n",
       "      <td>0.989769</td>\n",
       "      <td>0.018148</td>\n",
       "      <td>0.491090</td>\n",
       "      <td>0.577872</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.488813</td>\n",
       "      <td>0.501427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3140894</th>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.039058</td>\n",
       "      <td>0.235281</td>\n",
       "      <td>0.998685</td>\n",
       "      <td>0.023393</td>\n",
       "      <td>0.496149</td>\n",
       "      <td>0.581688</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.487904</td>\n",
       "      <td>0.501427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3378171</th>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.019591</td>\n",
       "      <td>0.086135</td>\n",
       "      <td>0.999568</td>\n",
       "      <td>0.009204</td>\n",
       "      <td>0.490955</td>\n",
       "      <td>0.569791</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.486524</td>\n",
       "      <td>0.494524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3615449</th>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.015814</td>\n",
       "      <td>0.073598</td>\n",
       "      <td>0.943966</td>\n",
       "      <td>0.005587</td>\n",
       "      <td>0.493709</td>\n",
       "      <td>0.576339</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.489193</td>\n",
       "      <td>0.499624</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         fold  epoch  global_step  mask_probs.mean  mask_probs.p95  \\\n",
       "151353      1    1.0          0.0         0.326855        0.951958   \n",
       "388581      1    1.0          0.0         0.336805        0.954254   \n",
       "625809      1    1.0          0.0         0.282438        0.929600   \n",
       "729332      1    1.0          0.0         0.308088        0.950631   \n",
       "953636      1    1.0          0.0         0.312324        0.949372   \n",
       "1009715     1    1.0          0.0         0.302411        0.946386   \n",
       "1234019     1    1.0          0.0         0.298773        0.945339   \n",
       "1290098     2    1.0          0.0         0.680387        0.998619   \n",
       "1527375     2    1.0          0.0         0.688203        0.999112   \n",
       "1764652     2    1.0          0.0         0.749124        0.999781   \n",
       "2001930     2    1.0          0.0         0.758492        0.999828   \n",
       "2239208     2    1.0          0.0         0.553269        0.976719   \n",
       "2342751     2    1.0          0.0         0.058101        0.349999   \n",
       "2567095     2    1.0          0.0         0.884733        0.999837   \n",
       "2623184     2    1.0          0.0         0.053815        0.321875   \n",
       "2847528     2    1.0          0.0         0.886822        0.999854   \n",
       "2903617     3    1.0          0.0         0.034498        0.195017   \n",
       "3140894     3    1.0          0.0         0.039058        0.235281   \n",
       "3378171     3    1.0          0.0         0.019591        0.086135   \n",
       "3615449     3    1.0          0.0         0.015814        0.073598   \n",
       "\n",
       "         mask_probs.max  mask_probs.frac_gt_0p5  class_probs.mean  \\\n",
       "151353         0.999967                0.294145          0.343201   \n",
       "388581         0.999995                0.308744          0.348552   \n",
       "625809         0.999995                0.255082          0.344200   \n",
       "729332         0.999999                0.283683          0.346655   \n",
       "953636         0.999966                0.287016          0.339520   \n",
       "1009715        0.999967                0.279248          0.341467   \n",
       "1234019        0.999967                0.278674          0.346324   \n",
       "1290098        1.000000                0.715739          0.365509   \n",
       "1527375        1.000000                0.721704          0.366493   \n",
       "1764652        1.000000                0.785486          0.365972   \n",
       "2001930        1.000000                0.790906          0.368057   \n",
       "2239208        0.999995                0.575387          0.598913   \n",
       "2342751        0.990789                0.029232          0.616394   \n",
       "2567095        1.000000                0.924585          0.436227   \n",
       "2623184        0.984451                0.026274          0.617752   \n",
       "2847528        1.000000                0.923873          0.435675   \n",
       "2903617        0.989769                0.018148          0.491090   \n",
       "3140894        0.998685                0.023393          0.496149   \n",
       "3378171        0.999568                0.009204          0.490955   \n",
       "3615449        0.943966                0.005587          0.493709   \n",
       "\n",
       "         class_probs.max  class_probs.frac_gt_0p1  img_probs.mean  \\\n",
       "151353          0.398486                      1.0        0.512244   \n",
       "388581          0.409816                      1.0        0.513045   \n",
       "625809          0.409816                      1.0        0.512113   \n",
       "729332          0.398486                      1.0        0.512678   \n",
       "953636          0.398486                      1.0        0.511916   \n",
       "1009715         0.398486                      1.0        0.511783   \n",
       "1234019         0.398486                      1.0        0.513472   \n",
       "1290098         0.435480                      1.0        0.497880   \n",
       "1527375         0.437016                      1.0        0.496629   \n",
       "1764652         0.431055                      1.0        0.492477   \n",
       "2001930         0.434608                      1.0        0.491302   \n",
       "2239208         0.682038                      1.0        0.523003   \n",
       "2342751         0.702232                      1.0        0.497535   \n",
       "2567095         0.515985                      1.0        0.514641   \n",
       "2623184         0.705796                      1.0        0.496012   \n",
       "2847528         0.510864                      1.0        0.515253   \n",
       "2903617         0.577872                      1.0        0.488813   \n",
       "3140894         0.581688                      1.0        0.487904   \n",
       "3378171         0.569791                      1.0        0.486524   \n",
       "3615449         0.576339                      1.0        0.489193   \n",
       "\n",
       "         img_probs.max  \n",
       "151353        0.515834  \n",
       "388581        0.519819  \n",
       "625809        0.517592  \n",
       "729332        0.520946  \n",
       "953636        0.517365  \n",
       "1009715       0.517365  \n",
       "1234019       0.519819  \n",
       "1290098       0.511066  \n",
       "1527375       0.505066  \n",
       "1764652       0.498755  \n",
       "2001930       0.495456  \n",
       "2239208       0.526959  \n",
       "2342751       0.504413  \n",
       "2567095       0.517240  \n",
       "2623184       0.504413  \n",
       "2847528       0.518362  \n",
       "2903617       0.501427  \n",
       "3140894       0.501427  \n",
       "3378171       0.494524  \n",
       "3615449       0.499624  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# --- Load ALL debug events ---\n",
    "dbg = debug_events.copy() if \"debug_events\" in globals() else pd.DataFrame()\n",
    "print(\"debug_events shape:\", dbg.shape)\n",
    "print(\"cols:\", list(dbg.columns))\n",
    "\n",
    "if len(dbg) == 0:\n",
    "    raise ValueError(\"debug_events is empty\")\n",
    "\n",
    "# ---------- helpers ----------\n",
    "def _to_bool(s):\n",
    "    if s.dtype == object:\n",
    "        return s.astype(str).str.lower().isin([\"true\", \"1\", \"yes\"])\n",
    "    return s.astype(bool)\n",
    "\n",
    "def _safe_num(df, cols):\n",
    "    for c in cols:\n",
    "        if c in df.columns:\n",
    "            df[c] = pd.to_numeric(df[c], errors=\"coerce\")\n",
    "    return df\n",
    "\n",
    "def _flatten_dict_col(df, col, prefix=None):\n",
    "    \"\"\"Flatten a dict-valued column into separate columns, preserving row alignment.\"\"\"\n",
    "    if col not in df.columns:\n",
    "        return df\n",
    "    pfx = prefix or col\n",
    "\n",
    "    ser = df[col]\n",
    "    mask = ser.apply(lambda x: isinstance(x, dict))\n",
    "    if not mask.any():\n",
    "        return df\n",
    "\n",
    "    flat = pd.json_normalize(ser[mask])\n",
    "    flat.index = ser[mask].index  # IMPORTANT: align with original rows\n",
    "    flat.columns = [f\"{pfx}.{k}\" for k in flat.columns]\n",
    "\n",
    "    df = df.drop(columns=[col])\n",
    "    df = df.join(flat, how=\"left\")\n",
    "    return df\n",
    "\n",
    "def p95(x):\n",
    "    x = pd.to_numeric(x, errors=\"coerce\").dropna()\n",
    "    return float(x.quantile(0.95)) if len(x) else np.nan\n",
    "\n",
    "# ---------- coerce types ----------\n",
    "dbg = _safe_num(dbg, [\n",
    "    \"fold\",\"epoch\",\"global_step\",\"img_label\",\"matched\",\"num_gt\",\"pos\",\"total\",\"pos_frac\",\n",
    "    \"thr\",\"temp\",\"authentic_frac\",\"per_image_penalty_mean\",\"loss_auth_penalty\",\n",
    "    \"val_samples\",\"masks_empty\",\"gate_fail\",\"num_keep0\",\"cls_filtered_all_fg\",\"no_fg_pre_keep\",\n",
    "    \"max_cls_prob\",\"max_mask_prob\",\n",
    "    \"presence_mean\",\"presence_min\",\"presence_max\",\"tau\",\"loss_presence_auth\",\"loss_forged_presence\",\n",
    "    \"fg_prob_mean\",\"fg_prob_p95\",\"fg_prob_max\",\n",
    "    \"pred_auth_frac\",\"pred_non_auth_count\",\"pred_non_auth_area_ratio_mean\",\n",
    "])\n",
    "\n",
    "# bool-ish flags\n",
    "for c in [\"masks_empty\",\"gate_fail\",\"num_keep0\",\"cls_filtered_all_fg\",\"no_fg_pre_keep\"]:\n",
    "    if c in dbg.columns:\n",
    "        dbg[c] = _to_bool(dbg[c])\n",
    "\n",
    "# flatten nested dict payloads so they become aggregatable\n",
    "for col in [\"rates\", \"mask_probs\", \"class_probs\", \"img_probs\"]:\n",
    "    dbg = _flatten_dict_col(dbg, col)\n",
    "\n",
    "# ---------- OOF inference debug summary (tag == oof_inference_debug) ----------\n",
    "print(\"\\n=== OOF inference debug summary (per fold: counts, rates, max probs) ===\")\n",
    "oof = dbg[dbg[\"tag\"].astype(str).eq(\"oof_inference_debug\")].copy()\n",
    "if len(oof):\n",
    "    # per-fold (uses the already-aggregated counts/rates from train_cv)\n",
    "    show_cols = [c for c in [\n",
    "        \"fold\",\"val_samples\",\"masks_empty\",\"gate_fail\",\"num_keep0\",\"cls_filtered_all_fg\",\"no_fg_pre_keep\",\n",
    "        \"rates.masks_empty\",\"rates.gate_fail\",\"rates.num_keep0\",\"rates.cls_filtered_all_fg\",\"rates.no_fg_pre_keep\",\n",
    "        \"max_cls_prob.mean\",\"max_cls_prob.p95\",\"max_cls_prob.max\",\n",
    "        \"max_mask_prob.mean\",\"max_mask_prob.p95\",\"max_mask_prob.max\",\n",
    "    ] if c in oof.columns]\n",
    "    display(oof.sort_values(\"fold\")[show_cols])\n",
    "\n",
    "    # global weighted rates across folds\n",
    "    print(\"\\n=== OOF inference debug summary (global weighted failure rates) ===\")\n",
    "    w = oof[\"val_samples\"].astype(float).replace(0, np.nan)\n",
    "    global_rates = {}\n",
    "    for k in [\"masks_empty\",\"gate_fail\",\"num_keep0\",\"cls_filtered_all_fg\",\"no_fg_pre_keep\"]:\n",
    "        if k in oof.columns:\n",
    "            global_rates[k] = float((oof[k].astype(float) / w).mul(w).sum() / w.sum())\n",
    "    display(pd.Series(global_rates, name=\"weighted_rate\").to_frame())\n",
    "\n",
    "# ---------- Presence coupling stats (tag == loss_presence_stats) ----------\n",
    "print(\"\\n=== Presence coupling stats (loss_presence_stats: last epoch per fold + mean/std) ===\")\n",
    "pres = dbg[dbg[\"tag\"].astype(str).eq(\"loss_presence_stats\")].copy()\n",
    "if len(pres):\n",
    "    cols = [c for c in [\"fold\",\"epoch\",\"presence_mean\",\"presence_min\",\"presence_max\",\"tau\",\"loss_presence_auth\",\"loss_forged_presence\"] if c in pres.columns]\n",
    "    per_fold_last = (pres.sort_values([\"fold\",\"epoch\"]).groupby(\"fold\", as_index=False).tail(1))[cols]\n",
    "    display(per_fold_last.sort_values(\"fold\"))\n",
    "    display(per_fold_last.drop(columns=[\"fold\",\"epoch\"], errors=\"ignore\").agg([\"mean\",\"std\"]).T)\n",
    "\n",
    "# ---------- Auth penalty stats (tag == loss_auth_penalty_stats) ----------\n",
    "print(\"\\n=== Authenticity penalty stats (loss_auth_penalty_stats: last epoch per fold + mean/std) ===\")\n",
    "ap = dbg[dbg[\"tag\"].astype(str).eq(\"loss_auth_penalty_stats\")].copy()\n",
    "if len(ap):\n",
    "    cols = [c for c in [\"fold\",\"epoch\",\"thr\",\"temp\",\"authentic_frac\",\"per_image_penalty_mean\",\"loss_auth_penalty\"] if c in ap.columns]\n",
    "    per_fold_last = (ap.sort_values([\"fold\",\"epoch\"]).groupby(\"fold\", as_index=False).tail(1))[cols]\n",
    "    display(per_fold_last.sort_values(\"fold\"))\n",
    "    display(per_fold_last.drop(columns=[\"fold\",\"epoch\"], errors=\"ignore\").agg([\"mean\",\"std\"]).T)\n",
    "\n",
    "# ---------- Class target balance (tag == loss_cls_targets) ----------\n",
    "print(\"\\n=== Class-target balance (loss_cls_targets: pos_frac across folds) ===\")\n",
    "ct = dbg[dbg[\"tag\"].astype(str).eq(\"loss_cls_targets\")].copy()\n",
    "if len(ct):\n",
    "    cols = [c for c in [\"fold\",\"epoch\",\"B\",\"Q\",\"pos\",\"total\",\"pos_frac\"] if c in ct.columns]\n",
    "    display(\n",
    "        ct.groupby(\"fold\", dropna=False)[[\"pos_frac\"]]\n",
    "          .agg([\"mean\",\"std\",\"min\",\"max\"])\n",
    "    )\n",
    "\n",
    "# ---------- Hungarian matching health (tags == hungarian_match_*) ----------\n",
    "print(\"\\n=== Hungarian matching input health (tgt masks: numel / sum / shape) ===\")\n",
    "hm_in = dbg[dbg[\"tag\"].astype(str).eq(\"hungarian_match_input\")].copy()\n",
    "hm_out = dbg[dbg[\"tag\"].astype(str).eq(\"hungarian_match_result\")].copy()\n",
    "\n",
    "if len(hm_in):\n",
    "    cols = [c for c in [\"fold\",\"epoch\",\"tgt_numel\",\"tgt_sum\",\"tgt_shape\"] if c in hm_in.columns]\n",
    "    display(hm_in[cols].describe(include=\"all\"))\n",
    "\n",
    "if len(hm_out):\n",
    "    print(\"\\n=== Hungarian matching results (matched vs num_gt, empty_gt reasons) ===\")\n",
    "    cols = [c for c in [\"fold\",\"epoch\",\"matched\",\"num_gt\",\"reason\"] if c in hm_out.columns]\n",
    "    # how often empty_gt happens, and typical matched counts when GT exists\n",
    "    display(hm_out.groupby([\"fold\",\"reason\"], dropna=False).size().rename(\"rows\").reset_index())\n",
    "    if \"matched\" in hm_out.columns:\n",
    "        display(hm_out.groupby(\"fold\")[\"matched\"].agg([\"mean\",\"std\",\"min\",\"max\"]))\n",
    "\n",
    "# ---------- Mask-head alive signal during training (tag == train_fg_prob_per_query) ----------\n",
    "print(\"\\n=== Mask-head liveness during training (train_fg_prob_per_query: last epoch) ===\")\n",
    "fgq = dbg[dbg[\"tag\"].astype(str).eq(\"train_fg_prob_per_query\")].copy()\n",
    "if len(fgq):\n",
    "    cols = [c for c in [\"fold\",\"epoch\",\"Q\",\"fg_prob_mean\",\"fg_prob_p95\",\"fg_prob_max\"] if c in fgq.columns]\n",
    "    per_fold_last = (fgq.sort_values([\"fold\",\"epoch\"]).groupby(\"fold\", as_index=False).tail(1))[cols]\n",
    "    display(per_fold_last.sort_values(\"fold\"))\n",
    "\n",
    "    # Summarize per-query distribution at last epoch (all folds pooled)\n",
    "    last = fgq.sort_values([\"fold\",\"epoch\"]).groupby(\"fold\", as_index=False).tail(1)\n",
    "    if \"fg_prob_per_query\" in last.columns:\n",
    "        # fg_prob_per_query is a list; explode into long form\n",
    "        s = last[[\"fold\",\"epoch\",\"fg_prob_per_query\"]].dropna()\n",
    "        s = s.explode(\"fg_prob_per_query\")\n",
    "        s[\"fg_prob_per_query\"] = pd.to_numeric(s[\"fg_prob_per_query\"], errors=\"coerce\")\n",
    "        print(\"\\n=== Mask-head per-query foreground distribution (last epoch, exploded) ===\")\n",
    "        display(\n",
    "            s.groupby(\"fold\")[\"fg_prob_per_query\"]\n",
    "             .agg(mean=\"mean\", p95=p95, max=\"max\")\n",
    "             .reset_index()\n",
    "             .sort_values(\"fold\")\n",
    "        )\n",
    "\n",
    "# ---------- One-time debug_probs snapshots (tag == debug_probs) ----------\n",
    "# These are nested dicts and now flattened into mask_probs.*, class_probs.*, img_probs.*\n",
    "print(\"\\n=== One-time logits/probability sanity snapshots (debug_probs) ===\")\n",
    "dp = dbg[dbg[\"tag\"].astype(str).eq(\"debug_probs\")].copy()\n",
    "if len(dp):\n",
    "    cols = [c for c in dp.columns if c.startswith((\"mask_probs.\",\"class_probs.\",\"img_probs.\"))]\n",
    "    show = [\"fold\",\"epoch\",\"global_step\"] + cols\n",
    "    display(dp.sort_values([\"fold\",\"epoch\",\"global_step\"]).head(20)[show])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a3f5cae",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\piiop\\AppData\\Local\\Temp\\ipykernel_29544\\3598422253.py:50: FutureWarning: errors='ignore' is deprecated and will raise in a future version. Use to_numeric without passing `errors` and catch exceptions explicitly instead\n",
      "  oof_inf_view[c] = pd.to_numeric(oof_inf_view[c], errors=\"ignore\")\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fold</th>\n",
       "      <th>val_samples</th>\n",
       "      <th>masks_empty</th>\n",
       "      <th>gate_fail</th>\n",
       "      <th>num_keep0</th>\n",
       "      <th>cls_filtered_all_fg</th>\n",
       "      <th>no_fg_pre_keep</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>388578</th>\n",
       "      <td>1</td>\n",
       "      <td>1726.0</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>625806</th>\n",
       "      <td>1</td>\n",
       "      <td>1726.0</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>729329</th>\n",
       "      <td>1</td>\n",
       "      <td>1726.0</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>953632</th>\n",
       "      <td>1</td>\n",
       "      <td>1726.0</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>249.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1009711</th>\n",
       "      <td>1</td>\n",
       "      <td>1726.0</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1234015</th>\n",
       "      <td>1</td>\n",
       "      <td>1726.0</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1945848</th>\n",
       "      <td>2</td>\n",
       "      <td>1725.0</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2183126</th>\n",
       "      <td>2</td>\n",
       "      <td>1725.0</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2286669</th>\n",
       "      <td>2</td>\n",
       "      <td>1725.0</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2511012</th>\n",
       "      <td>2</td>\n",
       "      <td>1725.0</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2567101</th>\n",
       "      <td>2</td>\n",
       "      <td>1725.0</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2791445</th>\n",
       "      <td>2</td>\n",
       "      <td>1725.0</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3503278</th>\n",
       "      <td>3</td>\n",
       "      <td>1725.0</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3740556</th>\n",
       "      <td>3</td>\n",
       "      <td>1725.0</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3844099</th>\n",
       "      <td>3</td>\n",
       "      <td>1725.0</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4068442</th>\n",
       "      <td>3</td>\n",
       "      <td>1725.0</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4124531</th>\n",
       "      <td>3</td>\n",
       "      <td>1725.0</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4348875</th>\n",
       "      <td>3</td>\n",
       "      <td>1725.0</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>337.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         fold  val_samples  masks_empty  gate_fail  num_keep0  \\\n",
       "388578      1       1726.0         True       True       True   \n",
       "625806      1       1726.0         True       True       True   \n",
       "729329      1       1726.0         True       True       True   \n",
       "953632      1       1726.0         True       True       True   \n",
       "1009711     1       1726.0         True       True       True   \n",
       "1234015     1       1726.0         True       True       True   \n",
       "1945848     2       1725.0         True       True       True   \n",
       "2183126     2       1725.0         True       True       True   \n",
       "2286669     2       1725.0         True       True       True   \n",
       "2511012     2       1725.0         True       True       True   \n",
       "2567101     2       1725.0         True       True       True   \n",
       "2791445     2       1725.0         True       True       True   \n",
       "3503278     3       1725.0         True       True       True   \n",
       "3740556     3       1725.0         True       True       True   \n",
       "3844099     3       1725.0         True       True       True   \n",
       "4068442     3       1725.0         True       True      False   \n",
       "4124531     3       1725.0         True       True       True   \n",
       "4348875     3       1725.0         True       True       True   \n",
       "\n",
       "         cls_filtered_all_fg  no_fg_pre_keep  \n",
       "388578                  True             NaN  \n",
       "625806                  True             NaN  \n",
       "729329                  True             NaN  \n",
       "953632                  True           249.0  \n",
       "1009711                 True             0.0  \n",
       "1234015                 True             0.0  \n",
       "1945848                 True             NaN  \n",
       "2183126                 True             NaN  \n",
       "2286669                 True             NaN  \n",
       "2511012                 True             0.0  \n",
       "2567101                 True             2.0  \n",
       "2791445                 True             0.0  \n",
       "3503278                 True             NaN  \n",
       "3740556                 True             NaN  \n",
       "3844099                 True             NaN  \n",
       "4068442                 True             0.0  \n",
       "4124531                 True             1.0  \n",
       "4348875                 True           337.0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Fold-level val_loader debug counts (from oof_inference_debug events)\n",
    "def _extract_debug_event(df: pd.DataFrame, tag: str) -> pd.DataFrame:\n",
    "    if df is None or len(df) == 0:\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    # Most common format: columns include [\"tag\", \"payload\", ...]\n",
    "    if \"tag\" in df.columns:\n",
    "        ev = df[df[\"tag\"].astype(str) == tag].copy()\n",
    "    else:\n",
    "        # fallback if tag was flattened into a column name\n",
    "        ev = df.copy()\n",
    "\n",
    "    if len(ev) == 0:\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    if \"payload\" in ev.columns:\n",
    "        # payload is a dict -> flatten\n",
    "        payloads = ev[\"payload\"].tolist()\n",
    "        flat = pd.json_normalize(payloads, sep=\".\")\n",
    "        # preserve fold if present as a top-level col too\n",
    "        return flat\n",
    "    else:\n",
    "        # already flattened\n",
    "        return ev\n",
    "\n",
    "# dbg should already exist from your earlier \"debug*.jsonl\" concat\n",
    "oof_inf = _extract_debug_event(dbg, \"oof_inference_debug\")\n",
    "oof_area = _extract_debug_event(dbg, \"oof_pred_area_stats\")\n",
    "\n",
    "if len(oof_inf) == 0:\n",
    "    print(\"No oof_inference_debug events found in dbg (check debug jsonl ingestion).\")\n",
    "else:\n",
    "    # keep only the key fields we care about (and anything else that exists)\n",
    "    cols = [\n",
    "        \"fold\", \"val_samples\",\n",
    "        \"masks_empty\", \"gate_fail\", \"num_keep0\", \"cls_filtered_all_fg\", \"no_fg_pre_keep\",\n",
    "        \"rates.masks_empty\", \"rates.gate_fail\", \"rates.num_keep0\", \"rates.cls_filtered_all_fg\", \"rates.no_fg_pre_keep\",\n",
    "        \"max_cls_prob.mean\", \"max_cls_prob.p95\", \"max_cls_prob.max\",\n",
    "        \"max_mask_prob.mean\", \"max_mask_prob.p95\", \"max_mask_prob.max\",\n",
    "    ]\n",
    "    keep = [c for c in cols if c in oof_inf.columns]\n",
    "    oof_inf_view = oof_inf[keep].copy()\n",
    "\n",
    "    # numeric coercion (safe)\n",
    "    for c in oof_inf_view.columns:\n",
    "        if c != \"fold\":\n",
    "            oof_inf_view[c] = pd.to_numeric(oof_inf_view[c], errors=\"ignore\")\n",
    "\n",
    "    oof_inf_view = oof_inf_view.sort_values(\"fold\") if \"fold\" in oof_inf_view.columns else oof_inf_view\n",
    "    display(oof_inf_view)\n",
    "\n",
    "if len(oof_area):\n",
    "    cols = [\"fold\", \"val_samples\", \"pred_auth_frac\", \"pred_non_auth_count\", \"pred_non_auth_area_ratio_mean\"]\n",
    "    keep = [c for c in cols if c in oof_area.columns]\n",
    "    oof_area_view = oof_area[keep].copy()\n",
    "    for c in oof_area_view.columns:\n",
    "        if c != \"fold\":\n",
    "            oof_area_view[c] = pd.to_numeric(oof_area_view[c], errors=\"ignore\")\n",
    "    oof_area_view = oof_area_view.sort_values(\"fold\") if \"fold\" in oof_area_view.columns else oof_area_view\n",
    "    display(oof_area_view)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e08e2c02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sanity_random_200 check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "883e8ec8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>rows</th>\n",
       "      <td>200.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>forged_folder_rate</th>\n",
       "      <td>0.545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>image_label_rate</th>\n",
       "      <td>0.545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>any_instances_rate</th>\n",
       "      <td>0.545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean_union_sum</th>\n",
       "      <td>30973.545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean_max_instance_sum</th>\n",
       "      <td>26154.455</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           value\n",
       "rows                     200.000\n",
       "forged_folder_rate         0.545\n",
       "image_label_rate           0.545\n",
       "any_instances_rate         0.545\n",
       "mean_union_sum         30973.545\n",
       "mean_max_instance_sum  26154.455"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "csvs = sorted(SAMPLEDUMP_ROOT.rglob(\"sanity_random_200.csv\"))\n",
    "assert csvs, \"No sanity_random_200.csv found under sanity_dumps\"\n",
    "\n",
    "df = pd.read_csv(csvs[-1])\n",
    "\n",
    "summary = {\n",
    "    \"rows\": len(df),\n",
    "    \"forged_folder_rate\": df[\"is_forged_folder\"].mean(),\n",
    "    \"image_label_rate\": df[\"image_label\"].mean(),\n",
    "    \"any_instances_rate\": (df[\"num_instances\"] > 0).mean(),\n",
    "    \"mean_union_sum\": df[\"union_sum\"].mean(),\n",
    "    \"mean_max_instance_sum\": df[\"max_instance_sum\"].mean(),\n",
    "}\n",
    "\n",
    "display(pd.Series(summary, name=\"value\").to_frame())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "af122e99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>image_label</th>\n",
       "      <th>0.0</th>\n",
       "      <th>1.0</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>is_forged_folder</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>False</th>\n",
       "      <td>91</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <td>0</td>\n",
       "      <td>109</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "image_label       0.0  1.0\n",
       "is_forged_folder          \n",
       "False              91    0\n",
       "True                0  109"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cross-tab: are forged-folder images ever labeled authentic?\n",
    "pd.crosstab(df[\"is_forged_folder\"], df[\"image_label\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bb1cd480",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# How often do we have forged-folder but zero instances?\n",
    "df.query(\"is_forged_folder == True and num_instances == 0\").shape[0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
