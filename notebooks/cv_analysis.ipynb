{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "67e6b406",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cv_analysis.ipynb\n",
    "\n",
    "import json\n",
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "PROJECT_ROOT = Path(\"..\").resolve()\n",
    "\n",
    "if str(PROJECT_ROOT) not in sys.path:\n",
    "    sys.path.insert(0, str(PROJECT_ROOT))\n",
    "\n",
    "from src.data.dataloader import (\n",
    "    ForgeryDataset,\n",
    "    detection_collate_fn,\n",
    "    get_val_transform,\n",
    ")\n",
    "from src.models.mask2former_v2 import Mask2FormerForgeryModel\n",
    "from src.utils.config_utils import load_yaml, sanitize_model_kwargs\n",
    "from src.training.train_cv import build_solution_df\n",
    "from src.data.dataloader import ForgeryDataset\n",
    "from src.models.kaggle_metric import score as kaggle_score\n",
    "\n",
    "plt.style.use(\"ggplot\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1cb53e0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------\n",
    "# Constants / Paths\n",
    "# -----------------\n",
    "\n",
    "OOF_ROOT = PROJECT_ROOT / \"experiments\" / \"oof_results\"\n",
    "FULL_TRAIN_ROOT = PROJECT_ROOT / \"experiments\" / \"full_train_results\"\n",
    "\n",
    "CLS_THRESHOLD_PATH = (\n",
    "    PROJECT_ROOT / \"experiments\" / \"cls_threshold_sweep\" / \"cls_threshold_sweep.csv\"\n",
    ")\n",
    "\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "CFG_PATH = PROJECT_ROOT / \"config\" / \"base.yaml\"\n",
    "\n",
    "CLPSE_ROOT = PROJECT_ROOT / \"experiments\" / \"cls_collapse\"\n",
    "\n",
    "SAMPLEDUMP_ROOT = PROJECT_ROOT / \"experiments\" / \"oof_results\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d693608",
   "metadata": {},
   "source": [
    "### OOF CV results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a5c26d53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OOF dirs: ['mini_tv_0_control', 'mini_tv_0p02', 'mini_tv_0p05_default', 'mini_tv_0p10_cls1p0', 'mini_tv_0p10_cls1p0_cnb', 'mini_tv_0p10_strong', 'mini_tv_0p10_strong_cnb', 'oof_tv_0p10_cls1p0_cnb_tk1_mm0p002_pr0p02_m0p5', 'oof_tv_0p10_cls1p0_cnb_tk1_mm0p002_pr0p02_m0p5_img256a', 'oof_tv_0p10_cls1p0_cnb_tk1_mm0p002_pr0p02_m0p5_img256b', 'oof_tv_0p10_cls1p0_cnb_tk1_mm0p002_pr0p02_m0p5_img512']\n"
     ]
    }
   ],
   "source": [
    "# List what's in experiments/oof_results/\n",
    "oof_items = list(OOF_ROOT.iterdir())\n",
    "oof_dirs = sorted([p.name for p in oof_items if p.is_dir()])\n",
    "oof_files = sorted([p.name for p in oof_items if p.is_file()])\n",
    "\n",
    "print(\"OOF dirs:\", oof_dirs)\n",
    "if oof_files:\n",
    "    print(\"OOF loose files:\", oof_files)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "03a67ab1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded:\n",
      " - oof_tv_0p10_cls1p0_cnb_tk1_mm0p002_pr0p02_m0p5_img512 (C:\\Users\\piiop\\Desktop\\Portfolio\\Projects\\RecodAI_LUC\\experiments\\oof_results\\oof_tv_0p10_cls1p0_cnb_tk1_mm0p002_pr0p02_m0p5_img512)\n"
     ]
    }
   ],
   "source": [
    "def load_run(names):\n",
    "    \"\"\"\n",
    "    names:\n",
    "      - str: dir name under OOF_ROOT OR filename under OOF_ROOT\n",
    "      - list/tuple[str]: load multiple; returns dict keyed by run/filename\n",
    "    \"\"\"\n",
    "    if isinstance(names, (list, tuple)):\n",
    "        return {str(n): load_run(str(n)) for n in names}\n",
    "\n",
    "    name = str(names)\n",
    "    p = OOF_ROOT / name\n",
    "\n",
    "    # Case A: run directory\n",
    "    if p.is_dir():\n",
    "        run_dir = p\n",
    "        oof_csv = run_dir / \"oof_predictions.csv\"\n",
    "        metrics_json = run_dir / \"oof_metrics.json\"\n",
    "\n",
    "        oof_df = pd.read_csv(oof_csv) if oof_csv.exists() else None\n",
    "        metrics = json.load(metrics_json.open()) if metrics_json.exists() else None\n",
    "\n",
    "        fold_files = sorted(run_dir.glob(\"fold_*_oof.csv\"))\n",
    "        fold_dfs = {f.stem: pd.read_csv(f) for f in fold_files}\n",
    "\n",
    "        return {\"name\": run_dir.name, \"path\": run_dir, \"oof\": oof_df, \"metrics\": metrics, \"folds\": fold_dfs}\n",
    "\n",
    "    # Case B: loose file\n",
    "    if p.is_file():\n",
    "        if p.suffix.lower() == \".csv\":\n",
    "            return {\"name\": p.name, \"path\": p, \"oof\": pd.read_csv(p), \"metrics\": None, \"folds\": {}}\n",
    "        if p.suffix.lower() == \".json\":\n",
    "            return {\"name\": p.name, \"path\": p, \"oof\": None, \"metrics\": json.load(p.open()), \"folds\": {}}\n",
    "        raise ValueError(f\"Unsupported file type: {p.suffix}\")\n",
    "\n",
    "    raise FileNotFoundError(f\"Not found under OOF_ROOT: {name}\")\n",
    "\n",
    "# Use load_run(name | [names]) to load one or more CV runs or loose files from experiments/oof_results/\n",
    "runs = load_run([\"oof_tv_0p10_cls1p0_cnb_tk1_mm0p002_pr0p02_m0p5_img512\"])  # or: load_run(\"mini_smoke\"), load_run(\"oof_predictions.csv\")\n",
    "\n",
    "print(\"Loaded:\")\n",
    "if isinstance(runs, dict) and \"name\" not in runs:\n",
    "    for k, v in runs.items():\n",
    "        print(f\" - {v['name']} ({v['path']})\")\n",
    "else:\n",
    "    print(f\" - {runs['name']} ({runs['path']})\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "eba815e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Loaded runs ===\n",
      "\n",
      "oof_tv_0p10_cls1p0_cnb_tk1_mm0p002_pr0p02_m0p5_img512\n",
      "  Mean CV   : 0.35866254327406605\n",
      "  OOF score : 0.3586462267303254\n",
      "  Folds     : [0.2742081128722896, 0.464044001597351, 0.3377355153525577]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 700x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def show_run_metrics(names):\n",
    "    \"\"\"\n",
    "    Pass a run dir name (str) or list of names to compare.\n",
    "    \"\"\"\n",
    "    runs = load_run(names)\n",
    "    if isinstance(runs, dict) and \"name\" not in runs:\n",
    "        items = list(runs.values())\n",
    "    else:\n",
    "        items = [runs]\n",
    "\n",
    "    # Clean summary header\n",
    "    print(\"=== Loaded runs ===\")\n",
    "    for r in items:\n",
    "        m = r[\"metrics\"] or {}\n",
    "        mean_cv = m.get(\"mean_cv\", None)\n",
    "        oof_score = m.get(\"oof_score\", None)\n",
    "        fold_scores = m.get(\"fold_scores\", None)\n",
    "\n",
    "        print(f\"\\n{r['name']}\")\n",
    "        print(f\"  Mean CV   : {mean_cv}\")\n",
    "        print(f\"  OOF score : {oof_score}\")\n",
    "        if fold_scores is not None:\n",
    "            print(f\"  Folds     : {fold_scores}\")\n",
    "\n",
    "    # Comparison plot (only for runs that have fold_scores)\n",
    "    plot_items = [(r[\"name\"], (r[\"metrics\"] or {}).get(\"fold_scores\")) for r in items]\n",
    "    plot_items = [(n, fs) for (n, fs) in plot_items if fs is not None]\n",
    "\n",
    "    if plot_items:\n",
    "        plt.figure(figsize=(7, 4))\n",
    "        for name, fs in plot_items:\n",
    "            plt.plot(range(1, len(fs) + 1), fs, marker=\"o\", label=name)\n",
    "        plt.xlabel(\"Fold\")\n",
    "        plt.ylabel(\"Score\")\n",
    "        plt.title(\"Per-fold scores (comparison)\")\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "\n",
    "    return runs\n",
    "\n",
    "# Single run\n",
    "_ = show_run_metrics(\"oof_tv_0p10_cls1p0_cnb_tk1_mm0p002_pr0p02_m0p5_img512\")\n",
    "\n",
    "# Compare multiple runs\n",
    "# _ = show_run_metrics([\"mini_smoke\", \"some_other_run\"])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc645bc2",
   "metadata": {},
   "source": [
    "## CollapseLogger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a17d44dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "== oof_predictions.csv (head) ==\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>row_id</th>\n",
       "      <th>annotation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10</td>\n",
       "      <td>authentic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10015</td>\n",
       "      <td>[1080386, 9, 1081586, 9, 1082786, 9, 1083986, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10017</td>\n",
       "      <td>authentic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10030</td>\n",
       "      <td>[266136, 11, 266802, 11, 267468, 11, 268134, 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10070</td>\n",
       "      <td>[48862, 23, 49574, 23, 50286, 23, 50998, 23, 5...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   row_id                                         annotation\n",
       "0      10                                          authentic\n",
       "1   10015  [1080386, 9, 1081586, 9, 1082786, 9, 1083986, ...\n",
       "2   10017                                          authentic\n",
       "3   10030  [266136, 11, 266802, 11, 267468, 11, 268134, 1...\n",
       "4   10070  [48862, 23, 49574, 23, 50286, 23, 50998, 23, 5..."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Found fold CSVs: ['fold_1_oof', 'fold_2_oof', 'fold_3_oof']\n"
     ]
    }
   ],
   "source": [
    "# ---- Use an already-loaded run from `runs` ----\n",
    "run = runs[\"oof_tv_0p10_cls1p0_cnb_tk1_mm0p002_pr0p02_m0p5_img512\"]  # must exist in `runs`\n",
    "\n",
    "OOF_RUN_DIR = Path(run[\"path\"])\n",
    "oof_metrics = run[\"metrics\"] or {}\n",
    "oof_predictions = run[\"oof\"]\n",
    "fold_dfs = run[\"folds\"]\n",
    "\n",
    "print(\"\\n== oof_predictions.csv (head) ==\")\n",
    "display(oof_predictions.head() if oof_predictions is not None else None)\n",
    "\n",
    "print(\"\\nFound fold CSVs:\", list(fold_dfs.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "72e30e1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "== Recomputed overall OOF score ==\n",
      "recomputed_oof: 0.3586462267303254\n",
      "\n",
      "== Recomputed per-fold scores ==\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fold</th>\n",
       "      <th>kaggle_metric</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.274208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.464044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.337736</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fold  kaggle_metric\n",
       "0     1       0.274208\n",
       "1     2       0.464044\n",
       "2     3       0.337736"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Rebuild solution_df and re-score to match train_cv additional pipeline verification\n",
    "full_dataset = ForgeryDataset(transform=None)\n",
    "solution_df = build_solution_df(full_dataset)\n",
    "\n",
    "# Overall OOF score (ALIGN BY row_id, then score)\n",
    "solution_df[\"row_id\"] = solution_df[\"row_id\"].astype(str)\n",
    "oof_predictions[\"row_id\"] = oof_predictions[\"row_id\"].astype(str)\n",
    "\n",
    "sub_aligned = (\n",
    "    solution_df[[\"row_id\"]]\n",
    "    .merge(oof_predictions[[\"row_id\", \"annotation\"]], on=\"row_id\", how=\"left\")\n",
    ")\n",
    "\n",
    "recomputed_oof = kaggle_score(\n",
    "    solution_df[[\"row_id\", \"annotation\", \"shape\"]].copy(),\n",
    "    oof_predictions[[\"row_id\", \"annotation\"]].reset_index(drop=True).copy(),\n",
    "    row_id_column_name=\"row_id\",\n",
    ")\n",
    "\n",
    "print(\"\\n== Recomputed overall OOF score ==\")\n",
    "print(\"recomputed_oof:\", float(recomputed_oof))\n",
    "\n",
    "# Per-fold (recompute using the saved fold CSVs if present)\n",
    "def fold_num_from_stem(stem: str) -> int:\n",
    "    m = re.search(r\"(\\d+)\", stem)\n",
    "    return int(m.group(1)) if m else -1\n",
    "\n",
    "if fold_dfs:\n",
    "    # Build stable (row_id, occ) keys on the FULL solution_df once\n",
    "    sol = solution_df.copy()\n",
    "    sol[\"row_id\"] = sol[\"row_id\"].astype(str)\n",
    "    sol[\"occ\"] = sol.groupby(\"row_id\").cumcount()\n",
    "\n",
    "    fold_scores = []\n",
    "    for stem, fdf in sorted(fold_dfs.items(), key=lambda kv: fold_num_from_stem(kv[0])):\n",
    "        fnum = fold_num_from_stem(stem)\n",
    "\n",
    "        sub = fdf.copy()\n",
    "        sub[\"row_id\"] = sub[\"row_id\"].astype(str)\n",
    "        # IMPORTANT: occ must follow the fold CSV order (this is what well score)\n",
    "        sub[\"occ\"] = sub.groupby(\"row_id\").cumcount()\n",
    "\n",
    "        # Rebuild fold solution IN THE SAME ORDER AS sub (no sorting, no isin)\n",
    "        fold_sol = sub[[\"row_id\", \"occ\"]].merge(\n",
    "            sol[[\"row_id\", \"occ\", \"annotation\", \"shape\"]],\n",
    "            on=[\"row_id\", \"occ\"],\n",
    "            how=\"left\",\n",
    "        )\n",
    "\n",
    "        # Hard sanity checks (if these fail, your saved fold CSV isn't compatible with solution_df)\n",
    "        assert len(fold_sol) == len(sub)\n",
    "        if fold_sol[\"annotation\"].isna().any() or fold_sol[\"shape\"].isna().any():\n",
    "            bad = fold_sol[fold_sol[\"annotation\"].isna() | fold_sol[\"shape\"].isna()].head(10)\n",
    "            raise RuntimeError(f\"{stem}: fold_sol has missing GT rows. Sample:\\n{bad}\")\n",
    "\n",
    "        # Submission already in correct order; kaggle_score aligns by row order\n",
    "        fold_sub = sub[[\"row_id\", \"annotation\"]].copy()\n",
    "\n",
    "        s = kaggle_score(\n",
    "            fold_sol[[\"row_id\", \"annotation\", \"shape\"]].copy(),\n",
    "            fold_sub.copy(),\n",
    "            row_id_column_name=\"row_id\",\n",
    "        )\n",
    "        fold_scores.append((fnum, float(s)))\n",
    "\n",
    "    fold_scores_df = pd.DataFrame(fold_scores, columns=[\"fold\", \"kaggle_metric\"]).sort_values(\"fold\")\n",
    "    print(\"\\n== Recomputed per-fold scores ==\")\n",
    "    display(fold_scores_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c4929a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded ClsCollapseLogger artifacts from:\n",
      "  C:\\Users\\piiop\\Desktop\\Portfolio\\Projects\\RecodAI_LUC\\experiments\\oof_results\\oof_tv_0p10_cls1p0_cnb_tk1_mm0p002_pr0p02_m0p5_img512\\cv_fold1\n",
      "  C:\\Users\\piiop\\Desktop\\Portfolio\\Projects\\RecodAI_LUC\\experiments\\oof_results\\oof_tv_0p10_cls1p0_cnb_tk1_mm0p002_pr0p02_m0p5_img512\\cv_fold2\n",
      "  C:\\Users\\piiop\\Desktop\\Portfolio\\Projects\\RecodAI_LUC\\experiments\\oof_results\\oof_tv_0p10_cls1p0_cnb_tk1_mm0p002_pr0p02_m0p5_img512\\cv_fold3\n",
      "  C:\\Users\\piiop\\Desktop\\Portfolio\\Projects\\RecodAI_LUC\\experiments\\oof_results\\oof_tv_0p10_cls1p0_cnb_tk1_mm0p002_pr0p02_m0p5_img512\\cv_oof_summary\n",
      "  JSON blobs : 6\n",
      "  Tables     : 10\n",
      "\n",
      "cv_fold1 tables:\n",
      "  - debug.jsonl | shape=(1207816, 72) | cols=['tag', 'fold', 'epoch', 'global_step', 'img_label', 'masks_shape', 'masks_sum', 'per_image', 'mask_probs', 'class_probs', 'b', 'Q', 'Hm', 'Wm', 'tgt_shape', 'tgt_numel', 'tgt_sum', 'allowed_q', 'matched', 'reason', 'cost_shape', 'num_gt', 'Qa', 'B', 'pos', 'total', 'pos_frac', 'weights_sum', 'weights_mean', 'presence_mean', 'presence_min', 'presence_max', 'loss_presence', 'presence_lse_beta', 'train_topk', 'train_min_mask_mass', 'allowed_queries_per_image', 'qscore_max', 'qscore_sum', 'qscore_max_over_sum', 'mask_mass_max', 'batch', 'fg_prob_per_query', 'fg_prob_mean', 'fg_prob_p95', 'fg_prob_max', 'authentic_frac', 'per_image_penalty_mean', 'loss_auth_penalty', 'few_queries_lambda', 'loss_few_queries', 'val_samples', 'masks_empty', 'gate_fail', 'num_keep0', 'cls_filtered_all_fg', 'no_fg_pre_keep', 'rates', 'max_cls_prob', 'max_mask_prob', 'max_qscore', 'mean_mask_mass', 'max_mask_mass', 'selection_mode_counts', 'used_mask_threshold', 'used_min_mask_mass', 'used_qscore_threshold', 'used_topk', 'used_presence_threshold', 'pred_auth_frac', 'pred_non_auth_count', 'pred_non_auth_area_ratio_mean']\n",
      "  - epoch_summary.csv | shape=(100, 14) | cols=['fold', 'epoch', 'epoch_loss', 'qscore_max_mean', 'qscore_max_p95', 'qscore_max_over_sum_mean', 'num_qscore_gt_0.05', 'num_qscore_gt_0.10', 'num_qscore_gt_0.20', 'mask_mass_max_mean', 'mask_max_mean', 'w_mask_cls', 'w_presence', 'few_queries_lambda']\n",
      "  - step_losses.csv | shape=(86300, 19) | cols=['fold', 'epoch', 'global_step', 'lr', 'loss_mask_bce', 'loss_mask_dice', 'loss_mask_cls', 'loss_presence', 'loss_auth_penalty', 'loss_tv', 'loss_total', 'w_mask_cls', 'w_presence', 'w_auth_penalty', 'tv_lambda', 'train_topk', 'train_min_mask_mass', 'few_queries_lambda', 'presence_lse_beta']\n",
      "\n",
      "cv_fold2 tables:\n",
      "  - debug.jsonl | shape=(1208016, 72) | cols=['tag', 'fold', 'epoch', 'global_step', 'img_label', 'masks_shape', 'masks_sum', 'per_image', 'mask_probs', 'class_probs', 'b', 'Q', 'Hm', 'Wm', 'tgt_shape', 'tgt_numel', 'tgt_sum', 'allowed_q', 'matched', 'reason', 'cost_shape', 'num_gt', 'Qa', 'B', 'pos', 'total', 'pos_frac', 'weights_sum', 'weights_mean', 'presence_mean', 'presence_min', 'presence_max', 'loss_presence', 'presence_lse_beta', 'train_topk', 'train_min_mask_mass', 'allowed_queries_per_image', 'qscore_max', 'qscore_sum', 'qscore_max_over_sum', 'mask_mass_max', 'batch', 'fg_prob_per_query', 'fg_prob_mean', 'fg_prob_p95', 'fg_prob_max', 'authentic_frac', 'per_image_penalty_mean', 'loss_auth_penalty', 'few_queries_lambda', 'loss_few_queries', 'val_samples', 'masks_empty', 'gate_fail', 'num_keep0', 'cls_filtered_all_fg', 'no_fg_pre_keep', 'rates', 'max_cls_prob', 'max_mask_prob', 'max_qscore', 'mean_mask_mass', 'max_mask_mass', 'selection_mode_counts', 'used_mask_threshold', 'used_min_mask_mass', 'used_qscore_threshold', 'used_topk', 'used_presence_threshold', 'pred_auth_frac', 'pred_non_auth_count', 'pred_non_auth_area_ratio_mean']\n",
      "  - epoch_summary.csv | shape=(100, 14) | cols=['fold', 'epoch', 'epoch_loss', 'qscore_max_mean', 'qscore_max_p95', 'qscore_max_over_sum_mean', 'num_qscore_gt_0.05', 'num_qscore_gt_0.10', 'num_qscore_gt_0.20', 'mask_mass_max_mean', 'mask_max_mean', 'w_mask_cls', 'w_presence', 'few_queries_lambda']\n",
      "  - step_losses.csv | shape=(86300, 19) | cols=['fold', 'epoch', 'global_step', 'lr', 'loss_mask_bce', 'loss_mask_dice', 'loss_mask_cls', 'loss_presence', 'loss_auth_penalty', 'loss_tv', 'loss_total', 'w_mask_cls', 'w_presence', 'w_auth_penalty', 'tv_lambda', 'train_topk', 'train_min_mask_mass', 'few_queries_lambda', 'presence_lse_beta']\n",
      "\n",
      "cv_fold3 tables:\n",
      "  - debug.jsonl | shape=(1084473, 72) | cols=['tag', 'fold', 'epoch', 'global_step', 'img_label', 'masks_shape', 'masks_sum', 'per_image', 'mask_probs', 'class_probs', 'b', 'Q', 'Hm', 'Wm', 'tgt_shape', 'tgt_numel', 'tgt_sum', 'allowed_q', 'cost_shape', 'matched', 'num_gt', 'Qa', 'B', 'pos', 'total', 'pos_frac', 'weights_sum', 'weights_mean', 'presence_mean', 'presence_min', 'presence_max', 'loss_presence', 'presence_lse_beta', 'train_topk', 'train_min_mask_mass', 'allowed_queries_per_image', 'qscore_max', 'qscore_sum', 'qscore_max_over_sum', 'mask_mass_max', 'batch', 'fg_prob_per_query', 'fg_prob_mean', 'fg_prob_p95', 'fg_prob_max', 'authentic_frac', 'per_image_penalty_mean', 'loss_auth_penalty', 'few_queries_lambda', 'loss_few_queries', 'reason', 'val_samples', 'masks_empty', 'gate_fail', 'num_keep0', 'cls_filtered_all_fg', 'no_fg_pre_keep', 'rates', 'max_cls_prob', 'max_mask_prob', 'max_qscore', 'mean_mask_mass', 'max_mask_mass', 'selection_mode_counts', 'used_mask_threshold', 'used_min_mask_mass', 'used_qscore_threshold', 'used_topk', 'used_presence_threshold', 'pred_auth_frac', 'pred_non_auth_count', 'pred_non_auth_area_ratio_mean']\n",
      "  - epoch_summary.csv | shape=(89, 14) | cols=['fold', 'epoch', 'epoch_loss', 'qscore_max_mean', 'qscore_max_p95', 'qscore_max_over_sum_mean', 'num_qscore_gt_0.05', 'num_qscore_gt_0.10', 'num_qscore_gt_0.20', 'mask_mass_max_mean', 'mask_max_mean', 'w_mask_cls', 'w_presence', 'few_queries_lambda']\n",
      "  - step_losses.csv | shape=(77474, 19) | cols=['fold', 'epoch', 'global_step', 'lr', 'loss_mask_bce', 'loss_mask_dice', 'loss_mask_cls', 'loss_presence', 'loss_auth_penalty', 'loss_tv', 'loss_total', 'w_mask_cls', 'w_presence', 'w_auth_penalty', 'tv_lambda', 'train_topk', 'train_min_mask_mass', 'few_queries_lambda', 'presence_lse_beta']\n",
      "\n",
      "cv_oof_summary tables:\n",
      "  - debug.jsonl | shape=(3, 5) | cols=['tag', 'val_samples', 'pred_auth_frac', 'pred_non_auth_count', 'pred_non_auth_area_ratio_mean']\n"
     ]
    }
   ],
   "source": [
    "# ---------------------------------------------------------------------\n",
    "# Load LoggerHelper outputs for the CV folds\n",
    "# (stored under experiments/oof_results/<run_name>/cv_fold*/ and cv_oof_summary/)\n",
    "# ---------------------------------------------------------------------\n",
    "\n",
    "def _read_json(p: Path):\n",
    "    with open(p, \"r\") as f:\n",
    "        return json.load(f)\n",
    "\n",
    "def _read_jsonl(p: Path):\n",
    "    rows = []\n",
    "    with open(p, \"r\") as f:\n",
    "        for line in f:\n",
    "            line = line.strip()\n",
    "            if line:\n",
    "                rows.append(json.loads(line))\n",
    "    return pd.DataFrame(rows) if rows else pd.DataFrame()\n",
    "\n",
    "def _read_table(p: Path):\n",
    "    suf = p.suffix.lower()\n",
    "    if suf == \".csv\":\n",
    "        return pd.read_csv(p)\n",
    "    if suf in (\".jsonl\", \".ndjson\"):\n",
    "        return _read_jsonl(p)\n",
    "    return None\n",
    "\n",
    "LOGGER_FILES = {\n",
    "    \"debug.jsonl\",\n",
    "    \"epoch_summary.csv\",\n",
    "    \"meta.json\",\n",
    "    \"optimizer.json\",\n",
    "    \"step_losses.csv\",\n",
    "}\n",
    "\n",
    "# Discover fold directories (cv_fold1, cv_fold2, ...) + optional cv_oof_summary\n",
    "fold_dirs = []\n",
    "if OOF_RUN_DIR.exists():\n",
    "    for d in sorted(OOF_RUN_DIR.iterdir()):\n",
    "        if d.is_dir() and (re.match(r\"cv_fold\\d+$\", d.name) or d.name == \"cv_oof_summary\"):\n",
    "            fold_dirs.append(d)\n",
    "\n",
    "collapse_json = {}    # (fold_dirname, filename) -> dict\n",
    "collapse_tables = {}  # (fold_dirname, filename) -> df\n",
    "\n",
    "for d in fold_dirs:\n",
    "    for fname in LOGGER_FILES:\n",
    "        p = d / fname\n",
    "        if not p.exists():\n",
    "            continue\n",
    "\n",
    "        if p.suffix.lower() == \".json\":\n",
    "            try:\n",
    "                collapse_json[(d.name, fname)] = _read_json(p)\n",
    "            except Exception:\n",
    "                pass\n",
    "        elif p.suffix.lower() in (\".csv\", \".jsonl\", \".ndjson\"):\n",
    "            try:\n",
    "                df = _read_table(p)\n",
    "                if df is not None and len(df) > 0:\n",
    "                    collapse_tables[(d.name, fname)] = df\n",
    "            except Exception:\n",
    "                pass\n",
    "\n",
    "print(\"Loaded LoggerHelper artifacts from:\")\n",
    "for d in fold_dirs:\n",
    "    print(\" \", d)\n",
    "\n",
    "print(f\"  JSON blobs : {len(collapse_json)}\")\n",
    "print(f\"  Tables     : {len(collapse_tables)}\")\n",
    "\n",
    "if collapse_tables:\n",
    "    by_dir = {}\n",
    "    for (dname, fname), df in collapse_tables.items():\n",
    "        by_dir.setdefault(dname, []).append((fname, df))\n",
    "\n",
    "    for dname in sorted(by_dir):\n",
    "        print(f\"\\n{dname} tables:\")\n",
    "        for fname, df in sorted(by_dir[dname], key=lambda x: x[0]):\n",
    "            print(f\"  - {fname} | shape={df.shape} | cols={list(df.columns)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "be951a4c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fold</th>\n",
       "      <th>epoch</th>\n",
       "      <th>global_step</th>\n",
       "      <th>lr</th>\n",
       "      <th>loss_mask_bce</th>\n",
       "      <th>loss_mask_dice</th>\n",
       "      <th>loss_mask_cls</th>\n",
       "      <th>loss_presence</th>\n",
       "      <th>loss_auth_penalty</th>\n",
       "      <th>loss_tv</th>\n",
       "      <th>loss_total</th>\n",
       "      <th>w_mask_cls</th>\n",
       "      <th>w_presence</th>\n",
       "      <th>w_auth_penalty</th>\n",
       "      <th>tv_lambda</th>\n",
       "      <th>train_topk</th>\n",
       "      <th>train_min_mask_mass</th>\n",
       "      <th>few_queries_lambda</th>\n",
       "      <th>presence_lse_beta</th>\n",
       "      <th>_source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>250074.000000</td>\n",
       "      <td>250074.000000</td>\n",
       "      <td>250074.000000</td>\n",
       "      <td>2.500740e+05</td>\n",
       "      <td>250074.000000</td>\n",
       "      <td>250074.000000</td>\n",
       "      <td>250074.000000</td>\n",
       "      <td>250074.000000</td>\n",
       "      <td>250074.000000</td>\n",
       "      <td>250074.000000</td>\n",
       "      <td>250074.000000</td>\n",
       "      <td>250074.000000</td>\n",
       "      <td>250074.0</td>\n",
       "      <td>250074.0</td>\n",
       "      <td>250074.000000</td>\n",
       "      <td>250074.000000</td>\n",
       "      <td>250074.000000</td>\n",
       "      <td>2.500740e+05</td>\n",
       "      <td>250074.0</td>\n",
       "      <td>250074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>step_losses.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>250074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.964706</td>\n",
       "      <td>12.739609</td>\n",
       "      <td>10562.021246</td>\n",
       "      <td>1.000000e-04</td>\n",
       "      <td>0.309873</td>\n",
       "      <td>0.736066</td>\n",
       "      <td>0.493297</td>\n",
       "      <td>1.037426</td>\n",
       "      <td>0.013907</td>\n",
       "      <td>0.041564</td>\n",
       "      <td>2.781900</td>\n",
       "      <td>1.258823</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.062941</td>\n",
       "      <td>1.741177</td>\n",
       "      <td>0.001259</td>\n",
       "      <td>1.000000e-01</td>\n",
       "      <td>10.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.808492</td>\n",
       "      <td>7.179042</td>\n",
       "      <td>6200.434910</td>\n",
       "      <td>4.065766e-20</td>\n",
       "      <td>0.286175</td>\n",
       "      <td>0.236975</td>\n",
       "      <td>0.204637</td>\n",
       "      <td>0.529425</td>\n",
       "      <td>0.013015</td>\n",
       "      <td>0.018123</td>\n",
       "      <td>0.767886</td>\n",
       "      <td>0.437989</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.021899</td>\n",
       "      <td>0.437989</td>\n",
       "      <td>0.000438</td>\n",
       "      <td>5.551126e-17</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000e-04</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000278</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.218338</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>1.000000e-01</td>\n",
       "      <td>10.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>5209.000000</td>\n",
       "      <td>1.000000e-04</td>\n",
       "      <td>0.185381</td>\n",
       "      <td>0.640971</td>\n",
       "      <td>0.362568</td>\n",
       "      <td>0.649618</td>\n",
       "      <td>0.005159</td>\n",
       "      <td>0.031556</td>\n",
       "      <td>2.312873</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>1.000000e-01</td>\n",
       "      <td>10.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>10419.000000</td>\n",
       "      <td>1.000000e-04</td>\n",
       "      <td>0.284241</td>\n",
       "      <td>0.792706</td>\n",
       "      <td>0.492899</td>\n",
       "      <td>0.943641</td>\n",
       "      <td>0.010756</td>\n",
       "      <td>0.039775</td>\n",
       "      <td>2.718544</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>1.000000e-01</td>\n",
       "      <td>10.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>3.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>15891.000000</td>\n",
       "      <td>1.000000e-04</td>\n",
       "      <td>0.395511</td>\n",
       "      <td>0.912901</td>\n",
       "      <td>0.598909</td>\n",
       "      <td>1.337017</td>\n",
       "      <td>0.019131</td>\n",
       "      <td>0.050245</td>\n",
       "      <td>3.248347</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.002000</td>\n",
       "      <td>1.000000e-01</td>\n",
       "      <td>10.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>3.000000</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>21574.000000</td>\n",
       "      <td>1.000000e-04</td>\n",
       "      <td>63.366310</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.753763</td>\n",
       "      <td>10.158528</td>\n",
       "      <td>0.427211</td>\n",
       "      <td>0.283090</td>\n",
       "      <td>66.480232</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.002000</td>\n",
       "      <td>1.000000e-01</td>\n",
       "      <td>10.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 fold          epoch    global_step            lr  \\\n",
       "count   250074.000000  250074.000000  250074.000000  2.500740e+05   \n",
       "unique            NaN            NaN            NaN           NaN   \n",
       "top               NaN            NaN            NaN           NaN   \n",
       "freq              NaN            NaN            NaN           NaN   \n",
       "mean         1.964706      12.739609   10562.021246  1.000000e-04   \n",
       "std          0.808492       7.179042    6200.434910  4.065766e-20   \n",
       "min          1.000000       1.000000       0.000000  1.000000e-04   \n",
       "25%          1.000000       7.000000    5209.000000  1.000000e-04   \n",
       "50%          2.000000      13.000000   10419.000000  1.000000e-04   \n",
       "75%          3.000000      19.000000   15891.000000  1.000000e-04   \n",
       "max          3.000000      25.000000   21574.000000  1.000000e-04   \n",
       "\n",
       "        loss_mask_bce  loss_mask_dice  loss_mask_cls  loss_presence  \\\n",
       "count   250074.000000   250074.000000  250074.000000  250074.000000   \n",
       "unique            NaN             NaN            NaN            NaN   \n",
       "top               NaN             NaN            NaN            NaN   \n",
       "freq              NaN             NaN            NaN            NaN   \n",
       "mean         0.309873        0.736066       0.493297       1.037426   \n",
       "std          0.286175        0.236975       0.204637       0.529425   \n",
       "min         -0.000000       -0.000000       0.000000       0.000278   \n",
       "25%          0.185381        0.640971       0.362568       0.649618   \n",
       "50%          0.284241        0.792706       0.492899       0.943641   \n",
       "75%          0.395511        0.912901       0.598909       1.337017   \n",
       "max         63.366310        1.000000       2.753763      10.158528   \n",
       "\n",
       "        loss_auth_penalty        loss_tv     loss_total     w_mask_cls  \\\n",
       "count       250074.000000  250074.000000  250074.000000  250074.000000   \n",
       "unique                NaN            NaN            NaN            NaN   \n",
       "top                   NaN            NaN            NaN            NaN   \n",
       "freq                  NaN            NaN            NaN            NaN   \n",
       "mean             0.013907       0.041564       2.781900       1.258823   \n",
       "std              0.013015       0.018123       0.767886       0.437989   \n",
       "min              0.000000      -0.000000       0.218338       1.000000   \n",
       "25%              0.005159       0.031556       2.312873       1.000000   \n",
       "50%              0.010756       0.039775       2.718544       1.000000   \n",
       "75%              0.019131       0.050245       3.248347       2.000000   \n",
       "max              0.427211       0.283090      66.480232       2.000000   \n",
       "\n",
       "        w_presence  w_auth_penalty      tv_lambda     train_topk  \\\n",
       "count     250074.0        250074.0  250074.000000  250074.000000   \n",
       "unique         NaN             NaN            NaN            NaN   \n",
       "top            NaN             NaN            NaN            NaN   \n",
       "freq           NaN             NaN            NaN            NaN   \n",
       "mean           1.0             1.0       0.062941       1.741177   \n",
       "std            0.0             0.0       0.021899       0.437989   \n",
       "min            1.0             1.0       0.050000       1.000000   \n",
       "25%            1.0             1.0       0.050000       1.000000   \n",
       "50%            1.0             1.0       0.050000       2.000000   \n",
       "75%            1.0             1.0       0.100000       2.000000   \n",
       "max            1.0             1.0       0.100000       2.000000   \n",
       "\n",
       "        train_min_mask_mass  few_queries_lambda  presence_lse_beta  \\\n",
       "count         250074.000000        2.500740e+05           250074.0   \n",
       "unique                  NaN                 NaN                NaN   \n",
       "top                     NaN                 NaN                NaN   \n",
       "freq                    NaN                 NaN                NaN   \n",
       "mean               0.001259        1.000000e-01               10.0   \n",
       "std                0.000438        5.551126e-17                0.0   \n",
       "min                0.001000        1.000000e-01               10.0   \n",
       "25%                0.001000        1.000000e-01               10.0   \n",
       "50%                0.001000        1.000000e-01               10.0   \n",
       "75%                0.002000        1.000000e-01               10.0   \n",
       "max                0.002000        1.000000e-01               10.0   \n",
       "\n",
       "                _source  \n",
       "count            250074  \n",
       "unique                1  \n",
       "top     step_losses.csv  \n",
       "freq             250074  \n",
       "mean                NaN  \n",
       "std                 NaN  \n",
       "min                 NaN  \n",
       "25%                 NaN  \n",
       "50%                 NaN  \n",
       "75%                 NaN  \n",
       "max                 NaN  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Convenience: key summaries across ALL loaded debug tables\n",
    "\n",
    "def concat_tables(name_contains: str):\n",
    "    dfs = []\n",
    "    for (fold_key, fname), df in collapse_tables.items():\n",
    "        if name_contains.lower() in fname.lower():\n",
    "            d = df.copy()\n",
    "            m = re.search(r\"(\\d+)\", str(fold_key))\n",
    "            d[\"fold\"] = int(m.group(1)) if m else fold_key  # cv_oof_summary stays as string\n",
    "            d[\"_source\"] = fname\n",
    "            dfs.append(d)\n",
    "    return pd.concat(dfs, ignore_index=True) if dfs else pd.DataFrame()\n",
    "\n",
    "\n",
    "step_losses = concat_tables(\"step\")\n",
    "epoch_summary = concat_tables(\"epoch\")\n",
    "debug_events = concat_tables(\"debug\")\n",
    "\n",
    "if len(step_losses):\n",
    "    display(step_losses.describe(include=\"all\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1315f2ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fold</th>\n",
       "      <th>epoch</th>\n",
       "      <th>loss_mask_bce</th>\n",
       "      <th>loss_mask_dice</th>\n",
       "      <th>loss_mask_cls</th>\n",
       "      <th>loss_presence</th>\n",
       "      <th>loss_auth_penalty</th>\n",
       "      <th>loss_total</th>\n",
       "      <th>w_mask_cls</th>\n",
       "      <th>w_presence</th>\n",
       "      <th>w_auth_penalty</th>\n",
       "      <th>train_topk</th>\n",
       "      <th>train_min_mask_mass</th>\n",
       "      <th>few_queries_lambda</th>\n",
       "      <th>presence_lse_beta</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.495357</td>\n",
       "      <td>0.831758</td>\n",
       "      <td>0.606954</td>\n",
       "      <td>1.312384</td>\n",
       "      <td>0.023183</td>\n",
       "      <td>3.349474</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.1</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.341942</td>\n",
       "      <td>0.803762</td>\n",
       "      <td>0.571213</td>\n",
       "      <td>1.128384</td>\n",
       "      <td>0.018835</td>\n",
       "      <td>2.931153</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.1</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0.331718</td>\n",
       "      <td>0.797204</td>\n",
       "      <td>0.536723</td>\n",
       "      <td>1.078652</td>\n",
       "      <td>0.016510</td>\n",
       "      <td>2.821057</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.1</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0.299285</td>\n",
       "      <td>0.719817</td>\n",
       "      <td>0.415129</td>\n",
       "      <td>0.810638</td>\n",
       "      <td>0.011761</td>\n",
       "      <td>2.297950</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.1</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0.290487</td>\n",
       "      <td>0.676825</td>\n",
       "      <td>0.414180</td>\n",
       "      <td>0.777458</td>\n",
       "      <td>0.011412</td>\n",
       "      <td>2.211296</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.1</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>3</td>\n",
       "      <td>21</td>\n",
       "      <td>0.282912</td>\n",
       "      <td>0.630342</td>\n",
       "      <td>0.405731</td>\n",
       "      <td>0.696911</td>\n",
       "      <td>0.009450</td>\n",
       "      <td>2.065098</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.1</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>3</td>\n",
       "      <td>22</td>\n",
       "      <td>0.285484</td>\n",
       "      <td>0.642182</td>\n",
       "      <td>0.396243</td>\n",
       "      <td>0.697244</td>\n",
       "      <td>0.009941</td>\n",
       "      <td>2.071374</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.1</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>3</td>\n",
       "      <td>23</td>\n",
       "      <td>0.304655</td>\n",
       "      <td>0.667097</td>\n",
       "      <td>0.416605</td>\n",
       "      <td>0.740453</td>\n",
       "      <td>0.010426</td>\n",
       "      <td>2.179246</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.1</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>3</td>\n",
       "      <td>24</td>\n",
       "      <td>0.281547</td>\n",
       "      <td>0.650896</td>\n",
       "      <td>0.407082</td>\n",
       "      <td>0.704326</td>\n",
       "      <td>0.009628</td>\n",
       "      <td>2.092931</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.1</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>3</td>\n",
       "      <td>25</td>\n",
       "      <td>0.276628</td>\n",
       "      <td>0.634515</td>\n",
       "      <td>0.418339</td>\n",
       "      <td>0.678949</td>\n",
       "      <td>0.009318</td>\n",
       "      <td>2.057366</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.1</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>75 rows  15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    fold  epoch  loss_mask_bce  loss_mask_dice  loss_mask_cls  loss_presence  \\\n",
       "0      1      1       0.495357        0.831758       0.606954       1.312384   \n",
       "1      1      2       0.341942        0.803762       0.571213       1.128384   \n",
       "2      1      3       0.331718        0.797204       0.536723       1.078652   \n",
       "3      1      4       0.299285        0.719817       0.415129       0.810638   \n",
       "4      1      5       0.290487        0.676825       0.414180       0.777458   \n",
       "..   ...    ...            ...             ...            ...            ...   \n",
       "70     3     21       0.282912        0.630342       0.405731       0.696911   \n",
       "71     3     22       0.285484        0.642182       0.396243       0.697244   \n",
       "72     3     23       0.304655        0.667097       0.416605       0.740453   \n",
       "73     3     24       0.281547        0.650896       0.407082       0.704326   \n",
       "74     3     25       0.276628        0.634515       0.418339       0.678949   \n",
       "\n",
       "    loss_auth_penalty  loss_total  w_mask_cls  w_presence  w_auth_penalty  \\\n",
       "0            0.023183    3.349474         1.0         1.0             1.0   \n",
       "1            0.018835    2.931153         1.0         1.0             1.0   \n",
       "2            0.016510    2.821057         1.0         1.0             1.0   \n",
       "3            0.011761    2.297950         1.0         1.0             1.0   \n",
       "4            0.011412    2.211296         1.0         1.0             1.0   \n",
       "..                ...         ...         ...         ...             ...   \n",
       "70           0.009450    2.065098         1.0         1.0             1.0   \n",
       "71           0.009941    2.071374         1.0         1.0             1.0   \n",
       "72           0.010426    2.179246         1.0         1.0             1.0   \n",
       "73           0.009628    2.092931         1.0         1.0             1.0   \n",
       "74           0.009318    2.057366         1.0         1.0             1.0   \n",
       "\n",
       "    train_topk  train_min_mask_mass  few_queries_lambda  presence_lse_beta  \n",
       "0          2.0                0.001                 0.1               10.0  \n",
       "1          2.0                0.001                 0.1               10.0  \n",
       "2          2.0                0.001                 0.1               10.0  \n",
       "3          2.0                0.001                 0.1               10.0  \n",
       "4          2.0                0.001                 0.1               10.0  \n",
       "..         ...                  ...                 ...                ...  \n",
       "70         2.0                0.001                 0.1               10.0  \n",
       "71         2.0                0.001                 0.1               10.0  \n",
       "72         2.0                0.001                 0.1               10.0  \n",
       "73         2.0                0.001                 0.1               10.0  \n",
       "74         2.0                0.001                 0.1               10.0  \n",
       "\n",
       "[75 rows x 15 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Epoch-aggregated losses (mean over steps, per fold  epoch)\n",
    "\n",
    "loss_cols = [\n",
    "    \"loss_mask_bce\",\n",
    "    \"loss_mask_dice\",\n",
    "    \"loss_mask_cls\",\n",
    "    \"loss_presence\",\n",
    "    \"loss_auth_penalty\",\n",
    "    \"loss_total\",\n",
    "]\n",
    "\n",
    "# (optional but useful) epoch-constant knobs / weights to aggregate too\n",
    "meta_cols = [\n",
    "    \"w_mask_cls\",\n",
    "    \"w_presence\",\n",
    "    \"w_auth_penalty\",\n",
    "    \"train_topk\",\n",
    "    \"train_min_mask_mass\",\n",
    "    \"few_queries_lambda\",\n",
    "    \"presence_lse_beta\",\n",
    "]\n",
    "\n",
    "cols = [c for c in (loss_cols + meta_cols) if c in step_losses.columns]\n",
    "\n",
    "epoch_losses = (\n",
    "    step_losses\n",
    "    .groupby([\"fold\", \"epoch\"], as_index=False)[cols]\n",
    "    .mean()\n",
    "    .sort_values([\"fold\", \"epoch\"])\n",
    ")\n",
    "\n",
    "display(epoch_losses)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e1e35d8b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fold</th>\n",
       "      <th>epoch</th>\n",
       "      <th>epoch_loss</th>\n",
       "      <th>qscore_max_mean</th>\n",
       "      <th>qscore_max_p95</th>\n",
       "      <th>qscore_max_over_sum_mean</th>\n",
       "      <th>num_qscore_gt_0.05</th>\n",
       "      <th>num_qscore_gt_0.10</th>\n",
       "      <th>num_qscore_gt_0.20</th>\n",
       "      <th>mask_mass_max_mean</th>\n",
       "      <th>mask_max_mean</th>\n",
       "      <th>w_mask_cls</th>\n",
       "      <th>w_presence</th>\n",
       "      <th>few_queries_lambda</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>25</td>\n",
       "      <td>2.155756</td>\n",
       "      <td>0.286306</td>\n",
       "      <td>0.395729</td>\n",
       "      <td>0.829390</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.433613</td>\n",
       "      <td>0.981555</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>25</td>\n",
       "      <td>2.057204</td>\n",
       "      <td>0.284169</td>\n",
       "      <td>0.392195</td>\n",
       "      <td>0.898003</td>\n",
       "      <td>1.25</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.397522</td>\n",
       "      <td>0.978599</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>25</td>\n",
       "      <td>2.057582</td>\n",
       "      <td>0.256838</td>\n",
       "      <td>0.408711</td>\n",
       "      <td>0.879069</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.396851</td>\n",
       "      <td>0.926939</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fold  epoch  epoch_loss  qscore_max_mean  qscore_max_p95  \\\n",
       "0     1     25    2.155756         0.286306        0.395729   \n",
       "1     2     25    2.057204         0.284169        0.392195   \n",
       "2     3     25    2.057582         0.256838        0.408711   \n",
       "\n",
       "   qscore_max_over_sum_mean  num_qscore_gt_0.05  num_qscore_gt_0.10  \\\n",
       "0                  0.829390                0.75                0.75   \n",
       "1                  0.898003                1.25                0.75   \n",
       "2                  0.879069                1.00                0.75   \n",
       "\n",
       "   num_qscore_gt_0.20  mask_mass_max_mean  mask_max_mean  w_mask_cls  \\\n",
       "0                0.75            0.433613       0.981555         1.0   \n",
       "1                0.75            0.397522       0.978599         1.0   \n",
       "2                0.75            0.396851       0.926939         1.0   \n",
       "\n",
       "   w_presence  few_queries_lambda  \n",
       "0         1.0                 0.1  \n",
       "1         1.0                 0.1  \n",
       "2         1.0                 0.1  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>few_queries_lambda</th>\n",
       "      <td>0.100000</td>\n",
       "      <td>1.699675e-17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>qscore_max_mean</th>\n",
       "      <td>0.275771</td>\n",
       "      <td>1.643128e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>qscore_max_p95</th>\n",
       "      <td>0.398878</td>\n",
       "      <td>8.696760e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mask_mass_max_mean</th>\n",
       "      <td>0.409329</td>\n",
       "      <td>2.103393e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>num_qscore_gt_0.20</th>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>num_qscore_gt_0.10</th>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>qscore_max_over_sum_mean</th>\n",
       "      <td>0.868820</td>\n",
       "      <td>3.543560e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mask_max_mean</th>\n",
       "      <td>0.962364</td>\n",
       "      <td>3.071496e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>w_mask_cls</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>num_qscore_gt_0.05</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.500000e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>w_presence</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>epoch_loss</th>\n",
       "      <td>2.090181</td>\n",
       "      <td>5.679036e-02</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              mean           std\n",
       "few_queries_lambda        0.100000  1.699675e-17\n",
       "qscore_max_mean           0.275771  1.643128e-02\n",
       "qscore_max_p95            0.398878  8.696760e-03\n",
       "mask_mass_max_mean        0.409329  2.103393e-02\n",
       "num_qscore_gt_0.20        0.750000  0.000000e+00\n",
       "num_qscore_gt_0.10        0.750000  0.000000e+00\n",
       "qscore_max_over_sum_mean  0.868820  3.543560e-02\n",
       "mask_max_mean             0.962364  3.071496e-02\n",
       "w_mask_cls                1.000000  0.000000e+00\n",
       "num_qscore_gt_0.05        1.000000  2.500000e-01\n",
       "w_presence                1.000000  0.000000e+00\n",
       "epoch_loss                2.090181  5.679036e-02"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fold</th>\n",
       "      <th>epoch</th>\n",
       "      <th>q_dead</th>\n",
       "      <th>sparse_dead</th>\n",
       "      <th>mask_dead</th>\n",
       "      <th>dominance_bad</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>1</td>\n",
       "      <td>25</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>2</td>\n",
       "      <td>25</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>3</td>\n",
       "      <td>25</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    fold  epoch  q_dead  sparse_dead  mask_dead  dominance_bad\n",
       "24     1     25   False        False      False          False\n",
       "49     2     25   False        False      False          False\n",
       "74     3     25   False        False      False          False"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>corr_with_epoch</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>epoch_loss</th>\n",
       "      <td>-0.727675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>num_qscore_gt_0.05</th>\n",
       "      <td>-0.142123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mask_max_mean</th>\n",
       "      <td>0.384192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mask_mass_max_mean</th>\n",
       "      <td>0.433840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>num_qscore_gt_0.10</th>\n",
       "      <td>0.464219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>qscore_max_mean</th>\n",
       "      <td>0.472229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>num_qscore_gt_0.20</th>\n",
       "      <td>0.518086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>qscore_max_p95</th>\n",
       "      <td>0.594044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>qscore_max_over_sum_mean</th>\n",
       "      <td>0.656860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>w_mask_cls</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>w_presence</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>few_queries_lambda</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          corr_with_epoch\n",
       "epoch_loss                      -0.727675\n",
       "num_qscore_gt_0.05              -0.142123\n",
       "mask_max_mean                    0.384192\n",
       "mask_mass_max_mean               0.433840\n",
       "num_qscore_gt_0.10               0.464219\n",
       "qscore_max_mean                  0.472229\n",
       "num_qscore_gt_0.20               0.518086\n",
       "qscore_max_p95                   0.594044\n",
       "qscore_max_over_sum_mean         0.656860\n",
       "w_mask_cls                            NaN\n",
       "w_presence                            NaN\n",
       "few_queries_lambda                    NaN"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# --- Useful, compact diagnostics for epoch_summary ---\n",
    "\n",
    "es = epoch_summary.copy()\n",
    "\n",
    "num_cols = [\n",
    "    \"epoch_loss\",\n",
    "    # qscore-focused signals\n",
    "    \"qscore_max_mean\", \"qscore_max_p95\", \"qscore_max_over_sum_mean\",\n",
    "    \"num_qscore_gt_0.05\", \"num_qscore_gt_0.10\", \"num_qscore_gt_0.20\",\n",
    "    # mask signals\n",
    "    \"mask_mass_max_mean\", \"mask_max_mean\",\n",
    "    # knobs/weights logged\n",
    "    \"w_mask_cls\", \"w_presence\", \"few_queries_lambda\",\n",
    "]\n",
    "for c in num_cols:\n",
    "    if c in es.columns:\n",
    "        es[c] = pd.to_numeric(es[c], errors=\"coerce\")\n",
    "\n",
    "present_cols = [c for c in num_cols if c in es.columns]\n",
    "\n",
    "last_epoch = (\n",
    "    es.sort_values([\"fold\", \"epoch\"])\n",
    "      .groupby(\"fold\", as_index=False)\n",
    "      .tail(1)\n",
    "      .sort_values(\"fold\")\n",
    ")\n",
    "\n",
    "# Per-fold last-epoch snapshot\n",
    "display(\n",
    "    last_epoch[[\"fold\", \"epoch\"] + present_cols]\n",
    "      .sort_values(\"fold\")\n",
    "      .reset_index(drop=True)\n",
    ")\n",
    "\n",
    "# Cross-fold mean/std at last epoch\n",
    "agg = last_epoch[present_cols].agg([\"mean\", \"std\"]).T\n",
    "agg.columns = [\"mean\", \"std\"]\n",
    "display(agg.sort_values(\"mean\"))\n",
    "\n",
    "# Quick red-flag table at last epoch (qscore-era)\n",
    "flags = last_epoch.assign(\n",
    "    q_dead   = last_epoch.get(\"qscore_max_p95\", np.nan) < 0.05,\n",
    "    sparse_dead = last_epoch.get(\"num_qscore_gt_0.10\", np.nan) < 0.5,   # ~no queries above 0.10 on avg\n",
    "    mask_dead = last_epoch.get(\"mask_mass_max_mean\", np.nan) < 0.01,    # masks never get any mass\n",
    "    dominance_bad = last_epoch.get(\"qscore_max_over_sum_mean\", np.nan) < 0.6,  # no single winner\n",
    ").loc[:, [\"fold\", \"epoch\", \"q_dead\", \"sparse_dead\", \"mask_dead\", \"dominance_bad\"]]\n",
    "display(flags)\n",
    "\n",
    "# Trend vs epoch (pooled across folds): corr with epoch\n",
    "trend_cols = [\"epoch\"] + present_cols\n",
    "trend_corr = (\n",
    "    es[trend_cols]\n",
    "      .corr(numeric_only=True)[\"epoch\"]\n",
    "      .drop(\"epoch\")\n",
    "      .sort_values()\n",
    ")\n",
    "display(trend_corr.to_frame(\"corr_with_epoch\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "bf6aa621",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "debug_events shape: (905963, 73)\n",
      "cols: ['tag', 'fold', 'epoch', 'global_step', 'img_label', 'masks_shape', 'masks_sum', 'per_image', 'mask_probs', 'class_probs', 'b', 'Q', 'Hm', 'Wm', 'tgt_shape', 'tgt_numel', 'tgt_sum', 'allowed_q', 'matched', 'reason', 'cost_shape', 'num_gt', 'Qa', 'B', 'pos', 'total', 'pos_frac', 'weights_sum', 'weights_mean', 'presence_mean', 'presence_min', 'presence_max', 'loss_presence', 'presence_lse_beta', 'train_topk', 'train_min_mask_mass', 'allowed_queries_per_image', 'qscore_max', 'qscore_sum', 'qscore_max_over_sum', 'mask_mass_max', 'batch', 'fg_prob_per_query', 'fg_prob_mean', 'fg_prob_p95', 'fg_prob_max', 'authentic_frac', 'per_image_penalty_mean', 'loss_auth_penalty', 'few_queries_lambda', 'loss_few_queries', 'val_samples', 'masks_empty', 'gate_fail', 'num_keep0', 'cls_filtered_all_fg', 'no_fg_pre_keep', 'rates', 'max_cls_prob', 'max_mask_prob', 'max_qscore', 'mean_mask_mass', 'max_mask_mass', 'selection_mode_counts', 'used_mask_threshold', 'used_min_mask_mass', 'used_qscore_threshold', 'used_topk', 'used_presence_threshold', 'pred_auth_frac', 'pred_non_auth_count', 'pred_non_auth_area_ratio_mean', '_source']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fold</th>\n",
       "      <th>val_samples</th>\n",
       "      <th>masks_empty</th>\n",
       "      <th>gate_fail</th>\n",
       "      <th>num_keep0</th>\n",
       "      <th>cls_filtered_all_fg</th>\n",
       "      <th>no_fg_pre_keep</th>\n",
       "      <th>rates</th>\n",
       "      <th>max_cls_prob</th>\n",
       "      <th>max_mask_prob</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>301952</th>\n",
       "      <td>1</td>\n",
       "      <td>1726.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>{'masks_empty': 0.0, 'gate_fail': 0.0, 'num_ke...</td>\n",
       "      <td>{'mean': 0.6969074010848999, 'p95': 0.79950189...</td>\n",
       "      <td>{'mean': 0.9507280588150024, 'p95': 0.99998199...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>603956</th>\n",
       "      <td>2</td>\n",
       "      <td>1725.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>165.0</td>\n",
       "      <td>{'masks_empty': 0.0, 'gate_fail': 0.0, 'num_ke...</td>\n",
       "      <td>{'mean': 0.7042760252952576, 'p95': 0.71485036...</td>\n",
       "      <td>{'mean': 0.8952463269233704, 'p95': 0.99995195...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>905960</th>\n",
       "      <td>3</td>\n",
       "      <td>1725.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>{'masks_empty': 0.0, 'gate_fail': 0.0, 'num_ke...</td>\n",
       "      <td>{'mean': 0.646255612373352, 'p95': 0.653552830...</td>\n",
       "      <td>{'mean': 0.9523042440414429, 'p95': 0.99999111...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       fold  val_samples  masks_empty  gate_fail  num_keep0  \\\n",
       "301952    1       1726.0          0.0        0.0        0.0   \n",
       "603956    2       1725.0          0.0        0.0        0.0   \n",
       "905960    3       1725.0          0.0        0.0        0.0   \n",
       "\n",
       "        cls_filtered_all_fg  no_fg_pre_keep  \\\n",
       "301952                  7.0            60.0   \n",
       "603956                 15.0           165.0   \n",
       "905960                  0.0            65.0   \n",
       "\n",
       "                                                    rates  \\\n",
       "301952  {'masks_empty': 0.0, 'gate_fail': 0.0, 'num_ke...   \n",
       "603956  {'masks_empty': 0.0, 'gate_fail': 0.0, 'num_ke...   \n",
       "905960  {'masks_empty': 0.0, 'gate_fail': 0.0, 'num_ke...   \n",
       "\n",
       "                                             max_cls_prob  \\\n",
       "301952  {'mean': 0.6969074010848999, 'p95': 0.79950189...   \n",
       "603956  {'mean': 0.7042760252952576, 'p95': 0.71485036...   \n",
       "905960  {'mean': 0.646255612373352, 'p95': 0.653552830...   \n",
       "\n",
       "                                            max_mask_prob  \n",
       "301952  {'mean': 0.9507280588150024, 'p95': 0.99998199...  \n",
       "603956  {'mean': 0.8952463269233704, 'p95': 0.99995195...  \n",
       "905960  {'mean': 0.9523042440414429, 'p95': 0.99999111...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== OOF inference debug summary (per fold) ===\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fold</th>\n",
       "      <th>val_samples</th>\n",
       "      <th>masks_empty</th>\n",
       "      <th>gate_fail</th>\n",
       "      <th>num_keep0</th>\n",
       "      <th>cls_filtered_all_fg</th>\n",
       "      <th>no_fg_pre_keep</th>\n",
       "      <th>rates.masks_empty</th>\n",
       "      <th>rates.gate_fail</th>\n",
       "      <th>rates.num_keep0</th>\n",
       "      <th>rates.cls_filtered_all_fg</th>\n",
       "      <th>rates.no_fg_pre_keep</th>\n",
       "      <th>max_cls_prob.mean</th>\n",
       "      <th>max_cls_prob.p95</th>\n",
       "      <th>max_cls_prob.max</th>\n",
       "      <th>max_mask_prob.mean</th>\n",
       "      <th>max_mask_prob.p95</th>\n",
       "      <th>max_mask_prob.max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>301952</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1726.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.004056</td>\n",
       "      <td>0.034762</td>\n",
       "      <td>0.696907</td>\n",
       "      <td>0.799502</td>\n",
       "      <td>0.823863</td>\n",
       "      <td>0.950728</td>\n",
       "      <td>0.999982</td>\n",
       "      <td>0.999999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>603956</th>\n",
       "      <td>2.0</td>\n",
       "      <td>1725.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>165.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.008696</td>\n",
       "      <td>0.095652</td>\n",
       "      <td>0.704276</td>\n",
       "      <td>0.714850</td>\n",
       "      <td>0.714852</td>\n",
       "      <td>0.895246</td>\n",
       "      <td>0.999952</td>\n",
       "      <td>0.999999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>905960</th>\n",
       "      <td>3.0</td>\n",
       "      <td>1725.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.037681</td>\n",
       "      <td>0.646256</td>\n",
       "      <td>0.653553</td>\n",
       "      <td>0.655220</td>\n",
       "      <td>0.952304</td>\n",
       "      <td>0.999991</td>\n",
       "      <td>0.999999</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        fold  val_samples  masks_empty  gate_fail  num_keep0  \\\n",
       "301952   1.0       1726.0          0.0        0.0        0.0   \n",
       "603956   2.0       1725.0          0.0        0.0        0.0   \n",
       "905960   3.0       1725.0          0.0        0.0        0.0   \n",
       "\n",
       "        cls_filtered_all_fg  no_fg_pre_keep  rates.masks_empty  \\\n",
       "301952                  7.0            60.0                0.0   \n",
       "603956                 15.0           165.0                0.0   \n",
       "905960                  0.0            65.0                0.0   \n",
       "\n",
       "        rates.gate_fail  rates.num_keep0  rates.cls_filtered_all_fg  \\\n",
       "301952              0.0              0.0                   0.004056   \n",
       "603956              0.0              0.0                   0.008696   \n",
       "905960              0.0              0.0                   0.000000   \n",
       "\n",
       "        rates.no_fg_pre_keep  max_cls_prob.mean  max_cls_prob.p95  \\\n",
       "301952              0.034762           0.696907          0.799502   \n",
       "603956              0.095652           0.704276          0.714850   \n",
       "905960              0.037681           0.646256          0.653553   \n",
       "\n",
       "        max_cls_prob.max  max_mask_prob.mean  max_mask_prob.p95  \\\n",
       "301952          0.823863            0.950728           0.999982   \n",
       "603956          0.714852            0.895246           0.999952   \n",
       "905960          0.655220            0.952304           0.999991   \n",
       "\n",
       "        max_mask_prob.max  \n",
       "301952           0.999999  \n",
       "603956           0.999999  \n",
       "905960           0.999999  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== OOF inference debug summary (global weighted failure rates) ===\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>weighted_rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>masks_empty</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gate_fail</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>num_keep0</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cls_filtered_all_fg</th>\n",
       "      <td>0.004250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>no_fg_pre_keep</th>\n",
       "      <td>0.056028</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     weighted_rate\n",
       "masks_empty               0.000000\n",
       "gate_fail                 0.000000\n",
       "num_keep0                 0.000000\n",
       "cls_filtered_all_fg       0.004250\n",
       "no_fg_pre_keep            0.056028"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Presence stats (loss_presence_stats: last epoch per fold + mean/std) ===\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fold</th>\n",
       "      <th>epoch</th>\n",
       "      <th>presence_mean</th>\n",
       "      <th>presence_min</th>\n",
       "      <th>presence_max</th>\n",
       "      <th>loss_presence</th>\n",
       "      <th>presence_lse_beta</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>301948</th>\n",
       "      <td>1.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>0.351367</td>\n",
       "      <td>0.301861</td>\n",
       "      <td>0.400873</td>\n",
       "      <td>1.055950</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>603952</th>\n",
       "      <td>2.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>0.275789</td>\n",
       "      <td>0.093194</td>\n",
       "      <td>0.413396</td>\n",
       "      <td>0.706060</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>905956</th>\n",
       "      <td>3.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>0.341684</td>\n",
       "      <td>0.033765</td>\n",
       "      <td>0.579916</td>\n",
       "      <td>0.369726</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        fold  epoch  presence_mean  presence_min  presence_max  loss_presence  \\\n",
       "301948   1.0   25.0       0.351367      0.301861      0.400873       1.055950   \n",
       "603952   2.0   25.0       0.275789      0.093194      0.413396       0.706060   \n",
       "905956   3.0   25.0       0.341684      0.033765      0.579916       0.369726   \n",
       "\n",
       "        presence_lse_beta  \n",
       "301948               10.0  \n",
       "603952               10.0  \n",
       "905956               10.0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>presence_mean</th>\n",
       "      <td>0.322947</td>\n",
       "      <td>0.041125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>presence_min</th>\n",
       "      <td>0.142940</td>\n",
       "      <td>0.140801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>presence_max</th>\n",
       "      <td>0.464728</td>\n",
       "      <td>0.099952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>loss_presence</th>\n",
       "      <td>0.710579</td>\n",
       "      <td>0.343134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>presence_lse_beta</th>\n",
       "      <td>10.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        mean       std\n",
       "presence_mean       0.322947  0.041125\n",
       "presence_min        0.142940  0.140801\n",
       "presence_max        0.464728  0.099952\n",
       "loss_presence       0.710579  0.343134\n",
       "presence_lse_beta  10.000000  0.000000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Auth penalty + few-queries stats (loss_auth_penalty_stats: last epoch per fold + mean/std) ===\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fold</th>\n",
       "      <th>epoch</th>\n",
       "      <th>authentic_frac</th>\n",
       "      <th>per_image_penalty_mean</th>\n",
       "      <th>loss_auth_penalty</th>\n",
       "      <th>few_queries_lambda</th>\n",
       "      <th>loss_few_queries</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>301951</th>\n",
       "      <td>1.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.024829</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.372440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>603955</th>\n",
       "      <td>2.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.018542</td>\n",
       "      <td>0.002088</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.278127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>905959</th>\n",
       "      <td>3.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.023600</td>\n",
       "      <td>0.010641</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.354007</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        fold  epoch  authentic_frac  per_image_penalty_mean  \\\n",
       "301951   1.0   25.0        0.000000                0.024829   \n",
       "603955   2.0   25.0        0.333333                0.018542   \n",
       "905959   3.0   25.0        0.666667                0.023600   \n",
       "\n",
       "        loss_auth_penalty  few_queries_lambda  loss_few_queries  \n",
       "301951           0.000000                 0.1          0.372440  \n",
       "603955           0.002088                 0.1          0.278127  \n",
       "905959           0.010641                 0.1          0.354007  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>authentic_frac</th>\n",
       "      <td>0.333333</td>\n",
       "      <td>3.333333e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>per_image_penalty_mean</th>\n",
       "      <td>0.022324</td>\n",
       "      <td>3.332494e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>loss_auth_penalty</th>\n",
       "      <td>0.004243</td>\n",
       "      <td>5.638275e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>few_queries_lambda</th>\n",
       "      <td>0.100000</td>\n",
       "      <td>1.699675e-17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>loss_few_queries</th>\n",
       "      <td>0.334858</td>\n",
       "      <td>4.998740e-02</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            mean           std\n",
       "authentic_frac          0.333333  3.333333e-01\n",
       "per_image_penalty_mean  0.022324  3.332494e-03\n",
       "loss_auth_penalty       0.004243  5.638275e-03\n",
       "few_queries_lambda      0.100000  1.699675e-17\n",
       "loss_few_queries        0.334858  4.998740e-02"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Class-target balance (loss_cls_targets) ===\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"4\" halign=\"left\">pos</th>\n",
       "      <th colspan=\"4\" halign=\"left\">total</th>\n",
       "      <th colspan=\"4\" halign=\"left\">pos_frac</th>\n",
       "      <th colspan=\"4\" halign=\"left\">weights_sum</th>\n",
       "      <th colspan=\"4\" halign=\"left\">weights_mean</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>max</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>max</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>max</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>max</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fold</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1.0</th>\n",
       "      <td>2.826327</td>\n",
       "      <td>1.469511</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>59.965238</td>\n",
       "      <td>1.020644</td>\n",
       "      <td>30.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.047131</td>\n",
       "      <td>0.024496</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>9.970672</td>\n",
       "      <td>3.168188</td>\n",
       "      <td>0.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>0.166270</td>\n",
       "      <td>0.052760</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2.0</th>\n",
       "      <td>2.850846</td>\n",
       "      <td>1.485101</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>59.982619</td>\n",
       "      <td>0.510322</td>\n",
       "      <td>45.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.047526</td>\n",
       "      <td>0.024756</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>10.024693</td>\n",
       "      <td>3.202679</td>\n",
       "      <td>0.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>0.167123</td>\n",
       "      <td>0.053371</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3.0</th>\n",
       "      <td>2.837822</td>\n",
       "      <td>1.477992</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>59.982619</td>\n",
       "      <td>0.510322</td>\n",
       "      <td>45.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.047310</td>\n",
       "      <td>0.024635</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>9.985968</td>\n",
       "      <td>3.190429</td>\n",
       "      <td>0.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>0.166479</td>\n",
       "      <td>0.053165</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.35</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           pos                          total                        pos_frac  \\\n",
       "          mean       std  min  max       mean       std   min   max      mean   \n",
       "fold                                                                            \n",
       "1.0   2.826327  1.469511  0.0  8.0  59.965238  1.020644  30.0  60.0  0.047131   \n",
       "2.0   2.850846  1.485101  0.0  8.0  59.982619  0.510322  45.0  60.0  0.047526   \n",
       "3.0   2.837822  1.477992  0.0  8.0  59.982619  0.510322  45.0  60.0  0.047310   \n",
       "\n",
       "                              weights_sum                      weights_mean  \\\n",
       "           std  min       max        mean       std  min   max         mean   \n",
       "fold                                                                          \n",
       "1.0   0.024496  0.0  0.133333    9.970672  3.168188  0.0  21.0     0.166270   \n",
       "2.0   0.024756  0.0  0.133333   10.024693  3.202679  0.0  21.0     0.167123   \n",
       "3.0   0.024635  0.0  0.133333    9.985968  3.190429  0.0  21.0     0.166479   \n",
       "\n",
       "                           \n",
       "           std  min   max  \n",
       "fold                       \n",
       "1.0   0.052760  0.0  0.35  \n",
       "2.0   0.053371  0.0  0.35  \n",
       "3.0   0.053165  0.0  0.35  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Hungarian matching input health (hungarian_match_input) ===\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fold</th>\n",
       "      <th>epoch</th>\n",
       "      <th>b</th>\n",
       "      <th>Q</th>\n",
       "      <th>Hm</th>\n",
       "      <th>Wm</th>\n",
       "      <th>tgt_shape</th>\n",
       "      <th>tgt_numel</th>\n",
       "      <th>tgt_sum</th>\n",
       "      <th>allowed_q</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>258800.000000</td>\n",
       "      <td>258800.000000</td>\n",
       "      <td>258800.000000</td>\n",
       "      <td>258800.0</td>\n",
       "      <td>258800.0</td>\n",
       "      <td>258800.0</td>\n",
       "      <td>258800</td>\n",
       "      <td>258800.000000</td>\n",
       "      <td>258800.000000</td>\n",
       "      <td>258800.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[0, 256, 256]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>118850</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2.000097</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>1.499517</td>\n",
       "      <td>15.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>49493.860896</td>\n",
       "      <td>1986.291924</td>\n",
       "      <td>1.962898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.816478</td>\n",
       "      <td>7.211116</td>\n",
       "      <td>1.117950</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>55922.759045</td>\n",
       "      <td>3843.413167</td>\n",
       "      <td>0.198932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>15.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>15.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>15.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>65536.000000</td>\n",
       "      <td>212.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>3.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>15.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>65536.000000</td>\n",
       "      <td>2262.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>3.000000</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>15.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>851968.000000</td>\n",
       "      <td>34445.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 fold          epoch              b         Q        Hm  \\\n",
       "count   258800.000000  258800.000000  258800.000000  258800.0  258800.0   \n",
       "unique            NaN            NaN            NaN       NaN       NaN   \n",
       "top               NaN            NaN            NaN       NaN       NaN   \n",
       "freq              NaN            NaN            NaN       NaN       NaN   \n",
       "mean         2.000097      13.000000       1.499517      15.0      64.0   \n",
       "std          0.816478       7.211116       1.117950       0.0       0.0   \n",
       "min          1.000000       1.000000       0.000000      15.0      64.0   \n",
       "25%          1.000000       7.000000       0.000000      15.0      64.0   \n",
       "50%          2.000000      13.000000       1.000000      15.0      64.0   \n",
       "75%          3.000000      19.000000       2.000000      15.0      64.0   \n",
       "max          3.000000      25.000000       3.000000      15.0      64.0   \n",
       "\n",
       "              Wm      tgt_shape      tgt_numel        tgt_sum      allowed_q  \n",
       "count   258800.0         258800  258800.000000  258800.000000  258800.000000  \n",
       "unique       NaN              8            NaN            NaN            NaN  \n",
       "top          NaN  [0, 256, 256]            NaN            NaN            NaN  \n",
       "freq         NaN         118850            NaN            NaN            NaN  \n",
       "mean        64.0            NaN   49493.860896    1986.291924       1.962898  \n",
       "std          0.0            NaN   55922.759045    3843.413167       0.198932  \n",
       "min         64.0            NaN       0.000000       0.000000       0.000000  \n",
       "25%         64.0            NaN       0.000000       0.000000       2.000000  \n",
       "50%         64.0            NaN   65536.000000     212.000000       2.000000  \n",
       "75%         64.0            NaN   65536.000000    2262.000000       2.000000  \n",
       "max         64.0            NaN  851968.000000   34445.000000       2.000000  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Hungarian matching results (hungarian_match_result) ===\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fold</th>\n",
       "      <th>reason</th>\n",
       "      <th>rows</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>empty_gt</td>\n",
       "      <td>39625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>no_allowed_queries</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>46617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.0</td>\n",
       "      <td>empty_gt</td>\n",
       "      <td>39600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0</td>\n",
       "      <td>no_allowed_queries</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>46647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3.0</td>\n",
       "      <td>empty_gt</td>\n",
       "      <td>39625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>3.0</td>\n",
       "      <td>no_allowed_queries</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>46635</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fold              reason   rows\n",
       "0   1.0            empty_gt  39625\n",
       "1   1.0  no_allowed_queries      8\n",
       "2   1.0                 NaN  46617\n",
       "3   2.0            empty_gt  39600\n",
       "4   2.0  no_allowed_queries     28\n",
       "5   2.0                 NaN  46647\n",
       "6   3.0            empty_gt  39625\n",
       "7   3.0  no_allowed_queries     15\n",
       "8   3.0                 NaN  46635"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fold</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1.0</th>\n",
       "      <td>0.706991</td>\n",
       "      <td>0.734962</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2.0</th>\n",
       "      <td>0.712918</td>\n",
       "      <td>0.741048</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3.0</th>\n",
       "      <td>0.709661</td>\n",
       "      <td>0.737762</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          mean       std  min  max\n",
       "fold                              \n",
       "1.0   0.706991  0.734962  0.0  2.0\n",
       "2.0   0.712918  0.741048  0.0  2.0\n",
       "3.0   0.709661  0.737762  0.0  2.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Sparsity metrics (sparsity_metrics: last epoch per fold + mean/std) ===\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fold</th>\n",
       "      <th>epoch</th>\n",
       "      <th>train_topk</th>\n",
       "      <th>train_min_mask_mass</th>\n",
       "      <th>batch.allowed_mean</th>\n",
       "      <th>batch.qmax_over_sum_mean</th>\n",
       "      <th>batch.mask_mass_max_mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>301949</th>\n",
       "      <td>1.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.001</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.949682</td>\n",
       "      <td>0.454769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>603953</th>\n",
       "      <td>2.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.001</td>\n",
       "      <td>1.666667</td>\n",
       "      <td>0.991286</td>\n",
       "      <td>0.385983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>905957</th>\n",
       "      <td>3.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.001</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.875468</td>\n",
       "      <td>0.569589</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        fold  epoch  train_topk  train_min_mask_mass  batch.allowed_mean  \\\n",
       "301949   1.0   25.0         2.0                0.001            2.000000   \n",
       "603953   2.0   25.0         2.0                0.001            1.666667   \n",
       "905957   3.0   25.0         2.0                0.001            2.000000   \n",
       "\n",
       "        batch.qmax_over_sum_mean  batch.mask_mass_max_mean  \n",
       "301949                  0.949682                  0.454769  \n",
       "603953                  0.991286                  0.385983  \n",
       "905957                  0.875468                  0.569589  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>train_topk</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>train_min_mask_mass</th>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>batch.allowed_mean</th>\n",
       "      <td>1.888889</td>\n",
       "      <td>0.192450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>batch.qmax_over_sum_mean</th>\n",
       "      <td>0.938812</td>\n",
       "      <td>0.058669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>batch.mask_mass_max_mean</th>\n",
       "      <td>0.470114</td>\n",
       "      <td>0.092760</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              mean       std\n",
       "train_topk                2.000000  0.000000\n",
       "train_min_mask_mass       0.001000  0.000000\n",
       "batch.allowed_mean        1.888889  0.192450\n",
       "batch.qmax_over_sum_mean  0.938812  0.058669\n",
       "batch.mask_mass_max_mean  0.470114  0.092760"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Mask-head liveness during training (train_fg_prob_per_query: last epoch) ===\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fold</th>\n",
       "      <th>epoch</th>\n",
       "      <th>Q</th>\n",
       "      <th>fg_prob_mean</th>\n",
       "      <th>fg_prob_p95</th>\n",
       "      <th>fg_prob_max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>301950</th>\n",
       "      <td>1.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0.106675</td>\n",
       "      <td>0.209589</td>\n",
       "      <td>0.454769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>603954</th>\n",
       "      <td>2.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0.043497</td>\n",
       "      <td>0.138753</td>\n",
       "      <td>0.385983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>905958</th>\n",
       "      <td>3.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0.121928</td>\n",
       "      <td>0.250055</td>\n",
       "      <td>0.488099</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        fold  epoch     Q  fg_prob_mean  fg_prob_p95  fg_prob_max\n",
       "301950   1.0   25.0  15.0      0.106675     0.209589     0.454769\n",
       "603954   2.0   25.0  15.0      0.043497     0.138753     0.385983\n",
       "905958   3.0   25.0  15.0      0.121928     0.250055     0.488099"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Mask-head per-query foreground distribution (last epoch, exploded) ===\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fold</th>\n",
       "      <th>mean</th>\n",
       "      <th>p95</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.106675</td>\n",
       "      <td>0.209589</td>\n",
       "      <td>0.454769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.0</td>\n",
       "      <td>0.043497</td>\n",
       "      <td>0.138753</td>\n",
       "      <td>0.385983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.0</td>\n",
       "      <td>0.121928</td>\n",
       "      <td>0.250055</td>\n",
       "      <td>0.488099</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fold      mean       p95       max\n",
       "0   1.0  0.106675  0.209589  0.454769\n",
       "1   2.0  0.043497  0.138753  0.385983\n",
       "2   3.0  0.121928  0.250055  0.488099"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== One-time logits/probability sanity snapshots (debug_probs) ===\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fold</th>\n",
       "      <th>epoch</th>\n",
       "      <th>global_step</th>\n",
       "      <th>mask_probs.mean</th>\n",
       "      <th>mask_probs.p95</th>\n",
       "      <th>mask_probs.max</th>\n",
       "      <th>mask_probs.frac_gt_0p5</th>\n",
       "      <th>class_probs.mean</th>\n",
       "      <th>class_probs.max</th>\n",
       "      <th>class_probs.frac_gt_0p1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.877971</td>\n",
       "      <td>0.999936</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.908700</td>\n",
       "      <td>0.610997</td>\n",
       "      <td>0.721622</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>301956</th>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.318083</td>\n",
       "      <td>0.991757</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.295341</td>\n",
       "      <td>0.540870</td>\n",
       "      <td>0.743484</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>603960</th>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.967447</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.979635</td>\n",
       "      <td>0.331544</td>\n",
       "      <td>0.407548</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        fold  epoch  global_step  mask_probs.mean  mask_probs.p95  \\\n",
       "2        1.0    1.0          0.0         0.877971        0.999936   \n",
       "301956   2.0    1.0          0.0         0.318083        0.991757   \n",
       "603960   3.0    1.0          0.0         0.967447        1.000000   \n",
       "\n",
       "        mask_probs.max  mask_probs.frac_gt_0p5  class_probs.mean  \\\n",
       "2                  1.0                0.908700          0.610997   \n",
       "301956             1.0                0.295341          0.540870   \n",
       "603960             1.0                0.979635          0.331544   \n",
       "\n",
       "        class_probs.max  class_probs.frac_gt_0p1  \n",
       "2              0.721622                      1.0  \n",
       "301956         0.743484                      1.0  \n",
       "603960         0.407548                      1.0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== OOF prediction distribution + area stats (oof_pred_area_stats) ===\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fold</th>\n",
       "      <th>val_samples</th>\n",
       "      <th>pred_auth_frac</th>\n",
       "      <th>pred_non_auth_count</th>\n",
       "      <th>pred_non_auth_area_ratio_mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>301953</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1726.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1726.0</td>\n",
       "      <td>0.395438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>603957</th>\n",
       "      <td>2.0</td>\n",
       "      <td>1725.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1725.0</td>\n",
       "      <td>0.397336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>905961</th>\n",
       "      <td>3.0</td>\n",
       "      <td>1725.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1725.0</td>\n",
       "      <td>0.884338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>905962</th>\n",
       "      <td>NaN</td>\n",
       "      <td>5176.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5176.0</td>\n",
       "      <td>0.559006</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        fold  val_samples  pred_auth_frac  pred_non_auth_count  \\\n",
       "301953   1.0       1726.0             0.0               1726.0   \n",
       "603957   2.0       1725.0             0.0               1725.0   \n",
       "905961   3.0       1725.0             0.0               1725.0   \n",
       "905962   NaN       5176.0             0.0               5176.0   \n",
       "\n",
       "        pred_non_auth_area_ratio_mean  \n",
       "301953                       0.395438  \n",
       "603957                       0.397336  \n",
       "905961                       0.884338  \n",
       "905962                       0.559006  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# --- Load ALL debug events (UPDATED for current collapse logger + train_cv tags) ---\n",
    "\n",
    "dbg = debug_events.copy() if \"debug_events\" in globals() else pd.DataFrame()\n",
    "print(\"debug_events shape:\", dbg.shape)\n",
    "print(\"cols:\", list(dbg.columns))\n",
    "\n",
    "if len(dbg) == 0:\n",
    "    raise ValueError(\"debug_events is empty\")\n",
    "\n",
    "# sanity check: OOF inference debug payload (per-fold, aggregated)\n",
    "oof_raw = dbg[dbg[\"tag\"].astype(str).eq(\"oof_inference_debug\")]\n",
    "show0 = [c for c in [\n",
    "    \"fold\",\"val_samples\",\n",
    "    \"masks_empty\",\"gate_fail\",\"num_keep0\",\"cls_filtered_all_fg\",\"no_fg_pre_keep\",\n",
    "    \"rates\",\"max_cls_prob\",\"max_mask_prob\",\n",
    "] if c in oof_raw.columns]\n",
    "display(oof_raw[show0].head(10))\n",
    "\n",
    "# ---------- helpers ----------\n",
    "def _to_bool(s):\n",
    "    if s.dtype == object:\n",
    "        return s.astype(str).str.lower().isin([\"true\", \"1\", \"yes\"])\n",
    "    return s.astype(bool)\n",
    "\n",
    "def _safe_num(df, cols):\n",
    "    for c in cols:\n",
    "        if c in df.columns:\n",
    "            df[c] = pd.to_numeric(df[c], errors=\"coerce\")\n",
    "    return df\n",
    "\n",
    "def _flatten_dict_col(df, col, prefix=None):\n",
    "    \"\"\"Flatten a dict-valued column into separate columns, preserving row alignment.\"\"\"\n",
    "    if col not in df.columns:\n",
    "        return df\n",
    "    pfx = prefix or col\n",
    "\n",
    "    ser = df[col]\n",
    "    mask = ser.apply(lambda x: isinstance(x, dict))\n",
    "    if not mask.any():\n",
    "        return df\n",
    "\n",
    "    flat = pd.json_normalize(ser[mask])\n",
    "    flat.index = ser[mask].index  # align with original rows\n",
    "    flat.columns = [f\"{pfx}.{k}\" for k in flat.columns]\n",
    "\n",
    "    df = df.drop(columns=[col])\n",
    "    df = df.join(flat, how=\"left\")\n",
    "    return df\n",
    "\n",
    "def p95(x):\n",
    "    x = pd.to_numeric(x, errors=\"coerce\").dropna()\n",
    "    return float(x.quantile(0.95)) if len(x) else np.nan\n",
    "\n",
    "# ---------- flatten nested dict payloads ----------\n",
    "# train_cv emits nested dicts for these tags\n",
    "for col in [\"rates\", \"mask_probs\", \"class_probs\", \"img_probs\", \"max_cls_prob\", \"max_mask_prob\", \"batch\", \"per_image\"]:\n",
    "    dbg = _flatten_dict_col(dbg, col)\n",
    "\n",
    "# ---------- coerce numerics (aligned to current emitted keys) ----------\n",
    "dbg = _safe_num(\n",
    "    dbg,\n",
    "    [\n",
    "        # common\n",
    "        \"fold\",\"epoch\",\"global_step\",\"b\",\"i\",\"B\",\"Q\",\"Hm\",\"Wm\",\n",
    "        \"img_label\",\"val_samples\",\n",
    "\n",
    "        # oof_inference_debug counts\n",
    "        \"masks_empty\",\"gate_fail\",\"num_keep0\",\"cls_filtered_all_fg\",\"no_fg_pre_keep\",\n",
    "\n",
    "        # oof_inference_debug flattened\n",
    "        \"rates.masks_empty\",\"rates.gate_fail\",\"rates.num_keep0\",\"rates.cls_filtered_all_fg\",\"rates.no_fg_pre_keep\",\n",
    "        \"max_cls_prob.mean\",\"max_cls_prob.p95\",\"max_cls_prob.max\",\n",
    "        \"max_mask_prob.mean\",\"max_mask_prob.p95\",\"max_mask_prob.max\",\n",
    "\n",
    "        # batch_target0 / mask_target_sanity / debug_probs\n",
    "        \"masks_sum\",\n",
    "        \"mask_probs.mean\",\"mask_probs.p95\",\"mask_probs.max\",\"mask_probs.frac_gt_0p5\",\n",
    "        \"class_probs.mean\",\"class_probs.max\",\"class_probs.frac_gt_0p1\",\n",
    "\n",
    "        # hungarian matching\n",
    "        \"tgt_numel\",\"tgt_sum\",\"allowed_q\",\"matched\",\"num_gt\",\"Qa\",\n",
    "\n",
    "        # loss_cls_targets\n",
    "        \"pos\",\"total\",\"pos_frac\",\"weights_sum\",\"weights_mean\",\n",
    "\n",
    "        # loss_presence_stats (from compute_losses)\n",
    "        \"presence_mean\",\"presence_min\",\"presence_max\",\"loss_presence\",\"presence_lse_beta\",\n",
    "\n",
    "        # sparsity_metrics (from compute_losses)\n",
    "        \"train_topk\",\"train_min_mask_mass\",\n",
    "        \"batch.allowed_mean\",\"batch.qmax_over_sum_mean\",\"batch.mask_mass_max_mean\",\n",
    "\n",
    "        # train_fg_prob_per_query (from compute_losses)\n",
    "        \"fg_prob_mean\",\"fg_prob_p95\",\"fg_prob_max\",\n",
    "\n",
    "        # loss_auth_penalty_stats (from compute_losses)\n",
    "        \"authentic_frac\",\"per_image_penalty_mean\",\"loss_auth_penalty\",\"few_queries_lambda\",\"loss_few_queries\",\n",
    "\n",
    "        # oof_pred_area_stats (from train_cv)\n",
    "        \"pred_auth_frac\",\"pred_non_auth_count\",\"pred_non_auth_area_ratio_mean\",\n",
    "    ],\n",
    ")\n",
    "\n",
    "# bool-ish flags (only include if present in your dbg)\n",
    "for c in [\"gate_pass\",\"any_fg_pre_keep\",\"any_fg_post_keep\"]:\n",
    "    if c in dbg.columns:\n",
    "        dbg[c] = _to_bool(dbg[c])\n",
    "\n",
    "\n",
    "# ---------- OOF inference debug summary (tag == oof_inference_debug) ----------\n",
    "print(\"\\n=== OOF inference debug summary (per fold) ===\")\n",
    "oof = dbg[dbg[\"tag\"].astype(str).eq(\"oof_inference_debug\")].copy()\n",
    "if len(oof):\n",
    "    show_cols = [c for c in [\n",
    "        \"fold\",\"val_samples\",\n",
    "        \"masks_empty\",\"gate_fail\",\"num_keep0\",\"cls_filtered_all_fg\",\"no_fg_pre_keep\",\n",
    "        \"rates.masks_empty\",\"rates.gate_fail\",\"rates.num_keep0\",\"rates.cls_filtered_all_fg\",\"rates.no_fg_pre_keep\",\n",
    "        \"max_cls_prob.mean\",\"max_cls_prob.p95\",\"max_cls_prob.max\",\n",
    "        \"max_mask_prob.mean\",\"max_mask_prob.p95\",\"max_mask_prob.max\",\n",
    "    ] if c in oof.columns]\n",
    "    display(oof.sort_values(\"fold\")[show_cols])\n",
    "\n",
    "    # global weighted failure rates across folds\n",
    "    print(\"\\n=== OOF inference debug summary (global weighted failure rates) ===\")\n",
    "    denom = oof[\"val_samples\"].astype(float).replace(0, np.nan)\n",
    "    global_rates = {}\n",
    "    for k in [\"masks_empty\",\"gate_fail\",\"num_keep0\",\"cls_filtered_all_fg\",\"no_fg_pre_keep\"]:\n",
    "        if k in oof.columns:\n",
    "            global_rates[k] = float(oof[k].astype(float).sum() / denom.sum())\n",
    "    display(pd.Series(global_rates, name=\"weighted_rate\").to_frame())\n",
    "\n",
    "\n",
    "# ---------- Presence stats (tag == loss_presence_stats) ----------\n",
    "print(\"\\n=== Presence stats (loss_presence_stats: last epoch per fold + mean/std) ===\")\n",
    "pres = dbg[dbg[\"tag\"].astype(str).eq(\"loss_presence_stats\")].copy()\n",
    "if len(pres):\n",
    "    cols = [c for c in [\n",
    "        \"fold\",\"epoch\",\"presence_mean\",\"presence_min\",\"presence_max\",\"loss_presence\",\"presence_lse_beta\"\n",
    "    ] if c in pres.columns]\n",
    "    per_fold_last = (pres.sort_values([\"fold\",\"epoch\"]).groupby(\"fold\", as_index=False).tail(1))[cols]\n",
    "    display(per_fold_last.sort_values(\"fold\"))\n",
    "    display(per_fold_last.drop(columns=[\"fold\",\"epoch\"], errors=\"ignore\").agg([\"mean\",\"std\"]).T)\n",
    "\n",
    "\n",
    "# ---------- Auth penalty + few-queries stats (tag == loss_auth_penalty_stats) ----------\n",
    "print(\"\\n=== Auth penalty + few-queries stats (loss_auth_penalty_stats: last epoch per fold + mean/std) ===\")\n",
    "ap = dbg[dbg[\"tag\"].astype(str).eq(\"loss_auth_penalty_stats\")].copy()\n",
    "if len(ap):\n",
    "    cols = [c for c in [\n",
    "        \"fold\",\"epoch\",\"authentic_frac\",\"per_image_penalty_mean\",\"loss_auth_penalty\",\n",
    "        \"few_queries_lambda\",\"loss_few_queries\"\n",
    "    ] if c in ap.columns]\n",
    "    per_fold_last = (ap.sort_values([\"fold\",\"epoch\"]).groupby(\"fold\", as_index=False).tail(1))[cols]\n",
    "    display(per_fold_last.sort_values(\"fold\"))\n",
    "    display(per_fold_last.drop(columns=[\"fold\",\"epoch\"], errors=\"ignore\").agg([\"mean\",\"std\"]).T)\n",
    "\n",
    "\n",
    "# ---------- Class target balance (tag == loss_cls_targets) ----------\n",
    "print(\"\\n=== Class-target balance (loss_cls_targets) ===\")\n",
    "ct = dbg[dbg[\"tag\"].astype(str).eq(\"loss_cls_targets\")].copy()\n",
    "if len(ct):\n",
    "    cols = [c for c in [\"fold\",\"epoch\",\"B\",\"Q\",\"pos\",\"total\",\"pos_frac\",\"weights_sum\",\"weights_mean\"] if c in ct.columns]\n",
    "    display(\n",
    "        ct[cols]\n",
    "          .groupby(\"fold\", dropna=False)[[c for c in cols if c not in (\"fold\",\"epoch\",\"B\",\"Q\")]]\n",
    "          .agg([\"mean\",\"std\",\"min\",\"max\"])\n",
    "    )\n",
    "\n",
    "\n",
    "# ---------- Hungarian matching health (tags == hungarian_match_*) ----------\n",
    "print(\"\\n=== Hungarian matching input health (hungarian_match_input) ===\")\n",
    "hm_in = dbg[dbg[\"tag\"].astype(str).eq(\"hungarian_match_input\")].copy()\n",
    "hm_out = dbg[dbg[\"tag\"].astype(str).eq(\"hungarian_match_result\")].copy()\n",
    "\n",
    "if len(hm_in):\n",
    "    cols = [c for c in [\"fold\",\"epoch\",\"b\",\"Q\",\"Hm\",\"Wm\",\"tgt_shape\",\"tgt_numel\",\"tgt_sum\",\"allowed_q\"] if c in hm_in.columns]\n",
    "    display(hm_in[cols].describe(include=\"all\"))\n",
    "\n",
    "if len(hm_out):\n",
    "    print(\"\\n=== Hungarian matching results (hungarian_match_result) ===\")\n",
    "    cols = [c for c in [\"fold\",\"epoch\",\"b\",\"matched\",\"num_gt\",\"Q\",\"Qa\",\"reason\",\"cost_shape.0\",\"cost_shape.1\"] if c in hm_out.columns]\n",
    "    if \"reason\" in hm_out.columns:\n",
    "        display(hm_out.groupby([\"fold\",\"reason\"], dropna=False).size().rename(\"rows\").reset_index())\n",
    "    if \"matched\" in hm_out.columns:\n",
    "        display(hm_out.groupby(\"fold\")[\"matched\"].agg([\"mean\",\"std\",\"min\",\"max\"]))\n",
    "\n",
    "\n",
    "# ---------- Sparsity metrics (tag == sparsity_metrics) ----------\n",
    "print(\"\\n=== Sparsity metrics (sparsity_metrics: last epoch per fold + mean/std) ===\")\n",
    "sp = dbg[dbg[\"tag\"].astype(str).eq(\"sparsity_metrics\")].copy()\n",
    "if len(sp):\n",
    "    cols = [c for c in [\n",
    "        \"fold\",\"epoch\",\"train_topk\",\"train_min_mask_mass\",\n",
    "        \"batch.allowed_mean\",\"batch.qmax_over_sum_mean\",\"batch.mask_mass_max_mean\",\n",
    "    ] if c in sp.columns]\n",
    "    per_fold_last = (sp.sort_values([\"fold\",\"epoch\"]).groupby(\"fold\", as_index=False).tail(1))[cols]\n",
    "    display(per_fold_last.sort_values(\"fold\"))\n",
    "    display(per_fold_last.drop(columns=[\"fold\",\"epoch\"], errors=\"ignore\").agg([\"mean\",\"std\"]).T)\n",
    "\n",
    "\n",
    "# ---------- Mask-head alive signal during training (tag == train_fg_prob_per_query) ----------\n",
    "print(\"\\n=== Mask-head liveness during training (train_fg_prob_per_query: last epoch) ===\")\n",
    "fgq = dbg[dbg[\"tag\"].astype(str).eq(\"train_fg_prob_per_query\")].copy()\n",
    "if len(fgq):\n",
    "    cols = [c for c in [\"fold\",\"epoch\",\"Q\",\"fg_prob_mean\",\"fg_prob_p95\",\"fg_prob_max\"] if c in fgq.columns]\n",
    "    per_fold_last = (fgq.sort_values([\"fold\",\"epoch\"]).groupby(\"fold\", as_index=False).tail(1))[cols]\n",
    "    display(per_fold_last.sort_values(\"fold\"))\n",
    "\n",
    "    # fg_prob_per_query is list -> explode if present\n",
    "    if \"fg_prob_per_query\" in fgq.columns:\n",
    "        last = fgq.sort_values([\"fold\",\"epoch\"]).groupby(\"fold\", as_index=False).tail(1)\n",
    "        s = last[[\"fold\",\"epoch\",\"fg_prob_per_query\"]].dropna().explode(\"fg_prob_per_query\")\n",
    "        s[\"fg_prob_per_query\"] = pd.to_numeric(s[\"fg_prob_per_query\"], errors=\"coerce\")\n",
    "        print(\"\\n=== Mask-head per-query foreground distribution (last epoch, exploded) ===\")\n",
    "        display(\n",
    "            s.groupby(\"fold\")[\"fg_prob_per_query\"]\n",
    "             .agg(mean=\"mean\", p95=p95, max=\"max\")\n",
    "             .reset_index()\n",
    "             .sort_values(\"fold\")\n",
    "        )\n",
    "\n",
    "\n",
    "# ---------- One-time logits/prob snapshots (tag == debug_probs) ----------\n",
    "print(\"\\n=== One-time logits/probability sanity snapshots (debug_probs) ===\")\n",
    "dp = dbg[dbg[\"tag\"].astype(str).eq(\"debug_probs\")].copy()\n",
    "if len(dp):\n",
    "    cols = [c for c in dp.columns if c.startswith((\"mask_probs.\",\"class_probs.\",\"img_probs.\"))]\n",
    "    show = [c for c in [\"fold\",\"epoch\",\"global_step\"] if c in dp.columns] + cols\n",
    "    display(dp.sort_values([c for c in [\"fold\",\"epoch\",\"global_step\"] if c in dp.columns]).head(20)[show])\n",
    "\n",
    "\n",
    "# ---------- OOF pred distribution + area stats (tag == oof_pred_area_stats) ----------\n",
    "print(\"\\n=== OOF prediction distribution + area stats (oof_pred_area_stats) ===\")\n",
    "oa = dbg[dbg[\"tag\"].astype(str).eq(\"oof_pred_area_stats\")].copy()\n",
    "if len(oa):\n",
    "    cols = [c for c in [\"fold\",\"val_samples\",\"pred_auth_frac\",\"pred_non_auth_count\",\"pred_non_auth_area_ratio_mean\"] if c in oa.columns]\n",
    "    display(oa.sort_values([c for c in [\"fold\"] if c in oa.columns])[cols])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ad6efd21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fold</th>\n",
       "      <th>val_samples</th>\n",
       "      <th>rates.masks_empty</th>\n",
       "      <th>rates.num_keep0</th>\n",
       "      <th>rates.no_fg_pre_keep</th>\n",
       "      <th>rates.cls_filtered_all_fg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>301952</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1726.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.034762</td>\n",
       "      <td>0.004056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>603956</th>\n",
       "      <td>2.0</td>\n",
       "      <td>1725.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.095652</td>\n",
       "      <td>0.008696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>905960</th>\n",
       "      <td>3.0</td>\n",
       "      <td>1725.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.037681</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        fold  val_samples  rates.masks_empty  rates.num_keep0  \\\n",
       "301952   1.0       1726.0                0.0              0.0   \n",
       "603956   2.0       1725.0                0.0              0.0   \n",
       "905960   3.0       1725.0                0.0              0.0   \n",
       "\n",
       "        rates.no_fg_pre_keep  rates.cls_filtered_all_fg  \n",
       "301952              0.034762                   0.004056  \n",
       "603956              0.095652                   0.008696  \n",
       "905960              0.037681                   0.000000  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>weighted_rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>rates.masks_empty</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rates.num_keep0</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rates.no_fg_pre_keep</th>\n",
       "      <td>0.056028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rates.cls_filtered_all_fg</th>\n",
       "      <td>0.004250</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           weighted_rate\n",
       "rates.masks_empty               0.000000\n",
       "rates.num_keep0                 0.000000\n",
       "rates.no_fg_pre_keep            0.056028\n",
       "rates.cls_filtered_all_fg       0.004250"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Explicit view of the 4 rates you care about (per fold + weighted mean)\n",
    "oof = dbg[dbg[\"tag\"].astype(str).eq(\"oof_inference_debug\")].copy()\n",
    "\n",
    "cols = [\"fold\",\"val_samples\",\"rates.masks_empty\",\"rates.num_keep0\",\"rates.no_fg_pre_keep\",\"rates.cls_filtered_all_fg\"]\n",
    "cols = [c for c in cols if c in oof.columns]\n",
    "display(oof.sort_values(\"fold\")[cols])\n",
    "\n",
    "w = oof[\"val_samples\"].astype(float).replace(0, np.nan)\n",
    "rate_cols = [c for c in cols if c.startswith(\"rates.\")]\n",
    "weighted = {c: float((oof[c].astype(float) * w).sum() / w.sum()) for c in rate_cols}\n",
    "display(pd.Series(weighted, name=\"weighted_rate\").to_frame())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "5f8387ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fold</th>\n",
       "      <th>epoch</th>\n",
       "      <th>loss_mask_bce</th>\n",
       "      <th>loss_mask_dice</th>\n",
       "      <th>loss_mask_cls</th>\n",
       "      <th>loss_presence</th>\n",
       "      <th>loss_auth_penalty</th>\n",
       "      <th>loss_total</th>\n",
       "      <th>w_mask_cls</th>\n",
       "      <th>w_presence</th>\n",
       "      <th>w_auth_penalty</th>\n",
       "      <th>val_samples</th>\n",
       "      <th>pred_auth_frac</th>\n",
       "      <th>pred_non_auth_count</th>\n",
       "      <th>pred_non_auth_area_ratio_mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>25</td>\n",
       "      <td>0.273408</td>\n",
       "      <td>0.684994</td>\n",
       "      <td>0.406272</td>\n",
       "      <td>0.740069</td>\n",
       "      <td>0.010942</td>\n",
       "      <td>2.155844</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1726.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1726.0</td>\n",
       "      <td>0.395438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>25</td>\n",
       "      <td>0.277971</td>\n",
       "      <td>0.628880</td>\n",
       "      <td>0.420679</td>\n",
       "      <td>0.681091</td>\n",
       "      <td>0.009332</td>\n",
       "      <td>2.057215</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1725.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1725.0</td>\n",
       "      <td>0.397336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>25</td>\n",
       "      <td>0.276628</td>\n",
       "      <td>0.634515</td>\n",
       "      <td>0.418339</td>\n",
       "      <td>0.678949</td>\n",
       "      <td>0.009318</td>\n",
       "      <td>2.057366</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1725.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1725.0</td>\n",
       "      <td>0.884338</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  fold  epoch  loss_mask_bce  loss_mask_dice  loss_mask_cls  loss_presence  \\\n",
       "0    1     25       0.273408        0.684994       0.406272       0.740069   \n",
       "1    2     25       0.277971        0.628880       0.420679       0.681091   \n",
       "2    3     25       0.276628        0.634515       0.418339       0.678949   \n",
       "\n",
       "   loss_auth_penalty  loss_total  w_mask_cls  w_presence  w_auth_penalty  \\\n",
       "0           0.010942    2.155844         1.0         1.0             1.0   \n",
       "1           0.009332    2.057215         1.0         1.0             1.0   \n",
       "2           0.009318    2.057366         1.0         1.0             1.0   \n",
       "\n",
       "   val_samples  pred_auth_frac  pred_non_auth_count  \\\n",
       "0       1726.0             0.0               1726.0   \n",
       "1       1725.0             0.0               1725.0   \n",
       "2       1725.0             0.0               1725.0   \n",
       "\n",
       "   pred_non_auth_area_ratio_mean  \n",
       "0                       0.395438  \n",
       "1                       0.397336  \n",
       "2                       0.884338  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Join last-epoch losses/weights with OOF behavior summaries (per fold)\n",
    "\n",
    "loss_keep = [\n",
    "    \"fold\",\"epoch\",\n",
    "    \"loss_mask_bce\",\"loss_mask_dice\",\"loss_mask_cls\",\"loss_presence\",\"loss_auth_penalty\",\"loss_total\",\n",
    "    \"w_mask_cls\",\"w_presence\",\"w_auth_penalty\",\n",
    "]\n",
    "loss_keep = [c for c in loss_keep if c in epoch_losses.columns]\n",
    "\n",
    "last_loss = (\n",
    "    epoch_losses.sort_values([\"fold\",\"epoch\"])\n",
    "    .groupby(\"fold\", as_index=False)\n",
    "    .tail(1)[loss_keep]\n",
    ")\n",
    "\n",
    "dbg = debug_events.copy()\n",
    "\n",
    "oof_inf = dbg[dbg[\"tag\"].astype(str).eq(\"oof_inference_debug\")].copy()\n",
    "oof_area = dbg[dbg[\"tag\"].astype(str).eq(\"oof_pred_area_stats\")].copy()\n",
    "\n",
    "# keep only fold-level summary cols\n",
    "oof_inf_cols = [c for c in [\n",
    "    \"fold\",\"val_samples\",\n",
    "    \"rates.num_keep0\",\"rates.gate_fail\",\"rates.masks_empty\",\n",
    "    \"max_cls_prob.p95\",\"max_mask_prob.p95\",\n",
    "] if c in oof_inf.columns]\n",
    "\n",
    "oof_area_cols = [c for c in [\n",
    "    \"fold\",\"pred_auth_frac\",\"pred_non_auth_count\",\"pred_non_auth_area_ratio_mean\",\n",
    "] if c in oof_area.columns]\n",
    "\n",
    "# (flattened cols may not exist if you didn't flatten; fallback to raw)\n",
    "if \"rates.num_keep0\" not in oof_inf.columns and \"rates\" in oof_inf.columns:\n",
    "    oof_inf = pd.concat([oof_inf.drop(columns=[\"rates\"]), pd.json_normalize(oof_inf[\"rates\"]).add_prefix(\"rates.\")], axis=1)\n",
    "\n",
    "if \"max_cls_prob.p95\" not in oof_inf.columns and \"max_cls_prob\" in oof_inf.columns:\n",
    "    oof_inf = pd.concat([oof_inf.drop(columns=[\"max_cls_prob\"]), pd.json_normalize(oof_inf[\"max_cls_prob\"]).add_prefix(\"max_cls_prob.\")], axis=1)\n",
    "\n",
    "if \"max_mask_prob.p95\" not in oof_inf.columns and \"max_mask_prob\" in oof_inf.columns:\n",
    "    oof_inf = pd.concat([oof_inf.drop(columns=[\"max_mask_prob\"]), pd.json_normalize(oof_inf[\"max_mask_prob\"]).add_prefix(\"max_mask_prob.\")], axis=1)\n",
    "\n",
    "oof_inf_cols = [c for c in oof_inf_cols if c in oof_inf.columns]\n",
    "\n",
    "summary = (\n",
    "    last_loss\n",
    "    .merge(oof_inf[oof_inf_cols].drop_duplicates(\"fold\"), on=\"fold\", how=\"left\")\n",
    "    .merge(oof_area[oof_area_cols].drop_duplicates(\"fold\"), on=\"fold\", how=\"left\")\n",
    "    .sort_values(\"fold\")\n",
    "    .reset_index(drop=True)\n",
    ")\n",
    "\n",
    "display(summary)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "6a3f5cae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fold</th>\n",
       "      <th>val_samples</th>\n",
       "      <th>masks_empty</th>\n",
       "      <th>gate_fail</th>\n",
       "      <th>num_keep0</th>\n",
       "      <th>cls_filtered_all_fg</th>\n",
       "      <th>no_fg_pre_keep</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>301952</th>\n",
       "      <td>1</td>\n",
       "      <td>1726.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>60.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>603956</th>\n",
       "      <td>2</td>\n",
       "      <td>1725.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>165.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>905960</th>\n",
       "      <td>3</td>\n",
       "      <td>1725.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>65.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        fold  val_samples  masks_empty  gate_fail  num_keep0  \\\n",
       "301952     1       1726.0          0.0        0.0        0.0   \n",
       "603956     2       1725.0          0.0        0.0        0.0   \n",
       "905960     3       1725.0          0.0        0.0        0.0   \n",
       "\n",
       "        cls_filtered_all_fg  no_fg_pre_keep  \n",
       "301952                  7.0            60.0  \n",
       "603956                 15.0           165.0  \n",
       "905960                  0.0            65.0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fold</th>\n",
       "      <th>val_samples</th>\n",
       "      <th>pred_auth_frac</th>\n",
       "      <th>pred_non_auth_count</th>\n",
       "      <th>pred_non_auth_area_ratio_mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>301953</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1726.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1726.0</td>\n",
       "      <td>0.395438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>603957</th>\n",
       "      <td>2.0</td>\n",
       "      <td>1725.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1725.0</td>\n",
       "      <td>0.397336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>905961</th>\n",
       "      <td>3.0</td>\n",
       "      <td>1725.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1725.0</td>\n",
       "      <td>0.884338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>905962</th>\n",
       "      <td>NaN</td>\n",
       "      <td>5176.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5176.0</td>\n",
       "      <td>0.559006</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        fold  val_samples  pred_auth_frac  pred_non_auth_count  \\\n",
       "301953   1.0       1726.0             0.0               1726.0   \n",
       "603957   2.0       1725.0             0.0               1725.0   \n",
       "905961   3.0       1725.0             0.0               1725.0   \n",
       "905962   NaN       5176.0             0.0               5176.0   \n",
       "\n",
       "        pred_non_auth_area_ratio_mean  \n",
       "301953                       0.395438  \n",
       "603957                       0.397336  \n",
       "905961                       0.884338  \n",
       "905962                       0.559006  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Fold-level val_loader debug counts (from oof_inference_debug events)\n",
    "def _extract_debug_event(df: pd.DataFrame, tag: str) -> pd.DataFrame:\n",
    "    if df is None or len(df) == 0:\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    if \"tag\" in df.columns:\n",
    "        ev = df[df[\"tag\"].astype(str) == tag].copy()\n",
    "    else:\n",
    "        ev = df.copy()\n",
    "\n",
    "    if len(ev) == 0:\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    if \"payload\" in ev.columns:\n",
    "        payloads = ev[\"payload\"].tolist()\n",
    "        return pd.json_normalize(payloads, sep=\".\")\n",
    "    return ev\n",
    "\n",
    "\n",
    "def _maybe_to_numeric(s: pd.Series) -> pd.Series:\n",
    "    \"\"\"Convert where possible; leave original values when conversion fails.\"\"\"\n",
    "    try:\n",
    "        out = pd.to_numeric(s, errors=\"coerce\")\n",
    "        # If nothing converted, keep original dtype/values\n",
    "        return s if out.isna().all() else out\n",
    "    except Exception:\n",
    "        return s\n",
    "\n",
    "\n",
    "# dbg should already exist from your earlier \"debug*.jsonl\" concat\n",
    "oof_inf = _extract_debug_event(dbg, \"oof_inference_debug\")\n",
    "oof_area = _extract_debug_event(dbg, \"oof_pred_area_stats\")\n",
    "\n",
    "if len(oof_inf) == 0:\n",
    "    print(\"No oof_inference_debug events found in dbg (check debug jsonl ingestion).\")\n",
    "else:\n",
    "    cols = [\n",
    "        \"fold\", \"val_samples\",\n",
    "        \"masks_empty\", \"gate_fail\", \"num_keep0\", \"cls_filtered_all_fg\", \"no_fg_pre_keep\",\n",
    "        \"rates.masks_empty\", \"rates.gate_fail\", \"rates.num_keep0\", \"rates.cls_filtered_all_fg\", \"rates.no_fg_pre_keep\",\n",
    "        \"max_cls_prob.mean\", \"max_cls_prob.p95\", \"max_cls_prob.max\",\n",
    "        \"max_mask_prob.mean\", \"max_mask_prob.p95\", \"max_mask_prob.max\",\n",
    "    ]\n",
    "    keep = [c for c in cols if c in oof_inf.columns]\n",
    "    oof_inf_view = oof_inf[keep].copy()\n",
    "\n",
    "    for c in oof_inf_view.columns:\n",
    "        if c != \"fold\":\n",
    "            oof_inf_view[c] = _maybe_to_numeric(oof_inf_view[c])\n",
    "\n",
    "    if \"fold\" in oof_inf_view.columns:\n",
    "        oof_inf_view[\"fold\"] = pd.to_numeric(oof_inf_view[\"fold\"], errors=\"coerce\")\n",
    "        oof_inf_view = oof_inf_view.sort_values(\"fold\", na_position=\"last\")\n",
    "\n",
    "    display(oof_inf_view)\n",
    "\n",
    "if len(oof_area) == 0:\n",
    "    print(\"No oof_pred_area_stats events found in dbg (check debug jsonl ingestion).\")\n",
    "else:\n",
    "    cols = [\"fold\", \"val_samples\", \"pred_auth_frac\", \"pred_non_auth_count\", \"pred_non_auth_area_ratio_mean\"]\n",
    "    keep = [c for c in cols if c in oof_area.columns]\n",
    "    oof_area_view = oof_area[keep].copy()\n",
    "\n",
    "    if \"fold\" in oof_area_view.columns:\n",
    "        oof_area_view[\"fold\"] = pd.to_numeric(oof_area_view[\"fold\"], errors=\"coerce\")\n",
    "\n",
    "    for c in oof_area_view.columns:\n",
    "        if c != \"fold\":\n",
    "            oof_area_view[c] = _maybe_to_numeric(oof_area_view[c])\n",
    "\n",
    "    if \"fold\" in oof_area_view.columns:\n",
    "        oof_area_view = oof_area_view.sort_values(\"fold\", na_position=\"last\")\n",
    "\n",
    "    display(oof_area_view)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "951e6360",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# --- Plots: mask_max_mean, mask_max_p95 vs epoch ---\n",
    "\n",
    "es_plot = epoch_summary.copy()\n",
    "\n",
    "need = [\"fold\", \"epoch\", \"mask_max_mean\", ]\n",
    "missing = [c for c in need if c not in es_plot.columns]\n",
    "if missing:\n",
    "    raise ValueError(f\"epoch_summary missing required columns: {missing}\")\n",
    "\n",
    "# coerce numeric\n",
    "for c in [\"fold\", \"epoch\", \"mask_max_mean\"]:\n",
    "    es_plot[c] = pd.to_numeric(es_plot[c], errors=\"coerce\")\n",
    "\n",
    "es_plot = es_plot.dropna(subset=[\"epoch\", \"mask_max_mean\"])\n",
    "\n",
    "# aggregate across folds per epoch\n",
    "g = es_plot.groupby(\"epoch\", as_index=False).agg(\n",
    "    mask_max_mean=(\"mask_max_mean\", \"mean\"),\n",
    "    mask_max_p95=(\"mask_max_mean\", lambda s: s.quantile(0.95))\n",
    ")\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(g[\"epoch\"], g[\"mask_max_mean\"], marker=\"o\", label=\"mask_max_mean\")\n",
    "plt.plot(g[\"epoch\"], g[\"mask_max_p95\"], marker=\"o\", label=\"mask_max_p95 (over folds)\")\n",
    "plt.xlabel(\"epoch\")\n",
    "plt.ylabel(\"value\")\n",
    "plt.title(\"Epoch trends (pooled across folds)\")\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e08e2c02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sanity_random_200 check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "883e8ec8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>rows</th>\n",
       "      <td>200.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>forged_folder_rate</th>\n",
       "      <td>0.545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>image_label_rate</th>\n",
       "      <td>0.545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>any_instances_rate</th>\n",
       "      <td>0.545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean_union_sum</th>\n",
       "      <td>30973.545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean_max_instance_sum</th>\n",
       "      <td>26154.455</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           value\n",
       "rows                     200.000\n",
       "forged_folder_rate         0.545\n",
       "image_label_rate           0.545\n",
       "any_instances_rate         0.545\n",
       "mean_union_sum         30973.545\n",
       "mean_max_instance_sum  26154.455"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "csvs = sorted(SAMPLEDUMP_ROOT.rglob(\"sanity_random_200.csv\"))\n",
    "assert csvs, \"No sanity_random_200.csv found under sanity_dumps\"\n",
    "\n",
    "df = pd.read_csv(csvs[-1])\n",
    "\n",
    "summary = {\n",
    "    \"rows\": len(df),\n",
    "    \"forged_folder_rate\": df[\"is_forged_folder\"].mean(),\n",
    "    \"image_label_rate\": df[\"image_label\"].mean(),\n",
    "    \"any_instances_rate\": (df[\"num_instances\"] > 0).mean(),\n",
    "    \"mean_union_sum\": df[\"union_sum\"].mean(),\n",
    "    \"mean_max_instance_sum\": df[\"max_instance_sum\"].mean(),\n",
    "}\n",
    "\n",
    "display(pd.Series(summary, name=\"value\").to_frame())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "af122e99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>image_label</th>\n",
       "      <th>0.0</th>\n",
       "      <th>1.0</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>is_forged_folder</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>False</th>\n",
       "      <td>91</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <td>0</td>\n",
       "      <td>109</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "image_label       0.0  1.0\n",
       "is_forged_folder          \n",
       "False              91    0\n",
       "True                0  109"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cross-tab: are forged-folder images ever labeled authentic?\n",
    "pd.crosstab(df[\"is_forged_folder\"], df[\"image_label\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "bb1cd480",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# How often do we have forged-folder but zero instances?\n",
    "df.query(\"is_forged_folder == True and num_instances == 0\").shape[0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
