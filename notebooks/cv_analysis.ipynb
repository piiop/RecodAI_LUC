{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "67e6b406",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cv_analysis.ipynb\n",
    "\n",
    "import json\n",
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "PROJECT_ROOT = Path(\"..\").resolve()\n",
    "\n",
    "if str(PROJECT_ROOT) not in sys.path:\n",
    "    sys.path.insert(0, str(PROJECT_ROOT))\n",
    "\n",
    "from src.data.dataloader import (\n",
    "    ForgeryDataset,\n",
    "    detection_collate_fn,\n",
    "    get_val_transform,\n",
    ")\n",
    "from src.models.mask2former_v1 import Mask2FormerForgeryModel\n",
    "from src.utils.config_utils import load_yaml, sanitize_model_kwargs\n",
    "from src.training.train_cv import build_solution_df\n",
    "from src.data.dataloader import ForgeryDataset\n",
    "from src.models.kaggle_metric import score as kaggle_score\n",
    "\n",
    "plt.style.use(\"ggplot\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1cb53e0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------\n",
    "# Constants / Paths\n",
    "# -----------------\n",
    "\n",
    "OOF_ROOT = PROJECT_ROOT / \"experiments\" / \"oof_results\"\n",
    "FULL_TRAIN_ROOT = PROJECT_ROOT / \"experiments\" / \"full_train_results\"\n",
    "\n",
    "CLS_THRESHOLD_PATH = (\n",
    "    PROJECT_ROOT / \"experiments\" / \"cls_threshold_sweep\" / \"cls_threshold_sweep.csv\"\n",
    ")\n",
    "\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "CFG_PATH = PROJECT_ROOT / \"config\" / \"base.yaml\"\n",
    "\n",
    "CLPSE_ROOT = PROJECT_ROOT / \"experiments\" / \"cls_collapse\"\n",
    "\n",
    "SAMPLEDUMP_ROOT = PROJECT_ROOT / \"experiments\" / \"oof_results\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d693608",
   "metadata": {},
   "source": [
    "### OOF CV results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a5c26d53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OOF dirs: ['anti_collapse_wcls2_strong_auth_penalty', 'balanced_soft_penalty_thr0p3_temp0p3', 'base_wgroupkfold', 'cls_unclamp_test', 'gate_pass_TRUE', 'inf_thresh_off', 'mask_first_wmask4_wcls0p25', 'mini_smoke']\n",
      "OOF loose files: ['sanity_random_200.csv']\n"
     ]
    }
   ],
   "source": [
    "# List what's in experiments/oof_results/\n",
    "oof_items = list(OOF_ROOT.iterdir())\n",
    "oof_dirs = sorted([p.name for p in oof_items if p.is_dir()])\n",
    "oof_files = sorted([p.name for p in oof_items if p.is_file()])\n",
    "\n",
    "print(\"OOF dirs:\", oof_dirs)\n",
    "if oof_files:\n",
    "    print(\"OOF loose files:\", oof_files)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "03a67ab1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded:\n",
      " - anti_collapse_wcls2_strong_auth_penalty (C:\\Users\\piiop\\Desktop\\Portfolio\\Projects\\RecodAI_LUC\\experiments\\oof_results\\anti_collapse_wcls2_strong_auth_penalty)\n"
     ]
    }
   ],
   "source": [
    "def load_run(names):\n",
    "    \"\"\"\n",
    "    names:\n",
    "      - str: dir name under OOF_ROOT OR filename under OOF_ROOT\n",
    "      - list/tuple[str]: load multiple; returns dict keyed by run/filename\n",
    "    \"\"\"\n",
    "    if isinstance(names, (list, tuple)):\n",
    "        return {str(n): load_run(str(n)) for n in names}\n",
    "\n",
    "    name = str(names)\n",
    "    p = OOF_ROOT / name\n",
    "\n",
    "    # Case A: run directory\n",
    "    if p.is_dir():\n",
    "        run_dir = p\n",
    "        oof_csv = run_dir / \"oof_predictions.csv\"\n",
    "        metrics_json = run_dir / \"oof_metrics.json\"\n",
    "\n",
    "        oof_df = pd.read_csv(oof_csv) if oof_csv.exists() else None\n",
    "        metrics = json.load(metrics_json.open()) if metrics_json.exists() else None\n",
    "\n",
    "        fold_files = sorted(run_dir.glob(\"fold_*_oof.csv\"))\n",
    "        fold_dfs = {f.stem: pd.read_csv(f) for f in fold_files}\n",
    "\n",
    "        return {\"name\": run_dir.name, \"path\": run_dir, \"oof\": oof_df, \"metrics\": metrics, \"folds\": fold_dfs}\n",
    "\n",
    "    # Case B: loose file\n",
    "    if p.is_file():\n",
    "        if p.suffix.lower() == \".csv\":\n",
    "            return {\"name\": p.name, \"path\": p, \"oof\": pd.read_csv(p), \"metrics\": None, \"folds\": {}}\n",
    "        if p.suffix.lower() == \".json\":\n",
    "            return {\"name\": p.name, \"path\": p, \"oof\": None, \"metrics\": json.load(p.open()), \"folds\": {}}\n",
    "        raise ValueError(f\"Unsupported file type: {p.suffix}\")\n",
    "\n",
    "    raise FileNotFoundError(f\"Not found under OOF_ROOT: {name}\")\n",
    "\n",
    "# Use load_run(name | [names]) to load one or more CV runs or loose files from experiments/oof_results/\n",
    "runs = load_run([\"anti_collapse_wcls2_strong_auth_penalty\"])  # or: load_run(\"mini_smoke\"), load_run(\"oof_predictions.csv\")\n",
    "\n",
    "print(\"Loaded:\")\n",
    "if isinstance(runs, dict) and \"name\" not in runs:\n",
    "    for k, v in runs.items():\n",
    "        print(f\" - {v['name']} ({v['path']})\")\n",
    "else:\n",
    "    print(f\" - {runs['name']} ({runs['path']})\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "eba815e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Loaded runs ===\n",
      "\n",
      "anti_collapse_wcls2_strong_auth_penalty\n",
      "  Mean CV   : 0.053382863963528086\n",
      "  OOF score : 0.05338264970685973\n",
      "  Folds     : [0.0522738714481377, 0.054225164098428584, 0.05364955634401796]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 700x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def show_run_metrics(names):\n",
    "    \"\"\"\n",
    "    Pass a run dir name (str) or list of names to compare.\n",
    "    \"\"\"\n",
    "    runs = load_run(names)\n",
    "    if isinstance(runs, dict) and \"name\" not in runs:\n",
    "        items = list(runs.values())\n",
    "    else:\n",
    "        items = [runs]\n",
    "\n",
    "    # Clean summary header\n",
    "    print(\"=== Loaded runs ===\")\n",
    "    for r in items:\n",
    "        m = r[\"metrics\"] or {}\n",
    "        mean_cv = m.get(\"mean_cv\", None)\n",
    "        oof_score = m.get(\"oof_score\", None)\n",
    "        fold_scores = m.get(\"fold_scores\", None)\n",
    "\n",
    "        print(f\"\\n{r['name']}\")\n",
    "        print(f\"  Mean CV   : {mean_cv}\")\n",
    "        print(f\"  OOF score : {oof_score}\")\n",
    "        if fold_scores is not None:\n",
    "            print(f\"  Folds     : {fold_scores}\")\n",
    "\n",
    "    # Comparison plot (only for runs that have fold_scores)\n",
    "    plot_items = [(r[\"name\"], (r[\"metrics\"] or {}).get(\"fold_scores\")) for r in items]\n",
    "    plot_items = [(n, fs) for (n, fs) in plot_items if fs is not None]\n",
    "\n",
    "    if plot_items:\n",
    "        plt.figure(figsize=(7, 4))\n",
    "        for name, fs in plot_items:\n",
    "            plt.plot(range(1, len(fs) + 1), fs, marker=\"o\", label=name)\n",
    "        plt.xlabel(\"Fold\")\n",
    "        plt.ylabel(\"Score\")\n",
    "        plt.title(\"Per-fold scores (comparison)\")\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "\n",
    "    return runs\n",
    "\n",
    "# Single run\n",
    "_ = show_run_metrics(\"anti_collapse_wcls2_strong_auth_penalty\")\n",
    "\n",
    "# Compare multiple runs\n",
    "# _ = show_run_metrics([\"mini_smoke\", \"some_other_run\"])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc645bc2",
   "metadata": {},
   "source": [
    "## CollapseLogger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a17d44dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "== oof_predictions.csv (head) ==\n",
      "\n",
      "Found fold CSVs: ['fold_1_oof', 'fold_2_oof', 'fold_3_oof']\n"
     ]
    }
   ],
   "source": [
    "# ---- Use an already-loaded run from `runs` ----\n",
    "run = runs[\"anti_collapse_wcls2_strong_auth_penalty\"]  # must exist in `runs`\n",
    "\n",
    "OOF_RUN_DIR = Path(run[\"path\"])\n",
    "oof_metrics = run[\"metrics\"] or {}\n",
    "oof_predictions = run[\"oof\"]\n",
    "fold_dfs = run[\"folds\"]\n",
    "\n",
    "print(\"\\n== oof_predictions.csv (head) ==\")\n",
    "display(oof_predictions.head() if oof_predictions is not None else None)\n",
    "\n",
    "print(\"\\nFound fold CSVs:\", list(fold_dfs.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72e30e1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "== Recomputed overall OOF score ==\n",
      "recomputed_oof: 0.045927753444568294\n",
      "\n",
      "== Recomputed per-fold scores ==\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fold</th>\n",
       "      <th>kaggle_metric</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.052274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.054225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.053650</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fold  kaggle_metric\n",
       "0     1       0.052274\n",
       "1     2       0.054225\n",
       "2     3       0.053650"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Rebuild solution_df and re-score to match train_cv additional pipeline verification\n",
    "full_dataset = ForgeryDataset(transform=None)\n",
    "solution_df = build_solution_df(full_dataset)\n",
    "\n",
    "# Overall OOF score (ALIGN BY row_id, then score)\n",
    "solution_df[\"row_id\"] = solution_df[\"row_id\"].astype(str)\n",
    "oof_predictions[\"row_id\"] = oof_predictions[\"row_id\"].astype(str)\n",
    "\n",
    "sub_aligned = (\n",
    "    solution_df[[\"row_id\"]]\n",
    "    .merge(oof_predictions[[\"row_id\", \"annotation\"]], on=\"row_id\", how=\"left\")\n",
    ")\n",
    "\n",
    "recomputed_oof = kaggle_score(\n",
    "    solution_df[[\"row_id\", \"annotation\", \"shape\"]].copy(),\n",
    "    sub_aligned[[\"row_id\", \"annotation\"]].copy(),\n",
    "    row_id_column_name=\"row_id\",\n",
    ")\n",
    "\n",
    "print(\"\\n== Recomputed overall OOF score ==\")\n",
    "print(\"recomputed_oof:\", float(recomputed_oof))\n",
    "\n",
    "# Per-fold (recompute using the saved fold CSVs if present)\n",
    "def fold_num_from_stem(stem: str) -> int:\n",
    "    m = re.search(r\"(\\d+)\", stem)\n",
    "    return int(m.group(1)) if m else -1\n",
    "\n",
    "if fold_dfs:\n",
    "    # Build stable (row_id, occ) keys on the FULL solution_df once\n",
    "    sol = solution_df.copy()\n",
    "    sol[\"row_id\"] = sol[\"row_id\"].astype(str)\n",
    "    sol[\"occ\"] = sol.groupby(\"row_id\").cumcount()\n",
    "\n",
    "    fold_scores = []\n",
    "    for stem, fdf in sorted(fold_dfs.items(), key=lambda kv: fold_num_from_stem(kv[0])):\n",
    "        fnum = fold_num_from_stem(stem)\n",
    "\n",
    "        sub = fdf.copy()\n",
    "        sub[\"row_id\"] = sub[\"row_id\"].astype(str)\n",
    "        # IMPORTANT: occ must follow the fold CSV order (this is what well score)\n",
    "        sub[\"occ\"] = sub.groupby(\"row_id\").cumcount()\n",
    "\n",
    "        # Rebuild fold solution IN THE SAME ORDER AS sub (no sorting, no isin)\n",
    "        fold_sol = sub[[\"row_id\", \"occ\"]].merge(\n",
    "            sol[[\"row_id\", \"occ\", \"annotation\", \"shape\"]],\n",
    "            on=[\"row_id\", \"occ\"],\n",
    "            how=\"left\",\n",
    "        )\n",
    "\n",
    "        # Hard sanity checks (if these fail, your saved fold CSV isn't compatible with solution_df)\n",
    "        assert len(fold_sol) == len(sub)\n",
    "        if fold_sol[\"annotation\"].isna().any() or fold_sol[\"shape\"].isna().any():\n",
    "            bad = fold_sol[fold_sol[\"annotation\"].isna() | fold_sol[\"shape\"].isna()].head(10)\n",
    "            raise RuntimeError(f\"{stem}: fold_sol has missing GT rows. Sample:\\n{bad}\")\n",
    "\n",
    "        # Submission already in correct order; kaggle_score aligns by row order\n",
    "        fold_sub = sub[[\"row_id\", \"annotation\"]].copy()\n",
    "\n",
    "        s = kaggle_score(\n",
    "            fold_sol[[\"row_id\", \"annotation\", \"shape\"]].copy(),\n",
    "            fold_sub.copy(),\n",
    "            row_id_column_name=\"row_id\",\n",
    "        )\n",
    "        fold_scores.append((fnum, float(s)))\n",
    "\n",
    "    fold_scores_df = pd.DataFrame(fold_scores, columns=[\"fold\", \"kaggle_metric\"]).sort_values(\"fold\")\n",
    "    print(\"\\n== Recomputed per-fold scores ==\")\n",
    "    display(fold_scores_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c4929a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded ClsCollapseLogger artifacts for folds: [1, 2, 3]\n",
      "  JSON blobs : 6\n",
      "  Tables     : 9\n",
      "\n",
      "fold1 tables:\n",
      "  - cv_fold1\\debug.jsonl | shape=(2069734, 53) | cols=['tag', 'fold', 'epoch', 'global_step', 'img_label', 'masks_shape', 'masks_sum', 'b', 'Q', 'Hm', 'Wm', 'tgt_shape', 'tgt_numel', 'tgt_sum', 'cost_shape', 'matched', 'num_gt', 'B', 'pos', 'total', 'pos_frac', 'thr', 'temp', 'authentic_frac', 'per_image_penalty_mean', 'loss_auth_penalty', 'reason', 'per_image', 'mask_probs', 'class_probs', 'img_probs', 'val_samples', 'masks_empty', 'gate_fail', 'num_keep0', 'cls_filtered_all_fg', 'rates', 'max_cls_prob', 'max_mask_prob', 'presence_mean', 'presence_min', 'presence_max', 'tau', 'loss_presence_auth', 'loss_forged_presence', 'fg_prob_per_query', 'fg_prob_mean', 'fg_prob_p95', 'fg_prob_max', 'no_fg_pre_keep', 'pred_auth_frac', 'pred_non_auth_count', 'pred_non_auth_area_ratio_mean']\n",
      "  - cv_fold1\\epoch_summary.csv | shape=(229, 11) | cols=['fold', 'epoch', 'epoch_loss', 'cls_max_mean', 'cls_max_p95', 'keep_rate@0.1', 'keep_rate@0.2', 'keep_rate@0.3', 'img_forged_mean', 'mask_max_mean', 'w_mask_cls']\n",
      "  - cv_fold1\\step_losses.csv | shape=(198153, 12) | cols=['fold', 'epoch', 'global_step', 'lr', 'loss_mask_bce', 'loss_mask_dice', 'loss_mask_cls', 'loss_img_auth', 'loss_auth_penalty', 'loss_total', 'w_mask_cls', 'w_auth_penalty']\n",
      "\n",
      "fold2 tables:\n",
      "  - cv_fold2\\debug.jsonl | shape=(2342640, 53) | cols=['tag', 'fold', 'epoch', 'global_step', 'img_label', 'masks_shape', 'masks_sum', 'per_image', 'mask_probs', 'class_probs', 'img_probs', 'b', 'Q', 'Hm', 'Wm', 'tgt_shape', 'tgt_numel', 'tgt_sum', 'matched', 'reason', 'cost_shape', 'num_gt', 'B', 'pos', 'total', 'pos_frac', 'thr', 'temp', 'authentic_frac', 'per_image_penalty_mean', 'loss_auth_penalty', 'val_samples', 'masks_empty', 'gate_fail', 'num_keep0', 'cls_filtered_all_fg', 'rates', 'max_cls_prob', 'max_mask_prob', 'presence_mean', 'presence_min', 'presence_max', 'tau', 'loss_presence_auth', 'loss_forged_presence', 'fg_prob_per_query', 'fg_prob_mean', 'fg_prob_p95', 'fg_prob_max', 'no_fg_pre_keep', 'pred_auth_frac', 'pred_non_auth_count', 'pred_non_auth_area_ratio_mean']\n",
      "  - cv_fold2\\epoch_summary.csv | shape=(225, 11) | cols=['fold', 'epoch', 'epoch_loss', 'cls_max_mean', 'cls_max_p95', 'keep_rate@0.1', 'keep_rate@0.2', 'keep_rate@0.3', 'img_forged_mean', 'mask_max_mean', 'w_mask_cls']\n",
      "  - cv_fold2\\step_losses.csv | shape=(194175, 12) | cols=['fold', 'epoch', 'global_step', 'lr', 'loss_mask_bce', 'loss_mask_dice', 'loss_mask_cls', 'loss_img_auth', 'loss_auth_penalty', 'loss_total', 'w_mask_cls', 'w_auth_penalty']\n",
      "\n",
      "fold3 tables:\n",
      "  - cv_fold3\\debug.jsonl | shape=(2342640, 53) | cols=['tag', 'fold', 'epoch', 'global_step', 'img_label', 'masks_shape', 'masks_sum', 'per_image', 'mask_probs', 'class_probs', 'img_probs', 'b', 'Q', 'Hm', 'Wm', 'tgt_shape', 'tgt_numel', 'tgt_sum', 'cost_shape', 'matched', 'num_gt', 'B', 'pos', 'total', 'pos_frac', 'thr', 'temp', 'authentic_frac', 'per_image_penalty_mean', 'loss_auth_penalty', 'reason', 'val_samples', 'masks_empty', 'gate_fail', 'num_keep0', 'cls_filtered_all_fg', 'rates', 'max_cls_prob', 'max_mask_prob', 'presence_mean', 'presence_min', 'presence_max', 'tau', 'loss_presence_auth', 'loss_forged_presence', 'fg_prob_per_query', 'fg_prob_mean', 'fg_prob_p95', 'fg_prob_max', 'no_fg_pre_keep', 'pred_auth_frac', 'pred_non_auth_count', 'pred_non_auth_area_ratio_mean']\n",
      "  - cv_fold3\\epoch_summary.csv | shape=(225, 11) | cols=['fold', 'epoch', 'epoch_loss', 'cls_max_mean', 'cls_max_p95', 'keep_rate@0.1', 'keep_rate@0.2', 'keep_rate@0.3', 'img_forged_mean', 'mask_max_mean', 'w_mask_cls']\n",
      "  - cv_fold3\\step_losses.csv | shape=(194175, 12) | cols=['fold', 'epoch', 'global_step', 'lr', 'loss_mask_bce', 'loss_mask_dice', 'loss_mask_cls', 'loss_img_auth', 'loss_auth_penalty', 'loss_total', 'w_mask_cls', 'w_auth_penalty']\n"
     ]
    }
   ],
   "source": [
    "# TODO: Check this when cv is actually done\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# Load ClsCollapseLogger outputs for the CV folds\n",
    "# (stored directly in experiments/oof_results/{run_name})\n",
    "# -----------------------------------------------------------------------------\n",
    "\n",
    "def _read_json(p: Path):\n",
    "    with open(p, \"r\") as f:\n",
    "        return json.load(f)\n",
    "\n",
    "def _read_jsonl(p: Path):\n",
    "    rows = []\n",
    "    with open(p, \"r\") as f:\n",
    "        for line in f:\n",
    "            line = line.strip()\n",
    "            if line:\n",
    "                rows.append(json.loads(line))\n",
    "    return pd.DataFrame(rows) if rows else pd.DataFrame()\n",
    "\n",
    "def _read_table(p: Path):\n",
    "    suf = p.suffix.lower()\n",
    "    if suf == \".csv\":\n",
    "        return pd.read_csv(p)\n",
    "    if suf in (\".jsonl\", \".ndjson\"):\n",
    "        return _read_jsonl(p)\n",
    "    return None\n",
    "\n",
    "def _fold_numbers_from_loaded_run(fold_dfs, oof_metrics):\n",
    "    nums = []\n",
    "    for k in (fold_dfs or {}).keys():\n",
    "        m = re.search(r\"(\\d+)\", str(k))\n",
    "        if m:\n",
    "            nums.append(int(m.group(1)))\n",
    "    if nums:\n",
    "        return sorted(set(nums))\n",
    "    fs = (oof_metrics or {}).get(\"fold_scores\", None)\n",
    "    return list(range(1, len(fs) + 1)) if fs else []\n",
    "\n",
    "fold_nums = _fold_numbers_from_loaded_run(fold_dfs, oof_metrics)\n",
    "\n",
    "LOGGER_FILES = {\n",
    "    \"debug.jsonl\",\n",
    "    \"epoch_summary.csv\",\n",
    "    \"meta.json\",\n",
    "    \"optimizer.json\",\n",
    "    \"step_losses.csv\",\n",
    "}\n",
    "\n",
    "collapse_json = {}    # (fold, filename) -> dict\n",
    "collapse_tables = {}  # (fold, filename) -> df\n",
    "\n",
    "for fnum in fold_nums:\n",
    "    for fname in LOGGER_FILES:\n",
    "        p = OOF_RUN_DIR / fname\n",
    "        if not p.exists():\n",
    "            continue\n",
    "\n",
    "        if p.suffix.lower() == \".json\":\n",
    "            try:\n",
    "                collapse_json[(fnum, fname)] = _read_json(p)\n",
    "            except Exception:\n",
    "                pass\n",
    "        elif p.suffix.lower() in (\".csv\", \".jsonl\", \".ndjson\"):\n",
    "            try:\n",
    "                df = _read_table(p)\n",
    "                if df is not None and len(df) > 0:\n",
    "                    collapse_tables[(fnum, fname)] = df\n",
    "            except Exception:\n",
    "                pass\n",
    "\n",
    "print(f\"Loaded ClsCollapseLogger artifacts for folds: {fold_nums}\")\n",
    "print(f\"  JSON blobs : {len(collapse_json)}\")\n",
    "print(f\"  Tables     : {len(collapse_tables)}\")\n",
    "\n",
    "if collapse_tables:\n",
    "    by_fold = {}\n",
    "    for (fnum, fname), df in collapse_tables.items():\n",
    "        by_fold.setdefault(fnum, []).append((fname, df))\n",
    "\n",
    "    for fnum in sorted(by_fold):\n",
    "        print(f\"\\nfold{fnum} tables:\")\n",
    "        for fname, df in sorted(by_fold[fnum], key=lambda x: x[0]):\n",
    "            print(f\"  - {fname} | shape={df.shape} | cols={list(df.columns)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be951a4c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fold</th>\n",
       "      <th>epoch</th>\n",
       "      <th>global_step</th>\n",
       "      <th>lr</th>\n",
       "      <th>loss_mask_bce</th>\n",
       "      <th>loss_mask_dice</th>\n",
       "      <th>loss_mask_cls</th>\n",
       "      <th>loss_img_auth</th>\n",
       "      <th>loss_auth_penalty</th>\n",
       "      <th>loss_total</th>\n",
       "      <th>w_mask_cls</th>\n",
       "      <th>w_auth_penalty</th>\n",
       "      <th>_source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>586503.000000</td>\n",
       "      <td>586503.000000</td>\n",
       "      <td>586503.000000</td>\n",
       "      <td>5.865030e+05</td>\n",
       "      <td>586503.000000</td>\n",
       "      <td>586503.000000</td>\n",
       "      <td>586503.000000</td>\n",
       "      <td>586503.000000</td>\n",
       "      <td>5.865030e+05</td>\n",
       "      <td>586503.000000</td>\n",
       "      <td>586503.0</td>\n",
       "      <td>586503.0</td>\n",
       "      <td>586503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>cv_fold1\\step_losses.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>198153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.993217</td>\n",
       "      <td>10.834233</td>\n",
       "      <td>8917.791730</td>\n",
       "      <td>1.000000e-04</td>\n",
       "      <td>0.123095</td>\n",
       "      <td>0.601660</td>\n",
       "      <td>0.275854</td>\n",
       "      <td>0.456733</td>\n",
       "      <td>2.589444e-03</td>\n",
       "      <td>1.650209</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.817852</td>\n",
       "      <td>6.783445</td>\n",
       "      <td>5859.540913</td>\n",
       "      <td>6.776269e-20</td>\n",
       "      <td>0.252046</td>\n",
       "      <td>0.229449</td>\n",
       "      <td>0.114930</td>\n",
       "      <td>0.261371</td>\n",
       "      <td>1.320205e-02</td>\n",
       "      <td>0.609750</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000e-04</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.001061</td>\n",
       "      <td>0.000024</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.006600</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>3665.000000</td>\n",
       "      <td>1.000000e-04</td>\n",
       "      <td>0.040792</td>\n",
       "      <td>0.467559</td>\n",
       "      <td>0.196323</td>\n",
       "      <td>0.265205</td>\n",
       "      <td>6.670928e-15</td>\n",
       "      <td>1.260726</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>8347.000000</td>\n",
       "      <td>1.000000e-04</td>\n",
       "      <td>0.085883</td>\n",
       "      <td>0.616834</td>\n",
       "      <td>0.260665</td>\n",
       "      <td>0.433163</td>\n",
       "      <td>1.040621e-11</td>\n",
       "      <td>1.638783</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>3.000000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>13747.000000</td>\n",
       "      <td>1.000000e-04</td>\n",
       "      <td>0.156712</td>\n",
       "      <td>0.765317</td>\n",
       "      <td>0.336399</td>\n",
       "      <td>0.624978</td>\n",
       "      <td>3.959066e-05</td>\n",
       "      <td>2.011557</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>3.000000</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>21574.000000</td>\n",
       "      <td>1.000000e-04</td>\n",
       "      <td>41.467186</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.426446</td>\n",
       "      <td>3.941484</td>\n",
       "      <td>1.129112e+00</td>\n",
       "      <td>43.669540</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 fold          epoch    global_step            lr  \\\n",
       "count   586503.000000  586503.000000  586503.000000  5.865030e+05   \n",
       "unique            NaN            NaN            NaN           NaN   \n",
       "top               NaN            NaN            NaN           NaN   \n",
       "freq              NaN            NaN            NaN           NaN   \n",
       "mean         1.993217      10.834233    8917.791730  1.000000e-04   \n",
       "std          0.817852       6.783445    5859.540913  6.776269e-20   \n",
       "min          1.000000       1.000000       0.000000  1.000000e-04   \n",
       "25%          1.000000       5.000000    3665.000000  1.000000e-04   \n",
       "50%          2.000000      10.000000    8347.000000  1.000000e-04   \n",
       "75%          3.000000      16.000000   13747.000000  1.000000e-04   \n",
       "max          3.000000      25.000000   21574.000000  1.000000e-04   \n",
       "\n",
       "        loss_mask_bce  loss_mask_dice  loss_mask_cls  loss_img_auth  \\\n",
       "count   586503.000000   586503.000000  586503.000000  586503.000000   \n",
       "unique            NaN             NaN            NaN            NaN   \n",
       "top               NaN             NaN            NaN            NaN   \n",
       "freq              NaN             NaN            NaN            NaN   \n",
       "mean         0.123095        0.601660       0.275854       0.456733   \n",
       "std          0.252046        0.229449       0.114930       0.261371   \n",
       "min         -0.000000       -0.000000       0.001061       0.000024   \n",
       "25%          0.040792        0.467559       0.196323       0.265205   \n",
       "50%          0.085883        0.616834       0.260665       0.433163   \n",
       "75%          0.156712        0.765317       0.336399       0.624978   \n",
       "max         41.467186        1.000000       1.426446       3.941484   \n",
       "\n",
       "        loss_auth_penalty     loss_total  w_mask_cls  w_auth_penalty  \\\n",
       "count        5.865030e+05  586503.000000    586503.0        586503.0   \n",
       "unique                NaN            NaN         NaN             NaN   \n",
       "top                   NaN            NaN         NaN             NaN   \n",
       "freq                  NaN            NaN         NaN             NaN   \n",
       "mean         2.589444e-03       1.650209         1.0             1.0   \n",
       "std          1.320205e-02       0.609750         0.0             0.0   \n",
       "min          0.000000e+00       0.006600         1.0             1.0   \n",
       "25%          6.670928e-15       1.260726         1.0             1.0   \n",
       "50%          1.040621e-11       1.638783         1.0             1.0   \n",
       "75%          3.959066e-05       2.011557         1.0             1.0   \n",
       "max          1.129112e+00      43.669540         1.0             1.0   \n",
       "\n",
       "                         _source  \n",
       "count                     586503  \n",
       "unique                         3  \n",
       "top     cv_fold1\\step_losses.csv  \n",
       "freq                      198153  \n",
       "mean                         NaN  \n",
       "std                          NaN  \n",
       "min                          NaN  \n",
       "25%                          NaN  \n",
       "50%                          NaN  \n",
       "75%                          NaN  \n",
       "max                          NaN  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# TODO: Doublecheck this works with new organization\n",
    "# Convenience: key summaries across ALL loaded debug tables\n",
    "\n",
    "def concat_tables(name_contains: str):\n",
    "    dfs = []\n",
    "    for (fold, fname), df in collapse_tables.items():\n",
    "        if name_contains.lower() in fname.lower():\n",
    "            d = df.copy()\n",
    "            d[\"fold\"] = fold\n",
    "            d[\"_source\"] = fname\n",
    "            dfs.append(d)\n",
    "    return pd.concat(dfs, ignore_index=True) if dfs else pd.DataFrame()\n",
    "\n",
    "step_losses = concat_tables(\"step\")\n",
    "epoch_summary = concat_tables(\"epoch\")\n",
    "debug_events = concat_tables(\"debug\")\n",
    "\n",
    "if len(step_losses):\n",
    "    display(step_losses.describe(include=\"all\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e1e35d8b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fold</th>\n",
       "      <th>epoch</th>\n",
       "      <th>epoch_loss</th>\n",
       "      <th>cls_max_mean</th>\n",
       "      <th>cls_max_p95</th>\n",
       "      <th>keep_rate@0.1</th>\n",
       "      <th>keep_rate@0.2</th>\n",
       "      <th>keep_rate@0.3</th>\n",
       "      <th>img_forged_mean</th>\n",
       "      <th>mask_max_mean</th>\n",
       "      <th>w_mask_cls</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>25</td>\n",
       "      <td>1.106284</td>\n",
       "      <td>0.041141</td>\n",
       "      <td>0.041141</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.459946</td>\n",
       "      <td>0.979579</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>25</td>\n",
       "      <td>1.099362</td>\n",
       "      <td>0.018741</td>\n",
       "      <td>0.058184</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.216331</td>\n",
       "      <td>0.900513</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>25</td>\n",
       "      <td>1.081480</td>\n",
       "      <td>0.041497</td>\n",
       "      <td>0.041497</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.096023</td>\n",
       "      <td>0.633171</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fold  epoch  epoch_loss  cls_max_mean  cls_max_p95  keep_rate@0.1  \\\n",
       "0     1     25    1.106284      0.041141     0.041141            0.0   \n",
       "1     2     25    1.099362      0.018741     0.058184            0.0   \n",
       "2     3     25    1.081480      0.041497     0.041497            0.0   \n",
       "\n",
       "   keep_rate@0.2  keep_rate@0.3  img_forged_mean  mask_max_mean  w_mask_cls  \n",
       "0            0.0            0.0         0.459946       0.979579         1.0  \n",
       "1            0.0            0.0         0.216331       0.900513         1.0  \n",
       "2            0.0            0.0         0.096023       0.633171         1.0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>keep_rate@0.1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>keep_rate@0.2</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>keep_rate@0.3</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cls_max_mean</th>\n",
       "      <td>0.033793</td>\n",
       "      <td>0.013036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cls_max_p95</th>\n",
       "      <td>0.046940</td>\n",
       "      <td>0.009738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>img_forged_mean</th>\n",
       "      <td>0.257433</td>\n",
       "      <td>0.185410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mask_max_mean</th>\n",
       "      <td>0.837754</td>\n",
       "      <td>0.181531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>w_mask_cls</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>epoch_loss</th>\n",
       "      <td>1.095709</td>\n",
       "      <td>0.012799</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     mean       std\n",
       "keep_rate@0.1    0.000000  0.000000\n",
       "keep_rate@0.2    0.000000  0.000000\n",
       "keep_rate@0.3    0.000000  0.000000\n",
       "cls_max_mean     0.033793  0.013036\n",
       "cls_max_p95      0.046940  0.009738\n",
       "img_forged_mean  0.257433  0.185410\n",
       "mask_max_mean    0.837754  0.181531\n",
       "w_mask_cls       1.000000  0.000000\n",
       "epoch_loss       1.095709  0.012799"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fold</th>\n",
       "      <th>epoch</th>\n",
       "      <th>cls_dead</th>\n",
       "      <th>keep_dead</th>\n",
       "      <th>mask_dead</th>\n",
       "      <th>auth_all_auth</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>1</td>\n",
       "      <td>25</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>328</th>\n",
       "      <td>2</td>\n",
       "      <td>25</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>553</th>\n",
       "      <td>3</td>\n",
       "      <td>25</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     fold  epoch  cls_dead  keep_dead  mask_dead  auth_all_auth\n",
       "99      1     25      True       True      False          False\n",
       "328     2     25     False       True      False          False\n",
       "553     3     25      True       True      False          False"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>corr_with_epoch</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>epoch_loss</th>\n",
       "      <td>-0.726866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>img_forged_mean</th>\n",
       "      <td>-0.423759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cls_max_mean</th>\n",
       "      <td>-0.217884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>keep_rate@0.1</th>\n",
       "      <td>-0.215503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>keep_rate@0.3</th>\n",
       "      <td>-0.177058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>keep_rate@0.2</th>\n",
       "      <td>-0.153736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cls_max_p95</th>\n",
       "      <td>-0.124636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mask_max_mean</th>\n",
       "      <td>0.015972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>w_mask_cls</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 corr_with_epoch\n",
       "epoch_loss             -0.726866\n",
       "img_forged_mean        -0.423759\n",
       "cls_max_mean           -0.217884\n",
       "keep_rate@0.1          -0.215503\n",
       "keep_rate@0.3          -0.177058\n",
       "keep_rate@0.2          -0.153736\n",
       "cls_max_p95            -0.124636\n",
       "mask_max_mean           0.015972\n",
       "w_mask_cls                   NaN"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# --- Useful, compact diagnostics for epoch_summary ---\n",
    "\n",
    "es = epoch_summary.copy()\n",
    "\n",
    "num_cols = [\n",
    "    \"epoch_loss\", \"cls_max_mean\", \"cls_max_p95\",\n",
    "    \"keep_rate@0.1\", \"keep_rate@0.2\", \"keep_rate@0.3\",\n",
    "    \"img_forged_mean\", \"mask_max_mean\", \"w_mask_cls\",\n",
    "]\n",
    "for c in num_cols:\n",
    "    es[c] = pd.to_numeric(es[c], errors=\"coerce\")\n",
    "\n",
    "last_epoch = (\n",
    "    es.sort_values([\"fold\", \"epoch\"])\n",
    "      .groupby(\"fold\", as_index=False)\n",
    "      .tail(1)\n",
    "      .sort_values(\"fold\")\n",
    ")\n",
    "\n",
    "# Per-fold last-epoch snapshot\n",
    "display(\n",
    "    last_epoch[[\"fold\", \"epoch\"] + num_cols]\n",
    "      .sort_values(\"fold\")\n",
    "      .reset_index(drop=True)\n",
    ")\n",
    "\n",
    "# Cross-fold mean/std at last epoch\n",
    "agg = last_epoch[num_cols].agg([\"mean\", \"std\"]).T\n",
    "agg.columns = [\"mean\", \"std\"]\n",
    "display(agg.sort_values(\"mean\"))\n",
    "\n",
    "# Quick red-flag table at last epoch\n",
    "flags = last_epoch.assign(\n",
    "    cls_dead = last_epoch[\"cls_max_p95\"] < 0.05,\n",
    "    keep_dead = last_epoch[\"keep_rate@0.2\"] < 0.01,\n",
    "    mask_dead = last_epoch[\"mask_max_mean\"] < 0.05,\n",
    "    auth_all_auth = last_epoch[\"img_forged_mean\"] < 0.05,\n",
    ").loc[:, [\"fold\", \"epoch\", \"cls_dead\", \"keep_dead\", \"mask_dead\", \"auth_all_auth\"]]\n",
    "display(flags)\n",
    "\n",
    "# Trend vs epoch (pooled across folds): corr with epoch\n",
    "trend_cols = [\"epoch\"] + num_cols\n",
    "trend_corr = es[trend_cols].corr(numeric_only=True)[\"epoch\"].drop(\"epoch\").sort_values()\n",
    "display(trend_corr.to_frame(\"corr_with_epoch\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bf6aa621",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "debug_events shape: (6755014, 54)\n",
      "cols: ['tag', 'fold', 'epoch', 'global_step', 'img_label', 'masks_shape', 'masks_sum', 'b', 'Q', 'Hm', 'Wm', 'tgt_shape', 'tgt_numel', 'tgt_sum', 'cost_shape', 'matched', 'num_gt', 'B', 'pos', 'total', 'pos_frac', 'thr', 'temp', 'authentic_frac', 'per_image_penalty_mean', 'loss_auth_penalty', 'reason', 'per_image', 'mask_probs', 'class_probs', 'img_probs', 'val_samples', 'masks_empty', 'gate_fail', 'num_keep0', 'cls_filtered_all_fg', 'rates', 'max_cls_prob', 'max_mask_prob', 'presence_mean', 'presence_min', 'presence_max', 'tau', 'loss_presence_auth', 'loss_forged_presence', 'fg_prob_per_query', 'fg_prob_mean', 'fg_prob_p95', 'fg_prob_max', 'no_fg_pre_keep', 'pred_auth_frac', 'pred_non_auth_count', 'pred_non_auth_area_ratio_mean', '_source']\n",
      "\n",
      "=== OOF inference debug summary (per fold: counts, rates, max probs) ===\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fold</th>\n",
       "      <th>val_samples</th>\n",
       "      <th>masks_empty</th>\n",
       "      <th>gate_fail</th>\n",
       "      <th>num_keep0</th>\n",
       "      <th>cls_filtered_all_fg</th>\n",
       "      <th>no_fg_pre_keep</th>\n",
       "      <th>rates.masks_empty</th>\n",
       "      <th>rates.gate_fail</th>\n",
       "      <th>rates.num_keep0</th>\n",
       "      <th>rates.cls_filtered_all_fg</th>\n",
       "      <th>rates.no_fg_pre_keep</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>388578</th>\n",
       "      <td>1</td>\n",
       "      <td>1726.0</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.504056</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.477404</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>625806</th>\n",
       "      <td>1</td>\n",
       "      <td>1726.0</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.461182</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.973349</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>729329</th>\n",
       "      <td>1</td>\n",
       "      <td>1726.0</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.600232</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.904983</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>953632</th>\n",
       "      <td>1</td>\n",
       "      <td>1726.0</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.396871</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.855736</td>\n",
       "      <td>0.144264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1009711</th>\n",
       "      <td>1</td>\n",
       "      <td>1726.0</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0.437428</td>\n",
       "      <td>0.437428</td>\n",
       "      <td>0.196408</td>\n",
       "      <td>0.437428</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1234015</th>\n",
       "      <td>1</td>\n",
       "      <td>1726.0</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0.355156</td>\n",
       "      <td>0.355156</td>\n",
       "      <td>0.012746</td>\n",
       "      <td>0.355156</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1290094</th>\n",
       "      <td>1</td>\n",
       "      <td>1726.0</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.408459</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.833140</td>\n",
       "      <td>0.166860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1346173</th>\n",
       "      <td>1</td>\n",
       "      <td>1726.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1570477</th>\n",
       "      <td>1</td>\n",
       "      <td>1726.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1794781</th>\n",
       "      <td>1</td>\n",
       "      <td>1726.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019085</th>\n",
       "      <td>1</td>\n",
       "      <td>1726.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2781565</th>\n",
       "      <td>2</td>\n",
       "      <td>1725.0</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.379130</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3018843</th>\n",
       "      <td>2</td>\n",
       "      <td>1725.0</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.436522</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.899710</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3122386</th>\n",
       "      <td>2</td>\n",
       "      <td>1725.0</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>0.442319</td>\n",
       "      <td>0.442319</td>\n",
       "      <td>0.313623</td>\n",
       "      <td>0.442319</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3346729</th>\n",
       "      <td>2</td>\n",
       "      <td>1725.0</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0.543768</td>\n",
       "      <td>0.543768</td>\n",
       "      <td>0.416812</td>\n",
       "      <td>0.543768</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3402818</th>\n",
       "      <td>2</td>\n",
       "      <td>1725.0</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.206957</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.998841</td>\n",
       "      <td>0.001159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3627162</th>\n",
       "      <td>2</td>\n",
       "      <td>1725.0</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0.461449</td>\n",
       "      <td>0.461449</td>\n",
       "      <td>0.316522</td>\n",
       "      <td>0.461449</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3683251</th>\n",
       "      <td>2</td>\n",
       "      <td>1725.0</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0.415072</td>\n",
       "      <td>0.415072</td>\n",
       "      <td>0.079420</td>\n",
       "      <td>0.415072</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3739340</th>\n",
       "      <td>2</td>\n",
       "      <td>1725.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3963684</th>\n",
       "      <td>2</td>\n",
       "      <td>1725.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4188028</th>\n",
       "      <td>2</td>\n",
       "      <td>1725.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4412372</th>\n",
       "      <td>2</td>\n",
       "      <td>1725.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5124205</th>\n",
       "      <td>3</td>\n",
       "      <td>1725.0</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.409275</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.949565</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5361483</th>\n",
       "      <td>3</td>\n",
       "      <td>1725.0</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.426087</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.722319</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5465026</th>\n",
       "      <td>3</td>\n",
       "      <td>1725.0</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>0.913623</td>\n",
       "      <td>0.740290</td>\n",
       "      <td>0.913623</td>\n",
       "      <td>0.786087</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5689369</th>\n",
       "      <td>3</td>\n",
       "      <td>1725.0</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0.386087</td>\n",
       "      <td>0.386087</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.386087</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5745458</th>\n",
       "      <td>3</td>\n",
       "      <td>1725.0</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>0.780290</td>\n",
       "      <td>0.282899</td>\n",
       "      <td>0.779710</td>\n",
       "      <td>0.779710</td>\n",
       "      <td>0.000580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5969802</th>\n",
       "      <td>3</td>\n",
       "      <td>1725.0</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.410435</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.804638</td>\n",
       "      <td>0.195362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6025891</th>\n",
       "      <td>3</td>\n",
       "      <td>1725.0</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>0.738551</td>\n",
       "      <td>0.281739</td>\n",
       "      <td>0.738551</td>\n",
       "      <td>0.729275</td>\n",
       "      <td>0.009275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6081980</th>\n",
       "      <td>3</td>\n",
       "      <td>1725.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6306324</th>\n",
       "      <td>3</td>\n",
       "      <td>1725.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6530668</th>\n",
       "      <td>3</td>\n",
       "      <td>1725.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6755012</th>\n",
       "      <td>3</td>\n",
       "      <td>1725.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         fold  val_samples  masks_empty  gate_fail  num_keep0  \\\n",
       "388578      1       1726.0         True       True       True   \n",
       "625806      1       1726.0         True       True       True   \n",
       "729329      1       1726.0         True       True       True   \n",
       "953632      1       1726.0         True       True       True   \n",
       "1009711     1       1726.0         True       True       True   \n",
       "1234015     1       1726.0         True       True       True   \n",
       "1290094     1       1726.0         True       True       True   \n",
       "1346173     1       1726.0        False      False      False   \n",
       "1570477     1       1726.0        False      False      False   \n",
       "1794781     1       1726.0        False      False      False   \n",
       "2019085     1       1726.0        False      False      False   \n",
       "2781565     2       1725.0         True       True       True   \n",
       "3018843     2       1725.0         True       True       True   \n",
       "3122386     2       1725.0         True       True       True   \n",
       "3346729     2       1725.0         True       True       True   \n",
       "3402818     2       1725.0         True       True       True   \n",
       "3627162     2       1725.0         True       True       True   \n",
       "3683251     2       1725.0         True       True       True   \n",
       "3739340     2       1725.0        False      False      False   \n",
       "3963684     2       1725.0        False      False      False   \n",
       "4188028     2       1725.0        False      False      False   \n",
       "4412372     2       1725.0        False      False      False   \n",
       "5124205     3       1725.0         True       True       True   \n",
       "5361483     3       1725.0         True       True       True   \n",
       "5465026     3       1725.0         True       True       True   \n",
       "5689369     3       1725.0         True       True      False   \n",
       "5745458     3       1725.0         True       True       True   \n",
       "5969802     3       1725.0         True       True       True   \n",
       "6025891     3       1725.0         True       True       True   \n",
       "6081980     3       1725.0        False      False      False   \n",
       "6306324     3       1725.0        False      False      False   \n",
       "6530668     3       1725.0        False      False      False   \n",
       "6755012     3       1725.0        False      False      False   \n",
       "\n",
       "         cls_filtered_all_fg  no_fg_pre_keep  rates.masks_empty  \\\n",
       "388578                  True            True           1.000000   \n",
       "625806                  True            True           1.000000   \n",
       "729329                  True            True           1.000000   \n",
       "953632                  True            True           1.000000   \n",
       "1009711                 True           False           0.437428   \n",
       "1234015                 True           False           0.355156   \n",
       "1290094                 True            True           1.000000   \n",
       "1346173                False           False           0.000000   \n",
       "1570477                False           False           0.000000   \n",
       "1794781                False           False           0.000000   \n",
       "2019085                False           False           0.000000   \n",
       "2781565                 True            True           1.000000   \n",
       "3018843                 True            True           1.000000   \n",
       "3122386                 True            True           0.442319   \n",
       "3346729                 True           False           0.543768   \n",
       "3402818                 True            True           1.000000   \n",
       "3627162                 True           False           0.461449   \n",
       "3683251                 True           False           0.415072   \n",
       "3739340                False           False           0.000000   \n",
       "3963684                False           False           0.000000   \n",
       "4188028                False           False           0.000000   \n",
       "4412372                False           False           0.000000   \n",
       "5124205                 True            True           1.000000   \n",
       "5361483                 True            True           1.000000   \n",
       "5465026                 True            True           0.913623   \n",
       "5689369                 True           False           0.386087   \n",
       "5745458                 True            True           0.780290   \n",
       "5969802                 True            True           1.000000   \n",
       "6025891                 True            True           0.738551   \n",
       "6081980                False           False           0.000000   \n",
       "6306324                False           False           0.000000   \n",
       "6530668                False           False           0.000000   \n",
       "6755012                False           False           0.000000   \n",
       "\n",
       "         rates.gate_fail  rates.num_keep0  rates.cls_filtered_all_fg  \\\n",
       "388578          0.504056         1.000000                   0.477404   \n",
       "625806          0.461182         1.000000                   0.973349   \n",
       "729329          0.600232         1.000000                   0.904983   \n",
       "953632          0.396871         1.000000                   0.855736   \n",
       "1009711         0.437428         0.196408                   0.437428   \n",
       "1234015         0.355156         0.012746                   0.355156   \n",
       "1290094         0.408459         1.000000                   0.833140   \n",
       "1346173         0.000000         0.000000                   0.000000   \n",
       "1570477         0.000000         0.000000                   0.000000   \n",
       "1794781         0.000000         0.000000                   0.000000   \n",
       "2019085         0.000000         0.000000                   0.000000   \n",
       "2781565         0.379130         1.000000                   1.000000   \n",
       "3018843         0.436522         1.000000                   0.899710   \n",
       "3122386         0.442319         0.313623                   0.442319   \n",
       "3346729         0.543768         0.416812                   0.543768   \n",
       "3402818         0.206957         1.000000                   0.998841   \n",
       "3627162         0.461449         0.316522                   0.461449   \n",
       "3683251         0.415072         0.079420                   0.415072   \n",
       "3739340         0.000000         0.000000                   0.000000   \n",
       "3963684         0.000000         0.000000                   0.000000   \n",
       "4188028         0.000000         0.000000                   0.000000   \n",
       "4412372         0.000000         0.000000                   0.000000   \n",
       "5124205         0.409275         1.000000                   0.949565   \n",
       "5361483         0.426087         1.000000                   0.722319   \n",
       "5465026         0.740290         0.913623                   0.786087   \n",
       "5689369         0.386087         0.000000                   0.386087   \n",
       "5745458         0.282899         0.779710                   0.779710   \n",
       "5969802         0.410435         1.000000                   0.804638   \n",
       "6025891         0.281739         0.738551                   0.729275   \n",
       "6081980         0.000000         0.000000                   0.000000   \n",
       "6306324         0.000000         0.000000                   0.000000   \n",
       "6530668         0.000000         0.000000                   0.000000   \n",
       "6755012         0.000000         0.000000                   0.000000   \n",
       "\n",
       "         rates.no_fg_pre_keep  \n",
       "388578                    NaN  \n",
       "625806                    NaN  \n",
       "729329                    NaN  \n",
       "953632               0.144264  \n",
       "1009711              0.000000  \n",
       "1234015              0.000000  \n",
       "1290094              0.166860  \n",
       "1346173              0.000000  \n",
       "1570477              0.000000  \n",
       "1794781              0.000000  \n",
       "2019085              0.000000  \n",
       "2781565                   NaN  \n",
       "3018843                   NaN  \n",
       "3122386                   NaN  \n",
       "3346729              0.000000  \n",
       "3402818              0.001159  \n",
       "3627162              0.000000  \n",
       "3683251              0.000000  \n",
       "3739340              0.000000  \n",
       "3963684              0.000000  \n",
       "4188028              0.000000  \n",
       "4412372              0.000000  \n",
       "5124205                   NaN  \n",
       "5361483                   NaN  \n",
       "5465026                   NaN  \n",
       "5689369              0.000000  \n",
       "5745458              0.000580  \n",
       "5969802              0.195362  \n",
       "6025891              0.009275  \n",
       "6081980              0.000000  \n",
       "6306324              0.000000  \n",
       "6530668              0.000000  \n",
       "6755012              0.000000  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== OOF inference debug summary (global weighted failure rates) ===\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>weighted_rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>masks_empty</th>\n",
       "      <td>0.000369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gate_fail</th>\n",
       "      <td>0.000369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>num_keep0</th>\n",
       "      <td>0.000351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cls_filtered_all_fg</th>\n",
       "      <td>0.000369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>no_fg_pre_keep</th>\n",
       "      <td>0.000263</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     weighted_rate\n",
       "masks_empty               0.000369\n",
       "gate_fail                 0.000369\n",
       "num_keep0                 0.000351\n",
       "cls_filtered_all_fg       0.000369\n",
       "no_fg_pre_keep            0.000263"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Presence coupling stats (loss_presence_stats: last epoch per fold + mean/std) ===\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fold</th>\n",
       "      <th>epoch</th>\n",
       "      <th>presence_mean</th>\n",
       "      <th>presence_min</th>\n",
       "      <th>presence_max</th>\n",
       "      <th>tau</th>\n",
       "      <th>loss_presence_auth</th>\n",
       "      <th>loss_forged_presence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2019083</th>\n",
       "      <td>1</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.543439</td>\n",
       "      <td>0.529845</td>\n",
       "      <td>0.557033</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.610151</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4412370</th>\n",
       "      <td>2</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.492129</td>\n",
       "      <td>0.298060</td>\n",
       "      <td>0.869016</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.573639</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6755010</th>\n",
       "      <td>3</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.369772</td>\n",
       "      <td>0.144140</td>\n",
       "      <td>0.510562</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.538733</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         fold  epoch  presence_mean  presence_min  presence_max  tau  \\\n",
       "2019083     1   20.0       0.543439      0.529845      0.557033  0.1   \n",
       "4412370     2   20.0       0.492129      0.298060      0.869016  0.1   \n",
       "6755010     3   20.0       0.369772      0.144140      0.510562  0.1   \n",
       "\n",
       "         loss_presence_auth  loss_forged_presence  \n",
       "2019083            0.610151                   0.0  \n",
       "4412370            0.573639                   0.0  \n",
       "6755010            0.538733                   0.0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>presence_mean</th>\n",
       "      <td>0.468446</td>\n",
       "      <td>8.922279e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>presence_min</th>\n",
       "      <td>0.324015</td>\n",
       "      <td>1.941582e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>presence_max</th>\n",
       "      <td>0.645537</td>\n",
       "      <td>1.949284e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tau</th>\n",
       "      <td>0.100000</td>\n",
       "      <td>1.699675e-17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>loss_presence_auth</th>\n",
       "      <td>0.574174</td>\n",
       "      <td>3.571179e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>loss_forged_presence</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          mean           std\n",
       "presence_mean         0.468446  8.922279e-02\n",
       "presence_min          0.324015  1.941582e-01\n",
       "presence_max          0.645537  1.949284e-01\n",
       "tau                   0.100000  1.699675e-17\n",
       "loss_presence_auth    0.574174  3.571179e-02\n",
       "loss_forged_presence  0.000000  0.000000e+00"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Authenticity penalty stats (loss_auth_penalty_stats: last epoch per fold + mean/std) ===\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fold</th>\n",
       "      <th>epoch</th>\n",
       "      <th>thr</th>\n",
       "      <th>temp</th>\n",
       "      <th>authentic_frac</th>\n",
       "      <th>per_image_penalty_mean</th>\n",
       "      <th>loss_auth_penalty</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>625805</th>\n",
       "      <td>1</td>\n",
       "      <td>25.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.198248e-17</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3018842</th>\n",
       "      <td>2</td>\n",
       "      <td>25.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>1.384936e-15</td>\n",
       "      <td>8.648611e-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5361482</th>\n",
       "      <td>3</td>\n",
       "      <td>25.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>9.730406e-17</td>\n",
       "      <td>1.960069e-17</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         fold  epoch  thr  temp  authentic_frac  per_image_penalty_mean  \\\n",
       "625805      1   25.0  0.5   0.1        0.000000            8.198248e-17   \n",
       "3018842     2   25.0  0.5   0.1        0.333333            1.384936e-15   \n",
       "5361482     3   25.0  0.5   0.1        0.333333            9.730406e-17   \n",
       "\n",
       "         loss_auth_penalty  \n",
       "625805        0.000000e+00  \n",
       "3018842       8.648611e-16  \n",
       "5361482       1.960069e-17  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>thr</th>\n",
       "      <td>5.000000e-01</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>temp</th>\n",
       "      <td>1.000000e-01</td>\n",
       "      <td>1.699675e-17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>authentic_frac</th>\n",
       "      <td>2.222222e-01</td>\n",
       "      <td>1.924501e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>per_image_penalty_mean</th>\n",
       "      <td>5.214076e-16</td>\n",
       "      <td>7.478769e-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>loss_auth_penalty</th>\n",
       "      <td>2.948206e-16</td>\n",
       "      <td>4.937668e-16</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                mean           std\n",
       "thr                     5.000000e-01  0.000000e+00\n",
       "temp                    1.000000e-01  1.699675e-17\n",
       "authentic_frac          2.222222e-01  1.924501e-01\n",
       "per_image_penalty_mean  5.214076e-16  7.478769e-16\n",
       "loss_auth_penalty       2.948206e-16  4.937668e-16"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Class-target balance (loss_cls_targets: pos_frac across folds) ===\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"4\" halign=\"left\">pos_frac</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fold</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.061744</td>\n",
       "      <td>0.044448</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.483333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.069300</td>\n",
       "      <td>0.050680</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.516667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.068873</td>\n",
       "      <td>0.050726</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      pos_frac                         \n",
       "          mean       std  min       max\n",
       "fold                                   \n",
       "1     0.061744  0.044448  0.0  0.483333\n",
       "2     0.069300  0.050680  0.0  0.516667\n",
       "3     0.068873  0.050726  0.0  0.500000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Hungarian matching input health (tgt masks: numel / sum / shape) ===\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fold</th>\n",
       "      <th>epoch</th>\n",
       "      <th>tgt_numel</th>\n",
       "      <th>tgt_sum</th>\n",
       "      <th>tgt_shape</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2.227308e+06</td>\n",
       "      <td>2.227308e+06</td>\n",
       "      <td>2.227308e+06</td>\n",
       "      <td>2.227308e+06</td>\n",
       "      <td>2227308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[0, 256, 256]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1026422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2.045848e+00</td>\n",
       "      <td>1.083262e+01</td>\n",
       "      <td>6.575627e+04</td>\n",
       "      <td>1.985458e+03</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>8.057806e-01</td>\n",
       "      <td>6.758765e+00</td>\n",
       "      <td>8.617348e+04</td>\n",
       "      <td>3.840537e+03</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>5.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>2.000000e+00</td>\n",
       "      <td>1.000000e+01</td>\n",
       "      <td>6.553600e+04</td>\n",
       "      <td>2.060000e+02</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>3.000000e+00</td>\n",
       "      <td>1.600000e+01</td>\n",
       "      <td>1.310720e+05</td>\n",
       "      <td>2.262000e+03</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>3.000000e+00</td>\n",
       "      <td>2.500000e+01</td>\n",
       "      <td>1.245184e+06</td>\n",
       "      <td>3.444500e+04</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                fold         epoch     tgt_numel       tgt_sum      tgt_shape\n",
       "count   2.227308e+06  2.227308e+06  2.227308e+06  2.227308e+06        2227308\n",
       "unique           NaN           NaN           NaN           NaN             16\n",
       "top              NaN           NaN           NaN           NaN  [0, 256, 256]\n",
       "freq             NaN           NaN           NaN           NaN        1026422\n",
       "mean    2.045848e+00  1.083262e+01  6.575627e+04  1.985458e+03            NaN\n",
       "std     8.057806e-01  6.758765e+00  8.617348e+04  3.840537e+03            NaN\n",
       "min     1.000000e+00  1.000000e+00  0.000000e+00  0.000000e+00            NaN\n",
       "25%     1.000000e+00  5.000000e+00  0.000000e+00  0.000000e+00            NaN\n",
       "50%     2.000000e+00  1.000000e+01  6.553600e+04  2.060000e+02            NaN\n",
       "75%     3.000000e+00  1.600000e+01  1.310720e+05  2.262000e+03            NaN\n",
       "max     3.000000e+00  2.500000e+01  1.245184e+06  3.444500e+04            NaN"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Hungarian matching results (matched vs num_gt, empty_gt reasons) ===\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fold</th>\n",
       "      <th>reason</th>\n",
       "      <th>rows</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>empty_gt</td>\n",
       "      <td>310647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>363711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>empty_gt</td>\n",
       "      <td>358125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>418350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>empty_gt</td>\n",
       "      <td>357650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>418825</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fold    reason    rows\n",
       "0     1  empty_gt  310647\n",
       "1     1       NaN  363711\n",
       "2     2  empty_gt  358125\n",
       "3     2       NaN  418350\n",
       "4     3  empty_gt  357650\n",
       "5     3       NaN  418825"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fold</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.926205</td>\n",
       "      <td>1.198934</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.039505</td>\n",
       "      <td>1.356656</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.033066</td>\n",
       "      <td>1.351646</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          mean       std  min   max\n",
       "fold                               \n",
       "1     0.926205  1.198934  0.0  15.0\n",
       "2     1.039505  1.356656  0.0  15.0\n",
       "3     1.033066  1.351646  0.0  15.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Mask-head liveness during training (train_fg_prob_per_query: last epoch) ===\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fold</th>\n",
       "      <th>epoch</th>\n",
       "      <th>Q</th>\n",
       "      <th>fg_prob_mean</th>\n",
       "      <th>fg_prob_p95</th>\n",
       "      <th>fg_prob_max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2019082</th>\n",
       "      <td>1</td>\n",
       "      <td>20.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0.285229</td>\n",
       "      <td>0.669149</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4412369</th>\n",
       "      <td>2</td>\n",
       "      <td>20.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0.085080</td>\n",
       "      <td>0.328765</td>\n",
       "      <td>0.991170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6755009</th>\n",
       "      <td>3</td>\n",
       "      <td>20.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0.490071</td>\n",
       "      <td>0.764940</td>\n",
       "      <td>0.808365</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         fold  epoch     Q  fg_prob_mean  fg_prob_p95  fg_prob_max\n",
       "2019082     1   20.0  15.0      0.285229     0.669149     1.000000\n",
       "4412369     2   20.0  15.0      0.085080     0.328765     0.991170\n",
       "6755009     3   20.0  15.0      0.490071     0.764940     0.808365"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Mask-head per-query foreground distribution (last epoch, exploded) ===\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fold</th>\n",
       "      <th>mean</th>\n",
       "      <th>p95</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.285229</td>\n",
       "      <td>0.669148</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.085080</td>\n",
       "      <td>0.328765</td>\n",
       "      <td>0.991170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.490071</td>\n",
       "      <td>0.764940</td>\n",
       "      <td>0.808365</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fold      mean       p95       max\n",
       "0     1  0.285229  0.669148  1.000000\n",
       "1     2  0.085080  0.328765  0.991170\n",
       "2     3  0.490071  0.764940  0.808365"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== One-time logits/probability sanity snapshots (debug_probs) ===\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fold</th>\n",
       "      <th>epoch</th>\n",
       "      <th>global_step</th>\n",
       "      <th>mask_probs.mean</th>\n",
       "      <th>mask_probs.p95</th>\n",
       "      <th>mask_probs.max</th>\n",
       "      <th>mask_probs.frac_gt_0p5</th>\n",
       "      <th>class_probs.mean</th>\n",
       "      <th>class_probs.max</th>\n",
       "      <th>class_probs.frac_gt_0p1</th>\n",
       "      <th>img_probs.mean</th>\n",
       "      <th>img_probs.max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>151353</th>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.326855</td>\n",
       "      <td>0.951958</td>\n",
       "      <td>0.999967</td>\n",
       "      <td>0.294145</td>\n",
       "      <td>0.343201</td>\n",
       "      <td>0.398486</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.512244</td>\n",
       "      <td>0.515834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>388581</th>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.336805</td>\n",
       "      <td>0.954254</td>\n",
       "      <td>0.999995</td>\n",
       "      <td>0.308744</td>\n",
       "      <td>0.348552</td>\n",
       "      <td>0.409816</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.513045</td>\n",
       "      <td>0.519819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>625809</th>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.282438</td>\n",
       "      <td>0.929600</td>\n",
       "      <td>0.999995</td>\n",
       "      <td>0.255082</td>\n",
       "      <td>0.344200</td>\n",
       "      <td>0.409816</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.512113</td>\n",
       "      <td>0.517592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>729332</th>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.308088</td>\n",
       "      <td>0.950631</td>\n",
       "      <td>0.999999</td>\n",
       "      <td>0.283683</td>\n",
       "      <td>0.346655</td>\n",
       "      <td>0.398486</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.512678</td>\n",
       "      <td>0.520946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>953636</th>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.312324</td>\n",
       "      <td>0.949372</td>\n",
       "      <td>0.999966</td>\n",
       "      <td>0.287016</td>\n",
       "      <td>0.339520</td>\n",
       "      <td>0.398486</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.511916</td>\n",
       "      <td>0.517365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1009715</th>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.302411</td>\n",
       "      <td>0.946386</td>\n",
       "      <td>0.999967</td>\n",
       "      <td>0.279248</td>\n",
       "      <td>0.341467</td>\n",
       "      <td>0.398486</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.511783</td>\n",
       "      <td>0.517365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1234019</th>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.298773</td>\n",
       "      <td>0.945339</td>\n",
       "      <td>0.999967</td>\n",
       "      <td>0.278674</td>\n",
       "      <td>0.346324</td>\n",
       "      <td>0.398486</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.513472</td>\n",
       "      <td>0.519819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1290098</th>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.317652</td>\n",
       "      <td>0.945745</td>\n",
       "      <td>0.999995</td>\n",
       "      <td>0.293453</td>\n",
       "      <td>0.345959</td>\n",
       "      <td>0.409816</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.512287</td>\n",
       "      <td>0.516379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1346177</th>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.312966</td>\n",
       "      <td>0.949280</td>\n",
       "      <td>0.999969</td>\n",
       "      <td>0.281079</td>\n",
       "      <td>0.339533</td>\n",
       "      <td>0.390349</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.512513</td>\n",
       "      <td>0.516373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1570481</th>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.296503</td>\n",
       "      <td>0.933591</td>\n",
       "      <td>0.999969</td>\n",
       "      <td>0.265515</td>\n",
       "      <td>0.339276</td>\n",
       "      <td>0.390349</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.512633</td>\n",
       "      <td>0.517365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1794785</th>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.313602</td>\n",
       "      <td>0.944555</td>\n",
       "      <td>0.999995</td>\n",
       "      <td>0.293376</td>\n",
       "      <td>0.344189</td>\n",
       "      <td>0.409816</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.511853</td>\n",
       "      <td>0.515834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019089</th>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.299311</td>\n",
       "      <td>0.937479</td>\n",
       "      <td>0.999995</td>\n",
       "      <td>0.260620</td>\n",
       "      <td>0.345669</td>\n",
       "      <td>0.390349</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.512517</td>\n",
       "      <td>0.517973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2069736</th>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.680387</td>\n",
       "      <td>0.998619</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.715739</td>\n",
       "      <td>0.365509</td>\n",
       "      <td>0.435480</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.497880</td>\n",
       "      <td>0.511066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2307013</th>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.688203</td>\n",
       "      <td>0.999112</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.721704</td>\n",
       "      <td>0.366493</td>\n",
       "      <td>0.437016</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.496629</td>\n",
       "      <td>0.505066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2544290</th>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.749124</td>\n",
       "      <td>0.999781</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.785486</td>\n",
       "      <td>0.365972</td>\n",
       "      <td>0.431055</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.492477</td>\n",
       "      <td>0.498755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2781568</th>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.758492</td>\n",
       "      <td>0.999828</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.790906</td>\n",
       "      <td>0.368057</td>\n",
       "      <td>0.434608</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.491302</td>\n",
       "      <td>0.495456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3018846</th>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.553269</td>\n",
       "      <td>0.976719</td>\n",
       "      <td>0.999995</td>\n",
       "      <td>0.575387</td>\n",
       "      <td>0.598913</td>\n",
       "      <td>0.682038</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.523003</td>\n",
       "      <td>0.526959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3122389</th>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.058101</td>\n",
       "      <td>0.349999</td>\n",
       "      <td>0.990789</td>\n",
       "      <td>0.029232</td>\n",
       "      <td>0.616394</td>\n",
       "      <td>0.702232</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.497535</td>\n",
       "      <td>0.504413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3346733</th>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.884733</td>\n",
       "      <td>0.999837</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.924585</td>\n",
       "      <td>0.436227</td>\n",
       "      <td>0.515985</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.514641</td>\n",
       "      <td>0.517240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3402822</th>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.053815</td>\n",
       "      <td>0.321875</td>\n",
       "      <td>0.984451</td>\n",
       "      <td>0.026274</td>\n",
       "      <td>0.617752</td>\n",
       "      <td>0.705796</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.496012</td>\n",
       "      <td>0.504413</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         fold  epoch  global_step  mask_probs.mean  mask_probs.p95  \\\n",
       "151353      1    1.0          0.0         0.326855        0.951958   \n",
       "388581      1    1.0          0.0         0.336805        0.954254   \n",
       "625809      1    1.0          0.0         0.282438        0.929600   \n",
       "729332      1    1.0          0.0         0.308088        0.950631   \n",
       "953636      1    1.0          0.0         0.312324        0.949372   \n",
       "1009715     1    1.0          0.0         0.302411        0.946386   \n",
       "1234019     1    1.0          0.0         0.298773        0.945339   \n",
       "1290098     1    1.0          0.0         0.317652        0.945745   \n",
       "1346177     1    1.0          0.0         0.312966        0.949280   \n",
       "1570481     1    1.0          0.0         0.296503        0.933591   \n",
       "1794785     1    1.0          0.0         0.313602        0.944555   \n",
       "2019089     1    1.0          0.0         0.299311        0.937479   \n",
       "2069736     2    1.0          0.0         0.680387        0.998619   \n",
       "2307013     2    1.0          0.0         0.688203        0.999112   \n",
       "2544290     2    1.0          0.0         0.749124        0.999781   \n",
       "2781568     2    1.0          0.0         0.758492        0.999828   \n",
       "3018846     2    1.0          0.0         0.553269        0.976719   \n",
       "3122389     2    1.0          0.0         0.058101        0.349999   \n",
       "3346733     2    1.0          0.0         0.884733        0.999837   \n",
       "3402822     2    1.0          0.0         0.053815        0.321875   \n",
       "\n",
       "         mask_probs.max  mask_probs.frac_gt_0p5  class_probs.mean  \\\n",
       "151353         0.999967                0.294145          0.343201   \n",
       "388581         0.999995                0.308744          0.348552   \n",
       "625809         0.999995                0.255082          0.344200   \n",
       "729332         0.999999                0.283683          0.346655   \n",
       "953636         0.999966                0.287016          0.339520   \n",
       "1009715        0.999967                0.279248          0.341467   \n",
       "1234019        0.999967                0.278674          0.346324   \n",
       "1290098        0.999995                0.293453          0.345959   \n",
       "1346177        0.999969                0.281079          0.339533   \n",
       "1570481        0.999969                0.265515          0.339276   \n",
       "1794785        0.999995                0.293376          0.344189   \n",
       "2019089        0.999995                0.260620          0.345669   \n",
       "2069736        1.000000                0.715739          0.365509   \n",
       "2307013        1.000000                0.721704          0.366493   \n",
       "2544290        1.000000                0.785486          0.365972   \n",
       "2781568        1.000000                0.790906          0.368057   \n",
       "3018846        0.999995                0.575387          0.598913   \n",
       "3122389        0.990789                0.029232          0.616394   \n",
       "3346733        1.000000                0.924585          0.436227   \n",
       "3402822        0.984451                0.026274          0.617752   \n",
       "\n",
       "         class_probs.max  class_probs.frac_gt_0p1  img_probs.mean  \\\n",
       "151353          0.398486                      1.0        0.512244   \n",
       "388581          0.409816                      1.0        0.513045   \n",
       "625809          0.409816                      1.0        0.512113   \n",
       "729332          0.398486                      1.0        0.512678   \n",
       "953636          0.398486                      1.0        0.511916   \n",
       "1009715         0.398486                      1.0        0.511783   \n",
       "1234019         0.398486                      1.0        0.513472   \n",
       "1290098         0.409816                      1.0        0.512287   \n",
       "1346177         0.390349                      1.0        0.512513   \n",
       "1570481         0.390349                      1.0        0.512633   \n",
       "1794785         0.409816                      1.0        0.511853   \n",
       "2019089         0.390349                      1.0        0.512517   \n",
       "2069736         0.435480                      1.0        0.497880   \n",
       "2307013         0.437016                      1.0        0.496629   \n",
       "2544290         0.431055                      1.0        0.492477   \n",
       "2781568         0.434608                      1.0        0.491302   \n",
       "3018846         0.682038                      1.0        0.523003   \n",
       "3122389         0.702232                      1.0        0.497535   \n",
       "3346733         0.515985                      1.0        0.514641   \n",
       "3402822         0.705796                      1.0        0.496012   \n",
       "\n",
       "         img_probs.max  \n",
       "151353        0.515834  \n",
       "388581        0.519819  \n",
       "625809        0.517592  \n",
       "729332        0.520946  \n",
       "953636        0.517365  \n",
       "1009715       0.517365  \n",
       "1234019       0.519819  \n",
       "1290098       0.516379  \n",
       "1346177       0.516373  \n",
       "1570481       0.517365  \n",
       "1794785       0.515834  \n",
       "2019089       0.517973  \n",
       "2069736       0.511066  \n",
       "2307013       0.505066  \n",
       "2544290       0.498755  \n",
       "2781568       0.495456  \n",
       "3018846       0.526959  \n",
       "3122389       0.504413  \n",
       "3346733       0.517240  \n",
       "3402822       0.504413  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# --- Load ALL debug events ---\n",
    "dbg = debug_events.copy() if \"debug_events\" in globals() else pd.DataFrame()\n",
    "print(\"debug_events shape:\", dbg.shape)\n",
    "print(\"cols:\", list(dbg.columns))\n",
    "\n",
    "if len(dbg) == 0:\n",
    "    raise ValueError(\"debug_events is empty\")\n",
    "\n",
    "# ---------- helpers ----------\n",
    "def _to_bool(s):\n",
    "    if s.dtype == object:\n",
    "        return s.astype(str).str.lower().isin([\"true\", \"1\", \"yes\"])\n",
    "    return s.astype(bool)\n",
    "\n",
    "def _safe_num(df, cols):\n",
    "    for c in cols:\n",
    "        if c in df.columns:\n",
    "            df[c] = pd.to_numeric(df[c], errors=\"coerce\")\n",
    "    return df\n",
    "\n",
    "def _flatten_dict_col(df, col, prefix=None):\n",
    "    \"\"\"Flatten a dict-valued column into separate columns, preserving row alignment.\"\"\"\n",
    "    if col not in df.columns:\n",
    "        return df\n",
    "    pfx = prefix or col\n",
    "\n",
    "    ser = df[col]\n",
    "    mask = ser.apply(lambda x: isinstance(x, dict))\n",
    "    if not mask.any():\n",
    "        return df\n",
    "\n",
    "    flat = pd.json_normalize(ser[mask])\n",
    "    flat.index = ser[mask].index  # IMPORTANT: align with original rows\n",
    "    flat.columns = [f\"{pfx}.{k}\" for k in flat.columns]\n",
    "\n",
    "    df = df.drop(columns=[col])\n",
    "    df = df.join(flat, how=\"left\")\n",
    "    return df\n",
    "\n",
    "def p95(x):\n",
    "    x = pd.to_numeric(x, errors=\"coerce\").dropna()\n",
    "    return float(x.quantile(0.95)) if len(x) else np.nan\n",
    "\n",
    "# ---------- coerce types ----------\n",
    "dbg = _safe_num(dbg, [\n",
    "    \"fold\",\"epoch\",\"global_step\",\"img_label\",\"matched\",\"num_gt\",\"pos\",\"total\",\"pos_frac\",\n",
    "    \"thr\",\"temp\",\"authentic_frac\",\"per_image_penalty_mean\",\"loss_auth_penalty\",\n",
    "    \"val_samples\",\"masks_empty\",\"gate_fail\",\"num_keep0\",\"cls_filtered_all_fg\",\"no_fg_pre_keep\",\n",
    "    \"max_cls_prob\",\"max_mask_prob\",\n",
    "    \"presence_mean\",\"presence_min\",\"presence_max\",\"tau\",\"loss_presence_auth\",\"loss_forged_presence\",\n",
    "    \"fg_prob_mean\",\"fg_prob_p95\",\"fg_prob_max\",\n",
    "    \"pred_auth_frac\",\"pred_non_auth_count\",\"pred_non_auth_area_ratio_mean\",\n",
    "])\n",
    "\n",
    "# bool-ish flags\n",
    "for c in [\"masks_empty\",\"gate_fail\",\"num_keep0\",\"cls_filtered_all_fg\",\"no_fg_pre_keep\"]:\n",
    "    if c in dbg.columns:\n",
    "        dbg[c] = _to_bool(dbg[c])\n",
    "\n",
    "# flatten nested dict payloads so they become aggregatable\n",
    "for col in [\"rates\", \"mask_probs\", \"class_probs\", \"img_probs\"]:\n",
    "    dbg = _flatten_dict_col(dbg, col)\n",
    "\n",
    "# ---------- OOF inference debug summary (tag == oof_inference_debug) ----------\n",
    "print(\"\\n=== OOF inference debug summary (per fold: counts, rates, max probs) ===\")\n",
    "oof = dbg[dbg[\"tag\"].astype(str).eq(\"oof_inference_debug\")].copy()\n",
    "if len(oof):\n",
    "    # per-fold (uses the already-aggregated counts/rates from train_cv)\n",
    "    show_cols = [c for c in [\n",
    "        \"fold\",\"val_samples\",\"masks_empty\",\"gate_fail\",\"num_keep0\",\"cls_filtered_all_fg\",\"no_fg_pre_keep\",\n",
    "        \"rates.masks_empty\",\"rates.gate_fail\",\"rates.num_keep0\",\"rates.cls_filtered_all_fg\",\"rates.no_fg_pre_keep\",\n",
    "        \"max_cls_prob.mean\",\"max_cls_prob.p95\",\"max_cls_prob.max\",\n",
    "        \"max_mask_prob.mean\",\"max_mask_prob.p95\",\"max_mask_prob.max\",\n",
    "    ] if c in oof.columns]\n",
    "    display(oof.sort_values(\"fold\")[show_cols])\n",
    "\n",
    "    # global weighted rates across folds\n",
    "    print(\"\\n=== OOF inference debug summary (global weighted failure rates) ===\")\n",
    "    w = oof[\"val_samples\"].astype(float).replace(0, np.nan)\n",
    "    global_rates = {}\n",
    "    for k in [\"masks_empty\",\"gate_fail\",\"num_keep0\",\"cls_filtered_all_fg\",\"no_fg_pre_keep\"]:\n",
    "        if k in oof.columns:\n",
    "            global_rates[k] = float((oof[k].astype(float) / w).mul(w).sum() / w.sum())\n",
    "    display(pd.Series(global_rates, name=\"weighted_rate\").to_frame())\n",
    "\n",
    "# ---------- Presence coupling stats (tag == loss_presence_stats) ----------\n",
    "print(\"\\n=== Presence coupling stats (loss_presence_stats: last epoch per fold + mean/std) ===\")\n",
    "pres = dbg[dbg[\"tag\"].astype(str).eq(\"loss_presence_stats\")].copy()\n",
    "if len(pres):\n",
    "    cols = [c for c in [\"fold\",\"epoch\",\"presence_mean\",\"presence_min\",\"presence_max\",\"tau\",\"loss_presence_auth\",\"loss_forged_presence\"] if c in pres.columns]\n",
    "    per_fold_last = (pres.sort_values([\"fold\",\"epoch\"]).groupby(\"fold\", as_index=False).tail(1))[cols]\n",
    "    display(per_fold_last.sort_values(\"fold\"))\n",
    "    display(per_fold_last.drop(columns=[\"fold\",\"epoch\"], errors=\"ignore\").agg([\"mean\",\"std\"]).T)\n",
    "\n",
    "# ---------- Auth penalty stats (tag == loss_auth_penalty_stats) ----------\n",
    "print(\"\\n=== Authenticity penalty stats (loss_auth_penalty_stats: last epoch per fold + mean/std) ===\")\n",
    "ap = dbg[dbg[\"tag\"].astype(str).eq(\"loss_auth_penalty_stats\")].copy()\n",
    "if len(ap):\n",
    "    cols = [c for c in [\"fold\",\"epoch\",\"thr\",\"temp\",\"authentic_frac\",\"per_image_penalty_mean\",\"loss_auth_penalty\"] if c in ap.columns]\n",
    "    per_fold_last = (ap.sort_values([\"fold\",\"epoch\"]).groupby(\"fold\", as_index=False).tail(1))[cols]\n",
    "    display(per_fold_last.sort_values(\"fold\"))\n",
    "    display(per_fold_last.drop(columns=[\"fold\",\"epoch\"], errors=\"ignore\").agg([\"mean\",\"std\"]).T)\n",
    "\n",
    "# ---------- Class target balance (tag == loss_cls_targets) ----------\n",
    "print(\"\\n=== Class-target balance (loss_cls_targets: pos_frac across folds) ===\")\n",
    "ct = dbg[dbg[\"tag\"].astype(str).eq(\"loss_cls_targets\")].copy()\n",
    "if len(ct):\n",
    "    cols = [c for c in [\"fold\",\"epoch\",\"B\",\"Q\",\"pos\",\"total\",\"pos_frac\"] if c in ct.columns]\n",
    "    display(\n",
    "        ct.groupby(\"fold\", dropna=False)[[\"pos_frac\"]]\n",
    "          .agg([\"mean\",\"std\",\"min\",\"max\"])\n",
    "    )\n",
    "\n",
    "# ---------- Hungarian matching health (tags == hungarian_match_*) ----------\n",
    "print(\"\\n=== Hungarian matching input health (tgt masks: numel / sum / shape) ===\")\n",
    "hm_in = dbg[dbg[\"tag\"].astype(str).eq(\"hungarian_match_input\")].copy()\n",
    "hm_out = dbg[dbg[\"tag\"].astype(str).eq(\"hungarian_match_result\")].copy()\n",
    "\n",
    "if len(hm_in):\n",
    "    cols = [c for c in [\"fold\",\"epoch\",\"tgt_numel\",\"tgt_sum\",\"tgt_shape\"] if c in hm_in.columns]\n",
    "    display(hm_in[cols].describe(include=\"all\"))\n",
    "\n",
    "if len(hm_out):\n",
    "    print(\"\\n=== Hungarian matching results (matched vs num_gt, empty_gt reasons) ===\")\n",
    "    cols = [c for c in [\"fold\",\"epoch\",\"matched\",\"num_gt\",\"reason\"] if c in hm_out.columns]\n",
    "    # how often empty_gt happens, and typical matched counts when GT exists\n",
    "    display(hm_out.groupby([\"fold\",\"reason\"], dropna=False).size().rename(\"rows\").reset_index())\n",
    "    if \"matched\" in hm_out.columns:\n",
    "        display(hm_out.groupby(\"fold\")[\"matched\"].agg([\"mean\",\"std\",\"min\",\"max\"]))\n",
    "\n",
    "# ---------- Mask-head alive signal during training (tag == train_fg_prob_per_query) ----------\n",
    "print(\"\\n=== Mask-head liveness during training (train_fg_prob_per_query: last epoch) ===\")\n",
    "fgq = dbg[dbg[\"tag\"].astype(str).eq(\"train_fg_prob_per_query\")].copy()\n",
    "if len(fgq):\n",
    "    cols = [c for c in [\"fold\",\"epoch\",\"Q\",\"fg_prob_mean\",\"fg_prob_p95\",\"fg_prob_max\"] if c in fgq.columns]\n",
    "    per_fold_last = (fgq.sort_values([\"fold\",\"epoch\"]).groupby(\"fold\", as_index=False).tail(1))[cols]\n",
    "    display(per_fold_last.sort_values(\"fold\"))\n",
    "\n",
    "    # Summarize per-query distribution at last epoch (all folds pooled)\n",
    "    last = fgq.sort_values([\"fold\",\"epoch\"]).groupby(\"fold\", as_index=False).tail(1)\n",
    "    if \"fg_prob_per_query\" in last.columns:\n",
    "        # fg_prob_per_query is a list; explode into long form\n",
    "        s = last[[\"fold\",\"epoch\",\"fg_prob_per_query\"]].dropna()\n",
    "        s = s.explode(\"fg_prob_per_query\")\n",
    "        s[\"fg_prob_per_query\"] = pd.to_numeric(s[\"fg_prob_per_query\"], errors=\"coerce\")\n",
    "        print(\"\\n=== Mask-head per-query foreground distribution (last epoch, exploded) ===\")\n",
    "        display(\n",
    "            s.groupby(\"fold\")[\"fg_prob_per_query\"]\n",
    "             .agg(mean=\"mean\", p95=p95, max=\"max\")\n",
    "             .reset_index()\n",
    "             .sort_values(\"fold\")\n",
    "        )\n",
    "\n",
    "# ---------- One-time debug_probs snapshots (tag == debug_probs) ----------\n",
    "# These are nested dicts and now flattened into mask_probs.*, class_probs.*, img_probs.*\n",
    "print(\"\\n=== One-time logits/probability sanity snapshots (debug_probs) ===\")\n",
    "dp = dbg[dbg[\"tag\"].astype(str).eq(\"debug_probs\")].copy()\n",
    "if len(dp):\n",
    "    cols = [c for c in dp.columns if c.startswith((\"mask_probs.\",\"class_probs.\",\"img_probs.\"))]\n",
    "    show = [\"fold\",\"epoch\",\"global_step\"] + cols\n",
    "    display(dp.sort_values([\"fold\",\"epoch\",\"global_step\"]).head(20)[show])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a3f5cae",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\piiop\\AppData\\Local\\Temp\\ipykernel_31968\\3800976337.py:47: FutureWarning: errors='ignore' is deprecated and will raise in a future version. Use to_numeric without passing `errors` and catch exceptions explicitly instead\n",
      "  oof_inf_view[c] = pd.to_numeric(oof_inf_view[c], errors=\"ignore\")\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fold</th>\n",
       "      <th>val_samples</th>\n",
       "      <th>masks_empty</th>\n",
       "      <th>gate_fail</th>\n",
       "      <th>num_keep0</th>\n",
       "      <th>cls_filtered_all_fg</th>\n",
       "      <th>no_fg_pre_keep</th>\n",
       "      <th>rates.masks_empty</th>\n",
       "      <th>rates.gate_fail</th>\n",
       "      <th>rates.num_keep0</th>\n",
       "      <th>rates.cls_filtered_all_fg</th>\n",
       "      <th>rates.no_fg_pre_keep</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>388578</th>\n",
       "      <td>1</td>\n",
       "      <td>1726.0</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.504056</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.477404</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>625806</th>\n",
       "      <td>1</td>\n",
       "      <td>1726.0</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.461182</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.973349</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>729329</th>\n",
       "      <td>1</td>\n",
       "      <td>1726.0</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.600232</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.904983</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>953632</th>\n",
       "      <td>1</td>\n",
       "      <td>1726.0</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.396871</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.855736</td>\n",
       "      <td>0.144264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1009711</th>\n",
       "      <td>1</td>\n",
       "      <td>1726.0</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0.437428</td>\n",
       "      <td>0.437428</td>\n",
       "      <td>0.196408</td>\n",
       "      <td>0.437428</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1234015</th>\n",
       "      <td>1</td>\n",
       "      <td>1726.0</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0.355156</td>\n",
       "      <td>0.355156</td>\n",
       "      <td>0.012746</td>\n",
       "      <td>0.355156</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1290094</th>\n",
       "      <td>1</td>\n",
       "      <td>1726.0</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.408459</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.833140</td>\n",
       "      <td>0.166860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1346173</th>\n",
       "      <td>1</td>\n",
       "      <td>1726.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1570477</th>\n",
       "      <td>1</td>\n",
       "      <td>1726.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1794781</th>\n",
       "      <td>1</td>\n",
       "      <td>1726.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019085</th>\n",
       "      <td>1</td>\n",
       "      <td>1726.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2781565</th>\n",
       "      <td>2</td>\n",
       "      <td>1725.0</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.379130</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3018843</th>\n",
       "      <td>2</td>\n",
       "      <td>1725.0</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.436522</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.899710</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3122386</th>\n",
       "      <td>2</td>\n",
       "      <td>1725.0</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>0.442319</td>\n",
       "      <td>0.442319</td>\n",
       "      <td>0.313623</td>\n",
       "      <td>0.442319</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3346729</th>\n",
       "      <td>2</td>\n",
       "      <td>1725.0</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0.543768</td>\n",
       "      <td>0.543768</td>\n",
       "      <td>0.416812</td>\n",
       "      <td>0.543768</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3402818</th>\n",
       "      <td>2</td>\n",
       "      <td>1725.0</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.206957</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.998841</td>\n",
       "      <td>0.001159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3627162</th>\n",
       "      <td>2</td>\n",
       "      <td>1725.0</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0.461449</td>\n",
       "      <td>0.461449</td>\n",
       "      <td>0.316522</td>\n",
       "      <td>0.461449</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3683251</th>\n",
       "      <td>2</td>\n",
       "      <td>1725.0</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0.415072</td>\n",
       "      <td>0.415072</td>\n",
       "      <td>0.079420</td>\n",
       "      <td>0.415072</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3739340</th>\n",
       "      <td>2</td>\n",
       "      <td>1725.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3963684</th>\n",
       "      <td>2</td>\n",
       "      <td>1725.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4188028</th>\n",
       "      <td>2</td>\n",
       "      <td>1725.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4412372</th>\n",
       "      <td>2</td>\n",
       "      <td>1725.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5124205</th>\n",
       "      <td>3</td>\n",
       "      <td>1725.0</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.409275</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.949565</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5361483</th>\n",
       "      <td>3</td>\n",
       "      <td>1725.0</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.426087</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.722319</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5465026</th>\n",
       "      <td>3</td>\n",
       "      <td>1725.0</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>0.913623</td>\n",
       "      <td>0.740290</td>\n",
       "      <td>0.913623</td>\n",
       "      <td>0.786087</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5689369</th>\n",
       "      <td>3</td>\n",
       "      <td>1725.0</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0.386087</td>\n",
       "      <td>0.386087</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.386087</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5745458</th>\n",
       "      <td>3</td>\n",
       "      <td>1725.0</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>0.780290</td>\n",
       "      <td>0.282899</td>\n",
       "      <td>0.779710</td>\n",
       "      <td>0.779710</td>\n",
       "      <td>0.000580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5969802</th>\n",
       "      <td>3</td>\n",
       "      <td>1725.0</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.410435</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.804638</td>\n",
       "      <td>0.195362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6025891</th>\n",
       "      <td>3</td>\n",
       "      <td>1725.0</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>0.738551</td>\n",
       "      <td>0.281739</td>\n",
       "      <td>0.738551</td>\n",
       "      <td>0.729275</td>\n",
       "      <td>0.009275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6081980</th>\n",
       "      <td>3</td>\n",
       "      <td>1725.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6306324</th>\n",
       "      <td>3</td>\n",
       "      <td>1725.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6530668</th>\n",
       "      <td>3</td>\n",
       "      <td>1725.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6755012</th>\n",
       "      <td>3</td>\n",
       "      <td>1725.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         fold  val_samples  masks_empty  gate_fail  num_keep0  \\\n",
       "388578      1       1726.0         True       True       True   \n",
       "625806      1       1726.0         True       True       True   \n",
       "729329      1       1726.0         True       True       True   \n",
       "953632      1       1726.0         True       True       True   \n",
       "1009711     1       1726.0         True       True       True   \n",
       "1234015     1       1726.0         True       True       True   \n",
       "1290094     1       1726.0         True       True       True   \n",
       "1346173     1       1726.0        False      False      False   \n",
       "1570477     1       1726.0        False      False      False   \n",
       "1794781     1       1726.0        False      False      False   \n",
       "2019085     1       1726.0        False      False      False   \n",
       "2781565     2       1725.0         True       True       True   \n",
       "3018843     2       1725.0         True       True       True   \n",
       "3122386     2       1725.0         True       True       True   \n",
       "3346729     2       1725.0         True       True       True   \n",
       "3402818     2       1725.0         True       True       True   \n",
       "3627162     2       1725.0         True       True       True   \n",
       "3683251     2       1725.0         True       True       True   \n",
       "3739340     2       1725.0        False      False      False   \n",
       "3963684     2       1725.0        False      False      False   \n",
       "4188028     2       1725.0        False      False      False   \n",
       "4412372     2       1725.0        False      False      False   \n",
       "5124205     3       1725.0         True       True       True   \n",
       "5361483     3       1725.0         True       True       True   \n",
       "5465026     3       1725.0         True       True       True   \n",
       "5689369     3       1725.0         True       True      False   \n",
       "5745458     3       1725.0         True       True       True   \n",
       "5969802     3       1725.0         True       True       True   \n",
       "6025891     3       1725.0         True       True       True   \n",
       "6081980     3       1725.0        False      False      False   \n",
       "6306324     3       1725.0        False      False      False   \n",
       "6530668     3       1725.0        False      False      False   \n",
       "6755012     3       1725.0        False      False      False   \n",
       "\n",
       "         cls_filtered_all_fg  no_fg_pre_keep  rates.masks_empty  \\\n",
       "388578                  True            True           1.000000   \n",
       "625806                  True            True           1.000000   \n",
       "729329                  True            True           1.000000   \n",
       "953632                  True            True           1.000000   \n",
       "1009711                 True           False           0.437428   \n",
       "1234015                 True           False           0.355156   \n",
       "1290094                 True            True           1.000000   \n",
       "1346173                False           False           0.000000   \n",
       "1570477                False           False           0.000000   \n",
       "1794781                False           False           0.000000   \n",
       "2019085                False           False           0.000000   \n",
       "2781565                 True            True           1.000000   \n",
       "3018843                 True            True           1.000000   \n",
       "3122386                 True            True           0.442319   \n",
       "3346729                 True           False           0.543768   \n",
       "3402818                 True            True           1.000000   \n",
       "3627162                 True           False           0.461449   \n",
       "3683251                 True           False           0.415072   \n",
       "3739340                False           False           0.000000   \n",
       "3963684                False           False           0.000000   \n",
       "4188028                False           False           0.000000   \n",
       "4412372                False           False           0.000000   \n",
       "5124205                 True            True           1.000000   \n",
       "5361483                 True            True           1.000000   \n",
       "5465026                 True            True           0.913623   \n",
       "5689369                 True           False           0.386087   \n",
       "5745458                 True            True           0.780290   \n",
       "5969802                 True            True           1.000000   \n",
       "6025891                 True            True           0.738551   \n",
       "6081980                False           False           0.000000   \n",
       "6306324                False           False           0.000000   \n",
       "6530668                False           False           0.000000   \n",
       "6755012                False           False           0.000000   \n",
       "\n",
       "         rates.gate_fail  rates.num_keep0  rates.cls_filtered_all_fg  \\\n",
       "388578          0.504056         1.000000                   0.477404   \n",
       "625806          0.461182         1.000000                   0.973349   \n",
       "729329          0.600232         1.000000                   0.904983   \n",
       "953632          0.396871         1.000000                   0.855736   \n",
       "1009711         0.437428         0.196408                   0.437428   \n",
       "1234015         0.355156         0.012746                   0.355156   \n",
       "1290094         0.408459         1.000000                   0.833140   \n",
       "1346173         0.000000         0.000000                   0.000000   \n",
       "1570477         0.000000         0.000000                   0.000000   \n",
       "1794781         0.000000         0.000000                   0.000000   \n",
       "2019085         0.000000         0.000000                   0.000000   \n",
       "2781565         0.379130         1.000000                   1.000000   \n",
       "3018843         0.436522         1.000000                   0.899710   \n",
       "3122386         0.442319         0.313623                   0.442319   \n",
       "3346729         0.543768         0.416812                   0.543768   \n",
       "3402818         0.206957         1.000000                   0.998841   \n",
       "3627162         0.461449         0.316522                   0.461449   \n",
       "3683251         0.415072         0.079420                   0.415072   \n",
       "3739340         0.000000         0.000000                   0.000000   \n",
       "3963684         0.000000         0.000000                   0.000000   \n",
       "4188028         0.000000         0.000000                   0.000000   \n",
       "4412372         0.000000         0.000000                   0.000000   \n",
       "5124205         0.409275         1.000000                   0.949565   \n",
       "5361483         0.426087         1.000000                   0.722319   \n",
       "5465026         0.740290         0.913623                   0.786087   \n",
       "5689369         0.386087         0.000000                   0.386087   \n",
       "5745458         0.282899         0.779710                   0.779710   \n",
       "5969802         0.410435         1.000000                   0.804638   \n",
       "6025891         0.281739         0.738551                   0.729275   \n",
       "6081980         0.000000         0.000000                   0.000000   \n",
       "6306324         0.000000         0.000000                   0.000000   \n",
       "6530668         0.000000         0.000000                   0.000000   \n",
       "6755012         0.000000         0.000000                   0.000000   \n",
       "\n",
       "         rates.no_fg_pre_keep  \n",
       "388578                    NaN  \n",
       "625806                    NaN  \n",
       "729329                    NaN  \n",
       "953632               0.144264  \n",
       "1009711              0.000000  \n",
       "1234015              0.000000  \n",
       "1290094              0.166860  \n",
       "1346173              0.000000  \n",
       "1570477              0.000000  \n",
       "1794781              0.000000  \n",
       "2019085              0.000000  \n",
       "2781565                   NaN  \n",
       "3018843                   NaN  \n",
       "3122386                   NaN  \n",
       "3346729              0.000000  \n",
       "3402818              0.001159  \n",
       "3627162              0.000000  \n",
       "3683251              0.000000  \n",
       "3739340              0.000000  \n",
       "3963684              0.000000  \n",
       "4188028              0.000000  \n",
       "4412372              0.000000  \n",
       "5124205                   NaN  \n",
       "5361483                   NaN  \n",
       "5465026                   NaN  \n",
       "5689369              0.000000  \n",
       "5745458              0.000580  \n",
       "5969802              0.195362  \n",
       "6025891              0.009275  \n",
       "6081980              0.000000  \n",
       "6306324              0.000000  \n",
       "6530668              0.000000  \n",
       "6755012              0.000000  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\piiop\\AppData\\Local\\Temp\\ipykernel_31968\\3800976337.py:58: FutureWarning: errors='ignore' is deprecated and will raise in a future version. Use to_numeric without passing `errors` and catch exceptions explicitly instead\n",
      "  oof_area_view[c] = pd.to_numeric(oof_area_view[c], errors=\"ignore\")\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fold</th>\n",
       "      <th>val_samples</th>\n",
       "      <th>pred_auth_frac</th>\n",
       "      <th>pred_non_auth_count</th>\n",
       "      <th>pred_non_auth_area_ratio_mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>953633</th>\n",
       "      <td>1</td>\n",
       "      <td>1726.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1009712</th>\n",
       "      <td>1</td>\n",
       "      <td>1726.0</td>\n",
       "      <td>0.437428</td>\n",
       "      <td>971.0</td>\n",
       "      <td>0.999578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1234016</th>\n",
       "      <td>1</td>\n",
       "      <td>1726.0</td>\n",
       "      <td>0.355156</td>\n",
       "      <td>1113.0</td>\n",
       "      <td>0.996847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1290095</th>\n",
       "      <td>1</td>\n",
       "      <td>1726.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1346174</th>\n",
       "      <td>1</td>\n",
       "      <td>1726.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1726.0</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1570478</th>\n",
       "      <td>1</td>\n",
       "      <td>1726.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1726.0</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1794782</th>\n",
       "      <td>1</td>\n",
       "      <td>1726.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1726.0</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019086</th>\n",
       "      <td>1</td>\n",
       "      <td>1726.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1726.0</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3346730</th>\n",
       "      <td>2</td>\n",
       "      <td>1725.0</td>\n",
       "      <td>0.543768</td>\n",
       "      <td>787.0</td>\n",
       "      <td>0.999915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3402819</th>\n",
       "      <td>2</td>\n",
       "      <td>1725.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3627163</th>\n",
       "      <td>2</td>\n",
       "      <td>1725.0</td>\n",
       "      <td>0.461449</td>\n",
       "      <td>929.0</td>\n",
       "      <td>0.999968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3683252</th>\n",
       "      <td>2</td>\n",
       "      <td>1725.0</td>\n",
       "      <td>0.415072</td>\n",
       "      <td>1009.0</td>\n",
       "      <td>0.993213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3739341</th>\n",
       "      <td>2</td>\n",
       "      <td>1725.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1725.0</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3963685</th>\n",
       "      <td>2</td>\n",
       "      <td>1725.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1725.0</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4188029</th>\n",
       "      <td>2</td>\n",
       "      <td>1725.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1725.0</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4412373</th>\n",
       "      <td>2</td>\n",
       "      <td>1725.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1725.0</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5689370</th>\n",
       "      <td>3</td>\n",
       "      <td>1725.0</td>\n",
       "      <td>0.386087</td>\n",
       "      <td>1059.0</td>\n",
       "      <td>0.977624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5745459</th>\n",
       "      <td>3</td>\n",
       "      <td>1725.0</td>\n",
       "      <td>0.780290</td>\n",
       "      <td>379.0</td>\n",
       "      <td>0.209065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5969803</th>\n",
       "      <td>3</td>\n",
       "      <td>1725.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6025892</th>\n",
       "      <td>3</td>\n",
       "      <td>1725.0</td>\n",
       "      <td>0.738551</td>\n",
       "      <td>451.0</td>\n",
       "      <td>0.996867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6081981</th>\n",
       "      <td>3</td>\n",
       "      <td>1725.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1725.0</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6306325</th>\n",
       "      <td>3</td>\n",
       "      <td>1725.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1725.0</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6530669</th>\n",
       "      <td>3</td>\n",
       "      <td>1725.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1725.0</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6755013</th>\n",
       "      <td>3</td>\n",
       "      <td>1725.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1725.0</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         fold  val_samples  pred_auth_frac  pred_non_auth_count  \\\n",
       "953633      1       1726.0        1.000000                  0.0   \n",
       "1009712     1       1726.0        0.437428                971.0   \n",
       "1234016     1       1726.0        0.355156               1113.0   \n",
       "1290095     1       1726.0        1.000000                  0.0   \n",
       "1346174     1       1726.0        0.000000               1726.0   \n",
       "1570478     1       1726.0        0.000000               1726.0   \n",
       "1794782     1       1726.0        0.000000               1726.0   \n",
       "2019086     1       1726.0        0.000000               1726.0   \n",
       "3346730     2       1725.0        0.543768                787.0   \n",
       "3402819     2       1725.0        1.000000                  0.0   \n",
       "3627163     2       1725.0        0.461449                929.0   \n",
       "3683252     2       1725.0        0.415072               1009.0   \n",
       "3739341     2       1725.0        0.000000               1725.0   \n",
       "3963685     2       1725.0        0.000000               1725.0   \n",
       "4188029     2       1725.0        0.000000               1725.0   \n",
       "4412373     2       1725.0        0.000000               1725.0   \n",
       "5689370     3       1725.0        0.386087               1059.0   \n",
       "5745459     3       1725.0        0.780290                379.0   \n",
       "5969803     3       1725.0        1.000000                  0.0   \n",
       "6025892     3       1725.0        0.738551                451.0   \n",
       "6081981     3       1725.0        0.000000               1725.0   \n",
       "6306325     3       1725.0        0.000000               1725.0   \n",
       "6530669     3       1725.0        0.000000               1725.0   \n",
       "6755013     3       1725.0        0.000000               1725.0   \n",
       "\n",
       "         pred_non_auth_area_ratio_mean  \n",
       "953633                        0.000000  \n",
       "1009712                       0.999578  \n",
       "1234016                       0.996847  \n",
       "1290095                       0.000000  \n",
       "1346174                       1.000000  \n",
       "1570478                       1.000000  \n",
       "1794782                       1.000000  \n",
       "2019086                       1.000000  \n",
       "3346730                       0.999915  \n",
       "3402819                       0.000000  \n",
       "3627163                       0.999968  \n",
       "3683252                       0.993213  \n",
       "3739341                       1.000000  \n",
       "3963685                       1.000000  \n",
       "4188029                       1.000000  \n",
       "4412373                       1.000000  \n",
       "5689370                       0.977624  \n",
       "5745459                       0.209065  \n",
       "5969803                       0.000000  \n",
       "6025892                       0.996867  \n",
       "6081981                       1.000000  \n",
       "6306325                       1.000000  \n",
       "6530669                       1.000000  \n",
       "6755013                       1.000000  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Fold-level val_loader debug counts (from oof_inference_debug events)\n",
    "def _extract_debug_event(df: pd.DataFrame, tag: str) -> pd.DataFrame:\n",
    "    if df is None or len(df) == 0:\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    # Most common format: columns include [\"tag\", \"payload\", ...]\n",
    "    if \"tag\" in df.columns:\n",
    "        ev = df[df[\"tag\"].astype(str) == tag].copy()\n",
    "    else:\n",
    "        # fallback if tag was flattened into a column name\n",
    "        ev = df.copy()\n",
    "\n",
    "    if len(ev) == 0:\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    if \"payload\" in ev.columns:\n",
    "        # payload is a dict -> flatten\n",
    "        payloads = ev[\"payload\"].tolist()\n",
    "        flat = pd.json_normalize(payloads, sep=\".\")\n",
    "        # preserve fold if present as a top-level col too\n",
    "        return flat\n",
    "    else:\n",
    "        # already flattened\n",
    "        return ev\n",
    "\n",
    "# dbg should already exist from your earlier \"debug*.jsonl\" concat\n",
    "oof_inf = _extract_debug_event(dbg, \"oof_inference_debug\")\n",
    "oof_area = _extract_debug_event(dbg, \"oof_pred_area_stats\")\n",
    "\n",
    "if len(oof_inf) == 0:\n",
    "    print(\"No oof_inference_debug events found in dbg (check debug jsonl ingestion).\")\n",
    "else:\n",
    "    cols = [\n",
    "        \"fold\", \"val_samples\",\n",
    "        \"masks_empty\", \"gate_fail\", \"num_keep0\", \"cls_filtered_all_fg\", \"no_fg_pre_keep\",\n",
    "        \"rates.masks_empty\", \"rates.gate_fail\", \"rates.num_keep0\", \"rates.cls_filtered_all_fg\", \"rates.no_fg_pre_keep\",\n",
    "        \"max_cls_prob.mean\", \"max_cls_prob.p95\", \"max_cls_prob.max\",\n",
    "        \"max_mask_prob.mean\", \"max_mask_prob.p95\", \"max_mask_prob.max\",\n",
    "    ]\n",
    "    keep = [c for c in cols if c in oof_inf.columns]\n",
    "    oof_inf_view = oof_inf[keep].copy()\n",
    "\n",
    "    for c in oof_inf_view.columns:\n",
    "        if c == \"fold\":\n",
    "            continue\n",
    "        try:\n",
    "            oof_inf_view[c] = pd.to_numeric(oof_inf_view[c])\n",
    "        except Exception:\n",
    "            pass\n",
    "\n",
    "    if \"fold\" in oof_inf_view.columns:\n",
    "        oof_inf_view = oof_inf_view.sort_values(\"fold\")\n",
    "\n",
    "    display(oof_inf_view)\n",
    "\n",
    "if len(oof_area):\n",
    "    cols = [\"fold\", \"val_samples\", \"pred_auth_frac\", \"pred_non_auth_count\", \"pred_non_auth_area_ratio_mean\"]\n",
    "    keep = [c for c in cols if c in oof_area.columns]\n",
    "    oof_area_view = oof_area[keep].copy()\n",
    "    for c in oof_area_view.columns:\n",
    "        if c != \"fold\":\n",
    "            oof_area_view[c] = pd.to_numeric(oof_area_view[c], errors=\"ignore\")\n",
    "    oof_area_view = oof_area_view.sort_values(\"fold\") if \"fold\" in oof_area_view.columns else oof_area_view\n",
    "    display(oof_area_view)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "951e6360",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# --- Plots: mask_max_mean, mask_max_p95, cls_max_mean vs epoch ---\n",
    "\n",
    "es_plot = epoch_summary.copy()\n",
    "\n",
    "need = [\"fold\", \"epoch\", \"mask_max_mean\", \"cls_max_mean\"]\n",
    "missing = [c for c in need if c not in es_plot.columns]\n",
    "if missing:\n",
    "    raise ValueError(f\"epoch_summary missing required columns: {missing}\")\n",
    "\n",
    "# coerce numeric\n",
    "for c in [\"fold\", \"epoch\", \"mask_max_mean\", \"cls_max_mean\"]:\n",
    "    es_plot[c] = pd.to_numeric(es_plot[c], errors=\"coerce\")\n",
    "\n",
    "es_plot = es_plot.dropna(subset=[\"epoch\", \"mask_max_mean\", \"cls_max_mean\"])\n",
    "\n",
    "# aggregate across folds per epoch\n",
    "g = es_plot.groupby(\"epoch\", as_index=False).agg(\n",
    "    mask_max_mean=(\"mask_max_mean\", \"mean\"),\n",
    "    mask_max_p95=(\"mask_max_mean\", lambda s: s.quantile(0.95)),\n",
    "    cls_max_mean=(\"cls_max_mean\", \"mean\"),\n",
    ")\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(g[\"epoch\"], g[\"mask_max_mean\"], marker=\"o\", label=\"mask_max_mean\")\n",
    "plt.plot(g[\"epoch\"], g[\"mask_max_p95\"], marker=\"o\", label=\"mask_max_p95 (over folds)\")\n",
    "plt.plot(g[\"epoch\"], g[\"cls_max_mean\"], marker=\"o\", label=\"cls_max_mean\")\n",
    "plt.xlabel(\"epoch\")\n",
    "plt.ylabel(\"value\")\n",
    "plt.title(\"Epoch trends (pooled across folds)\")\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e08e2c02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sanity_random_200 check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "883e8ec8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>rows</th>\n",
       "      <td>200.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>forged_folder_rate</th>\n",
       "      <td>0.545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>image_label_rate</th>\n",
       "      <td>0.545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>any_instances_rate</th>\n",
       "      <td>0.545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean_union_sum</th>\n",
       "      <td>30973.545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean_max_instance_sum</th>\n",
       "      <td>26154.455</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           value\n",
       "rows                     200.000\n",
       "forged_folder_rate         0.545\n",
       "image_label_rate           0.545\n",
       "any_instances_rate         0.545\n",
       "mean_union_sum         30973.545\n",
       "mean_max_instance_sum  26154.455"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "csvs = sorted(SAMPLEDUMP_ROOT.rglob(\"sanity_random_200.csv\"))\n",
    "assert csvs, \"No sanity_random_200.csv found under sanity_dumps\"\n",
    "\n",
    "df = pd.read_csv(csvs[-1])\n",
    "\n",
    "summary = {\n",
    "    \"rows\": len(df),\n",
    "    \"forged_folder_rate\": df[\"is_forged_folder\"].mean(),\n",
    "    \"image_label_rate\": df[\"image_label\"].mean(),\n",
    "    \"any_instances_rate\": (df[\"num_instances\"] > 0).mean(),\n",
    "    \"mean_union_sum\": df[\"union_sum\"].mean(),\n",
    "    \"mean_max_instance_sum\": df[\"max_instance_sum\"].mean(),\n",
    "}\n",
    "\n",
    "display(pd.Series(summary, name=\"value\").to_frame())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "af122e99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>image_label</th>\n",
       "      <th>0.0</th>\n",
       "      <th>1.0</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>is_forged_folder</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>False</th>\n",
       "      <td>91</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <td>0</td>\n",
       "      <td>109</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "image_label       0.0  1.0\n",
       "is_forged_folder          \n",
       "False              91    0\n",
       "True                0  109"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cross-tab: are forged-folder images ever labeled authentic?\n",
    "pd.crosstab(df[\"is_forged_folder\"], df[\"image_label\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bb1cd480",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# How often do we have forged-folder but zero instances?\n",
    "df.query(\"is_forged_folder == True and num_instances == 0\").shape[0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
